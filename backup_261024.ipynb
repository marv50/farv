{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1744b5a6",
   "metadata": {},
   "source": [
    "## Style guides (remove before submitting)\n",
    "1. PEP8 for python: https://peps.python.org/pep-0008\n",
    "2. for jupyter notebook: https://github.com/spacetelescope/style-guides/blob/master/guides/jupyter-notebooks.md\n",
    "\n",
    "## General TODO (remove before submitting)\n",
    "1. Maybe add Raise errors?\n",
    "\n",
    "## DOCSTRING convention example (according to Pep8) (remove before submitting)\n",
    "**Short docstrings:**\\\n",
    "\"\"\"This is an example of a short docstring.\"\"\"\\\n",
    "\\\n",
    "**Long docstrings:**\\\n",
    "\"\"\"\\\n",
    "Short description of the function (may be next to quotations above).\\\n",
    "\\\n",
    "Arguments:\\\n",
    "    parametername: What the parameter is\\\n",
    "    parametername2: what the parameter is\\\n",
    "\\\n",
    "Returns:\\\n",
    "    This is a description of what the function returns.\\\n",
    "\"\"\"\n",
    "\n",
    "# Gillespie's Algorithm and Stochasticity in a SIR model\n",
    "\n",
    "This code implements a Gillespie's algorithm (GA) to a SIR model where stochasticity is introduced.  \n",
    "\n",
    "#### SIR Model\n",
    "A SIR model is a description of the behavioral patterns of infectious disseases with the help of a set of Ordinary Differential Equations (ODEs). Depending on the dissease that's being modeled, there are different types of SIR models that can be implemented. The model that we use is divided into three categories:\n",
    "\n",
    "1.  Susceptible; A group within the population that is susceptible to infection with the dissease.\n",
    "2.  Infected; A group within the population that is currently infected with the dissease\n",
    "3.  Recovered; A group that has recovered from an infection, we assume they cannot be infected again\n",
    "\n",
    "The rate with which people transfer between these categories is described by parameters. The parameters we use are called the infection rate (beta) and recovery rate (gamma) that describe the flow of susceptible to infected (beta) and of infected to recovered (gamma). Additionally, birth and death rates are introduced to describe the effect of 'fresh' additions to the population to the susceptible pool and a chance of mortality at each category.\n",
    "\n",
    "The set of ODEs describe how the populations within these categories change over time due to the applied parameters. \n",
    "\n",
    "### Gillespie's Algorithm\n",
    "A Gillespie's Algorithm (GA) stochastically simulates discrete events from the equation it is applied to. In our application we used the so-called First Reaction Method where the rate at which an event occurs is passed to calculate how long it takes for the event to occur. To this determination, a random variable is attached to add stochasticity. The event that takes the least amount of time to occur is then executed, all other events are negated. The time that passed is updated to include the time it took for the event to occur and a new event is generated. This is repeated until the predetermined end-point is reached (such as an established end-time).\n",
    "\n",
    "- TO DO: \n",
    "    - add ODE functions\n",
    "    - add GA function \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8d472",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The following libraries where imported for further use in the code\n",
    "\n",
    "* tabulate for ...\n",
    "* numpy for use in numerical computing\n",
    "* matplotlib for visualisation of data in plots\n",
    "* pandas for ...\n",
    "* fractions for ...\n",
    "* solve_ivp for numerical integration of the SIR ODE functions\n",
    "* bisect for ...\n",
    "\n",
    "- TO DO:\n",
    "    - Add explanations\n",
    "    - Remove unused imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7642ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy import stats\n",
    "\n",
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.DiffusionModel as dm\n",
    "\n",
    "#np.random.seed(42) #MAx says you need to do this in every cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecd47f",
   "metadata": {},
   "source": [
    "# Stochasticity in a SIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4c8b7",
   "metadata": {},
   "source": [
    "## 1. Making a Stochastig SIR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fad77b",
   "metadata": {},
   "source": [
    "### 1.1 Define All Possible Events \n",
    "\n",
    "In order to update the stochastic GSP SIR model, the sir_update() function is given a key which it uses to identify and update the according S, I, R and or N populations. \n",
    "In this model, we approach the population as individuals, not scaled to percentages. Therefore, updates regard a single individual and only adjust the affected populations.\n",
    "\n",
    "By using if and elif statements, we prevent the function from accessing all if statements as there will always only be one key. If an if statement is accessed, it will return the updated S, I, R and N values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ea9b02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_update(S, I, R, N, key):\n",
    "    \"\"\"Updates and returns SIRN populations according to given key.\"\"\"\n",
    "\n",
    "    if key == 'infection':\n",
    "        S -= 1\n",
    "        I += 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'recovery': \n",
    "        R += 1\n",
    "        I -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'birth':\n",
    "        S += 1\n",
    "        N += 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death S':\n",
    "        S -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death I':\n",
    "        I -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death R':\n",
    "        R -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41243746",
   "metadata": {},
   "source": [
    "### 1.2 Implement GSP \n",
    "\n",
    "A random exponantial is assigned to each available event, allowing events occur only if the neccesary populations (S, I, R) have individuals. An event queue dictionary is initiated to store all possible events and their time of occurence, sorted in descending order. \n",
    "\n",
    "The simulation iterates by executing the first event in the queue, updating the SIR model parameters and adding the event's occurence time to the total elapsed time. After executing an event, the queue is cleared and reinitialized for the next cycle.\n",
    "\n",
    "This process continues until the elapsed time meets or exceeds a specified duration. The function returns the sizes of S, I, R, N as y_data along with the total simulation time\n",
    "\n",
    "\n",
    "\n",
    "- Add a way to control noise level (gsp function)\n",
    "    - Larger N reduces noise\n",
    "    - average results on multiple simulations\n",
    "    - reduce noise after simultaion: remove high frequency fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "845d40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsp(sir, beta, gamma, mu, end):\n",
    "    \"\"\"\n",
    "    Simulates disease spread using GA First Reaction Method.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        mu: Natural birth and death rate.\n",
    "        end: Signifies end point of simulation in time.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing a list of time events and population data \n",
    "        over time.\n",
    "    \"\"\"\n",
    "\n",
    "    S, I, R, N = sir\n",
    "    t = 0\n",
    "    \n",
    "    t_events = []\n",
    "    y_data = []\n",
    "    \n",
    "    while t <= end:\n",
    "        \n",
    "        # This queue collects the delta_t of each event at time t + delta_t\n",
    "        event_queue = {}\n",
    "\n",
    "        if S > 0 and I > 0 and N > 0:\n",
    "            dt_infection = np.random.exponential(1/(beta*S*I/N))\n",
    "            event_queue['infection'] = dt_infection\n",
    "\n",
    "        if I > 0:\n",
    "            dt_recovery = np.random.exponential(1/(gamma*I))\n",
    "            event_queue['recovery'] = dt_recovery\n",
    "\n",
    "        if N > 0:\n",
    "            dt_birth = np.random.exponential(1/(mu*N))\n",
    "            event_queue['birth'] = dt_birth\n",
    "\n",
    "        if S > 0:\n",
    "            dt_death_S = np.random.exponential(1/(mu*S))\n",
    "            event_queue['death S'] = dt_death_S\n",
    "\n",
    "        if I > 0:\n",
    "            dt_death_I = np.random.exponential(1/(mu*I))\n",
    "            event_queue['death I'] = dt_death_I\n",
    "\n",
    "        if R > 0:\n",
    "            dt_death_R = np.random.exponential(1/(mu*R))\n",
    "            event_queue['death R'] = dt_death_R\n",
    "\n",
    "        # Select the event with the smallest delta_t, this event will be carried out, the rest is omitted\n",
    "        sorted_queue = dict(sorted(event_queue.items(), \n",
    "                                   key=lambda item: item[1]))\n",
    "        first_event_key, first_event_time = list(sorted_queue.items())[0]\n",
    "        \n",
    "        # Updates the current time with delta_t\n",
    "        t += first_event_time\n",
    "        t_events.append(t)\n",
    "\n",
    "        # Handle each type of event\n",
    "        S, I, R, N = sir_update(S, I, R, N, first_event_key)\n",
    "\n",
    "        y_data.append([S, I, R])\n",
    "    \n",
    "    return (t_events, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c3a0a",
   "metadata": {},
   "source": [
    "### 1.3 Run Stochastic Simulation\n",
    "\n",
    "The function run_gsp_simulation() visualizes the data from the stochastic SIR model simulation above. By running the gsp() function, the neccesary data is unpacked into S, I and R and plotted. The figure indicates the change in population sizes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7c594d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gsp_simulation(sir, beta, gamma, mu, t_span):\n",
    "    \"\"\"\n",
    "    Runs the GA stochastic disease simulation and plots the results.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        mu: Natural birth and death rate.\n",
    "        t_span: Maximum duration of the GA simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    t_events, y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    S = y_data[:, 0]\n",
    "    I = y_data[:, 1]\n",
    "    R = y_data[:, 2]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t_events, S, label='Susceptible (S)', color='blue')\n",
    "    plt.plot(t_events, I, label='Infected (I)', color='orange')\n",
    "    plt.plot(t_events, R, label='Recovered (R)', color='green')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Population')\n",
    "    plt.title('Disease Simulation Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d47952",
   "metadata": {},
   "source": [
    "### 1.4 Parameters \n",
    "\n",
    "Parameters to the gsp model are initialized and passed to run the gsp simulation function. The parameters are kept seperately such that they may be changed with ease.\n",
    "The total population is chosen after which the other populations, Susceptible (S), Infected (I), and Recovered (R), are adjusted accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.01\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "timespan = 1000\n",
    "\n",
    "run_gsp_simulation(sir, beta, gamma, mu, timespan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a75d15",
   "metadata": {},
   "source": [
    "## 2. Making a Deterministic SIR Model\n",
    "\n",
    "A SIR model as created in the previous assignment is imported to analyze the difference between a deterministic and stochastic model. For clarity, all parameters are initiated again.\n",
    "\n",
    "TO DO: How much do we need to explain this?\n",
    "\n",
    "\n",
    "- Add similarity score between stochastic and derministic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2b5c1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ode(t, sir, parameters, N):\n",
    "    \"\"\"Calculates and returns the change in sir populations over time.\"\"\"\n",
    "    \n",
    "    beta, gamma, mu = parameters\n",
    "    S, I, R = sir\n",
    "\n",
    "    dSdt = (mu*N) - ((beta*S*I)/N) - (mu*S)\n",
    "    dIdt = ((beta*S*I)/N) - (gamma*I) - (mu*I)\n",
    "    dRdt = (gamma*I) - (mu*R)\n",
    "\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "\n",
    "def run_sir_det(sir, parameters, N, t_span):\n",
    "    \"\"\"Runs the deterministic sir model with passed initial values.\n",
    "    \n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        parameters: list containg recovery, infection and \n",
    "                    birth/death rate\n",
    "        N: Total initial population\n",
    "        t_span: Timespan in which the model is ran\n",
    "\n",
    "    Returns: \n",
    "        Timespan used to model sir and population sizes of S, I and R.\n",
    "    \"\"\"\n",
    "\n",
    "    # Time measurement with 1000 samples, equally spaced between 0 and t_span\n",
    "    time = np.linspace(0, t_span, 1000)\n",
    "\n",
    "    sir_integration = solve_ivp(calc_ode, [time[0], time[-1]], sir, \n",
    "                                args=(parameters, N), t_eval=time)\n",
    "    S, I, R = sir_integration.y\n",
    "\n",
    "    return time, S, I, R\n",
    "\n",
    "\n",
    "def plot_sir_det(time, S, I, R):\n",
    "    \"\"\"Plots the deterministic sir model.\"\"\"\n",
    "\n",
    "    plt.plot(time, S, label='Sus', color='b')\n",
    "    plt.plot(time, I, label='Infected', color='orange')\n",
    "    plt.plot(time, R, label='Rec', color='g')\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Number of Infected Individuals of Total Population')\n",
    "    plt.legend()\n",
    "    plt.title('Diagram of Infected Population against Discretized Time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitial population densities\n",
    "N = 500\n",
    "S0 = N - 1\n",
    "I0 = N - S0\n",
    "R0 = 0\n",
    "sir_det = [S0, I0, R0]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.01\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 1000\n",
    "\n",
    "# The semi-colon prevents the array from being printed in cell\n",
    "time, S, I, R = run_sir_det(sir_det, parameters, N, t_span);\n",
    "plot_sir_det(time, S, I, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7200f4",
   "metadata": {},
   "source": [
    "## 3. Analyzing stochasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19917057",
   "metadata": {},
   "source": [
    "### 3.1 Comparing GSP with Deterministic\n",
    "Both graphs of the deterministic and GSP model are overlapped with the same parameters to compare the difference between the results on a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sir_detvsgsp(sir, parameters, t_span):\n",
    "    \"\"\"Plots the deterministic vs stochastic sir models.\"\"\"\n",
    "\n",
    "    S, I, R, N = sir\n",
    "    sir_det = [S, I, R]\n",
    "    beta, gamma, mu = parameters\n",
    "\n",
    "    time, S_det, I_det, R_det = run_sir_det(sir_det, parameters, N, t_span)\n",
    "    t_events, y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    S_gsp = y_data[:, 0]\n",
    "    I_gsp = y_data[:, 1]\n",
    "    R_gsp = y_data[:, 2]\n",
    "\n",
    "    plt.plot(time, S_det, label='S (Deterministic)', color='b')\n",
    "    plt.plot(time, I_det, label='I (Deterministic)', color='orange')\n",
    "    plt.plot(time, R_det, label='R (Deterministic)', color='g')\n",
    "\n",
    "    plt.plot(t_events, S_gsp, label='S (GSP)', color='blue', linestyle='dashed')\n",
    "    plt.plot(t_events, I_gsp, label='I (GSP)', color='orange', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(t_events, R_gsp, label='R (GSP)', color='green', \n",
    "             linestyle='dashed')\n",
    "    \n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Number of Infected Individuals of Total Population')\n",
    "    plt.legend()\n",
    "    plt.title('Diagram of Infected Population against Discretized Time')\n",
    "    plt.show()\n",
    "\n",
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 100\n",
    "\n",
    "plot_sir_detvsgsp(sir, parameters, t_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20ecb7",
   "metadata": {},
   "source": [
    "### 3.2 Look at variance\n",
    "\n",
    "TODO MARVIN\n",
    "- write short python notebook since you made this one mostly, easier for you to do it\n",
    "\n",
    "- Plot results\n",
    "\n",
    "- Delete print statements (not yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96993",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(35)\n",
    "\n",
    "\n",
    "def generate_parameters(num_samples, lower_ratio=0.45, upper_ratio=0.55, \n",
    "                        beta_range=(0.1, 0.9), gamma_range=(0.1, 0.9)):\n",
    "    \"\"\"\n",
    "    Generates beta and gamma pairs randomly to calculate their R0 values. \n",
    "    Ensures ratio of R0 values  falls within specified bounds.\n",
    "    \n",
    "    Arguments:\n",
    "        num_samples: Total number of beta/gamma pairs to generate.\n",
    "        lower_ratio: Lower bound for the ratio of R0 values.\n",
    "        upper_ratio: Upper bound for the ratio of R0 values.\n",
    "        beta_range: Range for generated beta values.\n",
    "        gamma_range: Range for generated gamma values.\n",
    "    \n",
    "    Returns:\n",
    "        A list of the beta gamma pairs and a list of the generated \n",
    "        R0 values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize ratio of R0 values smaller and larger than 1.\n",
    "    ratio = 0\n",
    "\n",
    "    while ratio < lower_ratio or ratio > upper_ratio:\n",
    "\n",
    "        # only same random generator\n",
    "        betas = np.random.uniform(beta_range[0], beta_range[1], num_samples)\n",
    "        gammas = np.random.uniform(gamma_range[0], gamma_range[1], num_samples)\n",
    "\n",
    "        beta_gamma_pairs = list(zip(betas, gammas))\n",
    "        R0_vals = [beta / gamma for beta, gamma in beta_gamma_pairs]\n",
    "\n",
    "        # Calculate the ratio of R0 values < 1 and > 1\n",
    "        num_below_one = np.sum(np.array(R0_vals) < 1)\n",
    "        num_above_one = np.sum(np.array(R0_vals) > 1)\n",
    "        ratio = num_below_one/(num_above_one + 1e-10)  # Avoid division by zero (this is hardcoding, another way?)\n",
    "\n",
    "    R0_vals\n",
    "    print(\"Beta/gamma pairs: \" + str(beta_gamma_pairs))\n",
    "    print(\"R0 values: \" + str(R0_vals))\n",
    "    print(\"Ratio: \" + str(ratio))\n",
    "    \n",
    "    return beta_gamma_pairs, R0_vals\n",
    "\n",
    "\n",
    "def parameter_sweep(sir, pairs, mu, num_runs):\n",
    "    \"\"\"\n",
    "    Performs a parameter sweep over the SIR model simulation to analyze \n",
    "    the impact of varying beta and gamma values on the maximum number of \n",
    "    infected individuals.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        pairs: List of beta-gamma tuples to test in SIR model.\n",
    "        mu: Natural birth and death rate.\n",
    "        num_runs: Number of simulation runs per beta-gamma pair tuples.\n",
    "    \n",
    "    Returns:\n",
    "        A list of variances and covariances of the maximum infected \n",
    "        values for each beta-gamma pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    variances = []\n",
    "    covariances = []\n",
    "\n",
    "    for beta, gamma in pairs:\n",
    "        \n",
    "        # For variance\n",
    "        max_I_vals = []\n",
    "\n",
    "        # For covariance\n",
    "        S_vals= []\n",
    "        I_vals = []\n",
    "        \n",
    "        # Run simulation n times for each (beta, gamma) pair.\n",
    "        for _ in range(num_runs):\n",
    "\n",
    "            result = gsp(sir, beta, gamma, mu, t_span)\n",
    "            y_data = np.array(result[1])\n",
    "\n",
    "            S = y_data[:, 0]\n",
    "            I = y_data[:, 1]\n",
    "            R = y_data[:, 2]\n",
    "\n",
    "            S_vals.extend(S)\n",
    "            I_vals.extend(I)\n",
    "\n",
    "            # Extract max I value from each run.\n",
    "            max_I_vals.append(np.max(I))\n",
    "\n",
    "        # Variance for each (beta, gamma) pair after n runs is recorded.\n",
    "        variances.append(np.var(max_I_vals))\n",
    "        covariance_matrix = np.cov(S_vals, I_vals)\n",
    "        covariances.append(covariance_matrix[0, 1])\n",
    "\n",
    "    return variances, covariances\n",
    "\n",
    "\n",
    "def plot_R0_vs_variance(R0_vals, variances):\n",
    "    \"\"\"\n",
    "    Plots R0 values against variances of maximum infected individuals.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(R0_vals, variances, color='green', edgecolor='black')\n",
    "\n",
    "    plt.xlabel('R0 Values')\n",
    "    plt.ylabel('Variance of Max Infected')\n",
    "    plt.title('R0 Values vs Variance of Maximum Infected Individuals')\n",
    "    #plt.axhline(0, color='gray', linestyle='--')  # Optional: Add a horizontal line at y=0\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_R0_vs_covariances(R0_vals, covariances):\n",
    "    \"\"\"\n",
    "    Plots R0 values against covariances of S and I across different \n",
    "    parameter pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(R0_vals, covariances, color='green', edgecolor='black')\n",
    "\n",
    "    plt.xlabel('R0 Values')\n",
    "    plt.ylabel('S, I Covariance')\n",
    "    plt.title('R0 Values vs Covariances of S and I')\n",
    "    #plt.axhline(0, color='gray', linestyle='--')  # Optional: Add a horizontal line at y=0\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Define number of beta/gamma pairs.\n",
    "num_pairs = 50\n",
    "\n",
    "# Define number of runs per beta/gamma pair.\n",
    "num_runs = 10\n",
    "\n",
    "# Generate Parameters\n",
    "sample_pairs, sample_R0_vals = generate_parameters(num_pairs)\n",
    "\n",
    "# Calculate variances\n",
    "variances, covariances = parameter_sweep(sir, sample_pairs, mu, num_runs)\n",
    "\n",
    "# Combine and sort by R0 for variance analysis\n",
    "var_combined = list(zip(sample_R0_vals, variances))\n",
    "sorted_var_combined = sorted(var_combined)\n",
    "sorted_R0_vals, sorted_variances = zip(*sorted_var_combined)\n",
    "\n",
    "# Combine and sort by R0 for variance analysis\n",
    "covar_combined = list(zip(sample_R0_vals, covariances))\n",
    "sorted_covar_combined = sorted(covar_combined)\n",
    "sorted_R0_vals, sorted_covariances = zip(*sorted_covar_combined)\n",
    "\n",
    "plot_R0_vs_variance(sorted_R0_vals, sorted_variances)\n",
    "plot_R0_vs_covariances(sorted_R0_vals, sorted_covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f380c9",
   "metadata": {},
   "source": [
    "### 3.3 Calculate the Mean\n",
    "\n",
    "Since a stochastic simulation may render more extremes, we wanted to calculate and visualizes a mean for the stochastic SIR model to compare with the deterministic model. \n",
    "\n",
    "However, every gsp run may result in different time steps. Therefore we had to initialize dictionaries to store variables for each run at fixed steps. These steps were chosen by starting at t = 0 and ending at t = timespan. Here the timespan equals the timespan used for the gsp function. Steps were taken with equal spacing.\n",
    "\n",
    "For every gsp mean, the values of S, I and R (and N) at these specific time steps was saved. This was done by iterating over the list of fixed_steps and finding the S, I, R and N values at that point in time. The corresponding values are then stored in a dictionary with fixed_steps. This will eventually result in a dictionary with fixed time steps and values for S, I, R and N at each of those fixed steps. The amount of values at each step depends on how often the stochastic sir simulation was performed.\n",
    "\n",
    "The mean and std of each time step is then calculated and stored in seperate dictionaries.\n",
    "\n",
    "\n",
    "Since the steps at which S, I and R are recorded in the mean may differ from the fixed_steps that we determined, the lowest closest value was chosen and the S, I and R values were placed to the right of that value on the timeline\n",
    "TO DO: FRED\n",
    "- TO DO: change deterministic to roll with same parameters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsp_mean(runs, t_span, sir, parameters):\n",
    "    \"\"\"\n",
    "    This function runs the gsp SIR model a set number of times to \n",
    "    calculate the mean and standard deviation the runs.\n",
    "\n",
    "    Arguments:\n",
    "        runs: Number of times to run the gsp function\n",
    "        t_span: Lower bound for the ratio of R0 values.\n",
    "        sir: List of S, I, R and N populations.\n",
    "        parameters: list containg recovery, infection and \n",
    "                    birth/death rate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionaries with information stored of the results, mean and \n",
    "        standard deviation of each time step. Also returns a list of \n",
    "        maximum I values for each run.\n",
    "    \"\"\"\n",
    "\n",
    "    beta, gamma, mu = parameters\n",
    "\n",
    "    # calculates how large the steps should be in between time steps    \n",
    "    t_steps = t_span/ 1000\n",
    " \n",
    "    # end excludes end so include t_steps. steps are spacing between values\n",
    "    fixed_steps = np.round(np.arange(0, t_span + t_steps, t_steps), 2)\n",
    "\n",
    "    # store data from run at those fixed time steps \n",
    "    results = {\n",
    "        'time': fixed_steps.tolist(),\n",
    "        'S': {round(step, 4): [] for step in fixed_steps},\n",
    "        'I': {round(step, 4): [] for step in fixed_steps},\n",
    "        'R': {round(step, 4): [] for step in fixed_steps},\n",
    "        'N': {round(step, 4): [] for step in fixed_steps}\n",
    "        }\n",
    "    \n",
    "    results_mean = {\n",
    "        'S': [],\n",
    "        'I': [],\n",
    "        'R': [],\n",
    "        'N': []\n",
    "        }\n",
    "    \n",
    "    results_stdev = {\n",
    "        'S': [],\n",
    "        'I': [],\n",
    "        'R': [],\n",
    "        'N': []\n",
    "        }\n",
    "\n",
    "    # Stores the peak number of Infected and equivalent timepoints for every run\n",
    "    peak_infected = []\n",
    "\n",
    "    I_max = 0\n",
    "    t_max = 0\n",
    "\n",
    "    for _ in range(runs):\n",
    "        t_events , y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "        I_max = 0\n",
    "        t_max = 0\n",
    "\n",
    "        # Finds for which values of steps in fixed_steps what the closest (lower) is in t_events.\n",
    "        for steps in fixed_steps:\n",
    "            steps = round(steps, 4)\n",
    "\n",
    "            # Returns where a value should be inserted\n",
    "            position_value = bisect.bisect_right(t_events, steps)\n",
    "\n",
    "            # Find the closest lowest possible position value\n",
    "            if position_value > 0:\n",
    "                position_value -= 1\n",
    "\n",
    "            # Get the S, I and R data at that position\n",
    "            S, I, R = y_data[position_value]\n",
    "\n",
    "            if I > I_max:\n",
    "                I_max = I\n",
    "                t_max = t_events[position_value]\n",
    "\n",
    "            # Appends the corresponding values to the correct place on the timeline\n",
    "            results['S'][steps].append(S)\n",
    "            results['I'][steps].append(I)\n",
    "            results['R'][steps].append(R)\n",
    "            results['N'][steps].append(S + I + R)\n",
    "            \n",
    "        peak_infected.append([t_max, I_max])\n",
    "\n",
    "    # Access all entries for S, I , R and N in the fixed steps and store mean values in a dictionary\n",
    "    for steps in fixed_steps:\n",
    "        \n",
    "        results_mean['S'].append(np.mean(results['S'][steps]))\n",
    "        results_mean['I'].append(np.mean(results['I'][steps]))\n",
    "        results_mean['R'].append(np.mean(results['R'][steps]))\n",
    "        results_mean['N'].append(np.mean(results['N'][steps]))\n",
    "\n",
    "        results_stdev['S'].append(np.std(results['S'][steps]))\n",
    "        results_stdev['I'].append(np.std(results['I'][steps]))\n",
    "        results_stdev['R'].append(np.std(results['R'][steps]))\n",
    "        results_stdev['N'].append(np.std(results['N'][steps]))\n",
    "    \n",
    "    return results, results_mean, results_stdev, peak_infected\n",
    "\n",
    "\n",
    "def plot_mean(results, results_mean, sir):\n",
    "    \"\"\"\n",
    "    Visualizes the results from the gsp_mean function as changes in \n",
    "    population sizes over time.\n",
    "    \"\"\"\n",
    "   \n",
    "    S, I, R, N = sir\n",
    "    sir_det = [S, I, R]\n",
    "\n",
    "    S_mean = results_mean['S']\n",
    "    I_mean = results_mean['I']\n",
    "    R_mean = results_mean['R']\n",
    "    time = results['time']\n",
    "\n",
    "    time_2, S, I, R = run_sir_det(sir_det, parameters, N, t_span)\n",
    "    \n",
    "    plt.plot(time, S_mean, label='S mean', color='blue')\n",
    "    plt.plot(time, I_mean, label='I mean', color='red')\n",
    "    plt.plot(time, R_mean, label='R mean', color='green')\n",
    "    plt.plot(time_2, S, label='S deterministic', color='blue', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(time_2, I, label='I deterministic', color='red', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(time_2, R, label='R deterministic', color='green', \n",
    "             linestyle='dashed')\n",
    "\n",
    "    time_steps_S = []\n",
    "    time_steps_I = []\n",
    "    time_steps_R = []\n",
    "    S_values = []\n",
    "    I_values = []\n",
    "    R_values = []\n",
    "\n",
    "    for time_step, values in results['S'].items():\n",
    "        for value in values:\n",
    "            time_steps_S.append(time_step)\n",
    "            S_values.append(value)\n",
    "    \n",
    "    for time_step, values in results['I'].items():\n",
    "        for value in values:\n",
    "            time_steps_I.append(time_step)\n",
    "            I_values.append(value)\n",
    "\n",
    "    for time_step, values in results['R'].items():\n",
    "        for value in values:\n",
    "            time_steps_R.append(time_step)\n",
    "            R_values.append(value)\n",
    "\n",
    "    plt.scatter(time_steps_S, S_values, alpha=0.03, linewidths=0, \n",
    "                color='blue', marker='o', label='S values', s=1)\n",
    "    plt.scatter(time_steps_I, I_values, alpha=0.03, linewidths=0, \n",
    "                color='red', marker='o', label='I values', s=1)\n",
    "    plt.scatter(time_steps_R, R_values, alpha=0.03, linewidths=0, \n",
    "                color='green', marker='o', label='R values', s=1)\n",
    "\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Mean Number of Infected Individuals of Total Population')\n",
    "    plt.legend()\n",
    "    plt.title('Diagram of Population against Discretized Time (mean)')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 100\n",
    "runs = 100\n",
    "\n",
    "results, results_mean, results_stdev, _ = gsp_mean(runs, t_span, sir, parameters);\n",
    "plot_mean(results, results_mean, sir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18546bd",
   "metadata": {},
   "source": [
    "### 3.4 R0 vs Extinction Events\n",
    "\n",
    "TODO: MARVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab711086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_large_R0(num_samples, R0_range=(1.1, 5), gamma_value=0.1):\n",
    "    \"\"\"\n",
    "    Generates systematic beta and gamma pairs such that the R0 values range from 1.1 to 5.\n",
    "    \n",
    "    Parameters:\n",
    "        num_samples (int): Number of beta/gamma pairs to generate.\n",
    "        R0_range (tuple): Range for R0 values.\n",
    "        gamma_value (float): Fixed value for gamma (to systematically calculate beta).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of (beta, gamma) pairs.\n",
    "        list: List of R0 values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate evenly spaced R0 values within the specified range\n",
    "    R0_vals = np.linspace(R0_range[0], R0_range[1], num_samples)\n",
    "    \n",
    "    # Use a fixed gamma value, and calculate corresponding beta = R0 * gamma\n",
    "    gammas = np.full(num_samples, gamma_value)\n",
    "    betas = R0_vals*gammas  # beta = R0 * gamma\n",
    "\n",
    "    beta_gamma_pairs = list(zip(betas, gammas))\n",
    "\n",
    "    # Optional: print for debugging\n",
    "    print(\"Beta/gamma pairs: \" + str(beta_gamma_pairs))\n",
    "    print(\"R0 values: \" + str(R0_vals))\n",
    "    \n",
    "    return beta_gamma_pairs, R0_vals\n",
    "\n",
    "\n",
    "def count_R0_extinctions(pairs, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    extinction_list = []\n",
    "\n",
    "    for beta, gamma in pairs:\n",
    "        num_extinctions = 0\n",
    "    \n",
    "        for _ in range(num_runs):\n",
    "                result = gsp(sir, beta, gamma, mu, t_span)\n",
    "                y_data = np.array(result[1])\n",
    "\n",
    "                I = y_data[:, 1]\n",
    "\n",
    "                mean = np.mean(I)\n",
    "                print(mean)\n",
    "\n",
    "                if mean < 1e-2:  # Treat any value below a small threshold as extinction:\n",
    "                    num_extinctions += 1\n",
    "\n",
    "        extinction_list.append(num_extinctions)\n",
    "\n",
    "    return extinction_list\n",
    "        \n",
    "\n",
    "def plot_results_R0(num_pairs, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "    \n",
    "    sample_pairs, sample_R0_vals = generate_large_R0(num_pairs)\n",
    "    R0_extinctions = count_R0_extinctions(sample_pairs, num_runs)\n",
    "\n",
    "    # Sort R0 values and corresponding extinctions\n",
    "    R0_extinction_pairs = list(zip(sample_R0_vals, R0_extinctions))\n",
    "    sorted_R0_extinction_pairs = sorted(R0_extinction_pairs)\n",
    "\n",
    "    sorted_R0_vals, sorted_extinctions = zip(*sorted_R0_extinction_pairs)\n",
    "\n",
    "    # Convert to numpy arrays for easy indexing\n",
    "    sorted_R0_vals = np.array(sorted_R0_vals)\n",
    "    sorted_extinctions = np.array(sorted_extinctions)\n",
    "\n",
    "    # Bin the R0 values (for example, in intervals of 0.1)\n",
    "    bins = np.arange(min(sorted_R0_vals), max(sorted_R0_vals), 0.2)\n",
    "    bin_indices = np.digitize(sorted_R0_vals, bins)\n",
    "\n",
    "    # Average extinctions within each bin\n",
    "    binned_extinctions = [np.mean(sorted_extinctions[bin_indices == i]) \n",
    "                          for i in range(1, len(bins))]\n",
    "\n",
    "    # Plotting\n",
    "    plt.bar(bins[:-1], binned_extinctions, width=0.1)\n",
    "    plt.xlabel(\"R0 Value\")\n",
    "    plt.ylabel(\"Average Extinctions\")\n",
    "    plt.title(\"Average Extinctions vs. R0 Value\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ADD BLOCKNOTE\n",
    "num_pairs = 20\n",
    "num_runs = 50\n",
    "mu = 0.0001\n",
    "\n",
    "plot_results_R0(num_pairs, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0e80a",
   "metadata": {},
   "source": [
    "### 3.5 N vs Extinction Events\n",
    "\n",
    "TODO MARVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04092cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_populations(num_pops):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    populations = []\n",
    "    \n",
    "    # Evenly distributes populations from 100 to 10,000.\n",
    "    S_0 = np.linspace(100, 10000, num_pops)\n",
    "\n",
    "    for i in range(num_pops):\n",
    "        S = S_0[i]\n",
    "        I = 1\n",
    "        R = 0\n",
    "        N = S + I\n",
    "        sir = (S, I, R, N)\n",
    "        populations.append(sir)\n",
    "    \n",
    "    return populations\n",
    "\n",
    "\n",
    "def count_N_extinctions(num_pops, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    populations = generate_populations(num_pops)\n",
    "    extinction_list = []\n",
    "\n",
    "    for pop in populations:\n",
    "        num_extinctions = 0\n",
    "        for _ in range(num_runs):\n",
    "            result = gsp(pop, beta, gamma, mu, t_span)\n",
    "            y_data = np.array(result[1])\n",
    "            I = y_data[:, 1]\n",
    "            mean = np.mean(I)\n",
    "\n",
    "            # Treats any value below a small threshold as extinction.\n",
    "            if mean < 1e-3:\n",
    "                num_extinctions += 1\n",
    "        \n",
    "        extinction_list.append(num_extinctions)\n",
    "    \n",
    "    return extinction_list\n",
    "\n",
    "\n",
    "def plot_results_N(num_pops, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "    \n",
    "    sample_pops = generate_populations(num_pops)\n",
    "    N_extinctions = count_N_extinctions(num_pops, num_runs)\n",
    "\n",
    "    # Sorts population sizes and corresponding extinctions.\n",
    "    N_extinction_pairs = list(zip(sample_pops, N_extinctions))\n",
    "    sorted_N_extinction_pairs = sorted(N_extinction_pairs)\n",
    "\n",
    "    sorted_pops, sorted_extinctions = zip(*sorted_N_extinction_pairs)\n",
    "\n",
    "    # Convert to numpy arrays for easy indexing\n",
    "    sorted_pops = np.array(sorted_pops)\n",
    "    sorted_extinctions = np.array(sorted_extinctions)\n",
    "\n",
    "    # Bin the population sizes more sensibly with a larger bin size\n",
    "    bins = np.arange(min(sorted_pops[:, 0]), max(sorted_pops[:, 0]) + 1, 300)  # Increase bin size to 1000\n",
    "    bin_indices = np.digitize(sorted_pops[:, 0], bins)\n",
    "\n",
    "    # Average extinctions within each bin\n",
    "    binned_extinctions = [np.mean(sorted_extinctions[bin_indices == i]) for i in range(1, len(bins))]\n",
    "\n",
    "    # Plotting\n",
    "    plt.bar(bins[:-1], binned_extinctions, width=np.diff(bins), align='edge')\n",
    "    plt.xlabel(\"N\")\n",
    "    plt.ylabel(\"Average Extinctions\")\n",
    "    plt.title(\"Average Extinctions vs. N (with adjusted bin size)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parameters\n",
    "beta = 0.4\n",
    "gamma = 0.1\n",
    "mu = 0.0001\n",
    "\n",
    "num_pops = 20\n",
    "num_runs = 50\n",
    "\n",
    "plot_results_N(num_pops, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e3585",
   "metadata": {},
   "source": [
    "### 3.6 Extinctions as a Function of R0 and N\n",
    "\n",
    "TODO MARVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_R0_N(num_pairs, num_pops, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    # Generate R0 pairs\n",
    "    sample_pairs, sample_R0_vals = generate_large_R0(num_pairs)\n",
    "\n",
    "    # Generate populations\n",
    "    populations = generate_populations(num_pops)\n",
    "\n",
    "    # Count extinctions for each combination of R0 and N\n",
    "    extinction_data = []\n",
    "\n",
    "    for (beta, gamma), R0 in zip(sample_pairs, sample_R0_vals):\n",
    "        \n",
    "        for pop in populations:\n",
    "            num_extinctions = 0\n",
    "            \n",
    "            for _ in range(num_runs):\n",
    "                result = gsp(pop, beta, gamma, mu, t_span)\n",
    "                y_data = np.array(result[1])\n",
    "                I = y_data[:, 1]\n",
    "                mean = np.mean(I)\n",
    "                \n",
    "                if mean < 1e-2:  # Treat any value below a small threshold as extinction\n",
    "                    num_extinctions += 1\n",
    "\n",
    "            # Store results: (N, R0, num_extinctions)\n",
    "            N = pop[0] + pop[1] + pop[2]  # S + I + R\n",
    "            extinction_data.append((N, R0, num_extinctions))\n",
    "\n",
    "    # Convert to numpy array for easier indexing\n",
    "    extinction_data = np.array(extinction_data)\n",
    "\n",
    "    # Separate the data for plotting\n",
    "    N_values = extinction_data[:, 0]\n",
    "    R0_values = extinction_data[:, 1]\n",
    "    extinction_counts = extinction_data[:, 2]\n",
    "\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    scatter = ax.scatter(N_values, R0_values, extinction_counts, c=extinction_counts, cmap='viridis')\n",
    "    \n",
    "    ax.set_xlabel('Population Size (N)')\n",
    "    ax.set_ylabel('R0 Value')\n",
    "    ax.set_zlabel('Number of Extinctions')\n",
    "    ax.set_title('Interaction between R0 and N in Extinctions')\n",
    "\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Number of Extinctions')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parameters\n",
    "num_pairs = 20\n",
    "num_pops = 20\n",
    "num_runs = 20\n",
    "mu = 0.0001\n",
    "\n",
    "# Execute the plotting function\n",
    "plot_results_R0_N(num_pairs, num_pops, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17600feb",
   "metadata": {},
   "source": [
    "### 3.7 Stochastic Resonance\n",
    "\n",
    "TODO FRED\n",
    "\n",
    "Might have to redo see pic max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091299a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoc_res_R0(num_samples, R0_range=(1, 10), gamma_value=0.1):\n",
    "    \"\"\"R0 values is a list of n_samples R0 and beta of n_sample amount, gamma equal.\"\"\"\n",
    "    \n",
    "    R0_values = np.round(np.linspace(R0_range[0], R0_range[1], num_samples), 2)\n",
    "    \n",
    "    beta_values = []\n",
    "    gamma_values = []\n",
    "\n",
    "    for value in R0_values:\n",
    "        beta_values.append(np.round((value * gamma_value), 2))\n",
    "        gamma_values.append(gamma_value)\n",
    "\n",
    "    beta_gamma_pairs = list(zip(beta_values, gamma_values))\n",
    "\n",
    "    return beta_gamma_pairs\n",
    "\n",
    "\n",
    "def stoc_res(sir, t_span, num_samples, mu):\n",
    "    \"\"\"\n",
    "    Peak infected and peak_det are lists containing all sets of peak \n",
    "    infected values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_gamma_pairs = stoc_res_R0(num_samples)\n",
    "\n",
    "    peak_det = []\n",
    "    bg = []\n",
    "    snr = []\n",
    "    mean_time = []\n",
    "    stdev_time = []\n",
    "\n",
    "    for beta, gamma in beta_gamma_pairs:\n",
    "        parameters = [beta, gamma, mu]\n",
    "        runs_stoc = 10\n",
    "        _, _, _, peak_infected = gsp_mean(runs_stoc, t_span, sir, parameters)\n",
    "\n",
    "        # Calculates the mean and stdev for peak infected time in gsp\n",
    "        time = [t[0] for t in peak_infected]\n",
    "        mean_time.append(np.mean([time]))\n",
    "        mean_time_gsp = np.mean([time])\n",
    "        stdev_time.append(np.std([time]))\n",
    "        \n",
    "        # Unpacks and reassign sir for deterministic model.\n",
    "        S, I, R, N = sir\n",
    "        sir_det = S, I , R\n",
    "        time_det, _, I_det, _ = run_sir_det(sir_det, parameters, N, \n",
    "                                                    t_span)\n",
    "\n",
    "        # Finds maximum values for deterministic model and stores them.\n",
    "        I_max = max(I_det)\n",
    "        t_max_index = np.where(I_det == I_max)\n",
    "        t_max = time_det[t_max_index][0]\n",
    "        peak_det.append([t_max])\n",
    "\n",
    "        bg.append(beta/gamma)\n",
    "        snr.append(t_max/ mean_time_gsp)\n",
    "\n",
    "\n",
    "    # have peaks for det\n",
    "    # have peaks for gsp mean\n",
    "    # have peaks for gsp stdev\n",
    "    return mean_time, stdev_time, peak_det, bg, snr\n",
    "\n",
    "\n",
    "def plot_stoc_peak(mean_time, peak_det, bg):\n",
    "    \"\"\"\n",
    "    TO DO: possibly add stdev error bars, substract mean det from mean \n",
    "    gsp, but will go into 0.\"\"\"\n",
    "\n",
    "    plt.plot(bg, peak_det, label='peak I time det', color='green')\n",
    "    plt.plot(bg, mean_time, label='peak I time stoc', color='blue')\n",
    "    plt.xlabel('R0')\n",
    "    plt.ylabel('Time of peak I')\n",
    "    plt.legend()\n",
    "    plt.title('Time to reach peak in Infected population for different R0 values')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_stoc_snr(bg, snr):\n",
    "    \"\"\"\n",
    "    TO DO: possibly add stdev error bars, substract mean det from mean \n",
    "    gsp, but will go into 0.\"\"\"\n",
    "\n",
    "    plt.plot(bg, snr, label='SNR', color='red')\n",
    "    plt.xlabel('R0')\n",
    "    plt.ylabel('Signal to Noise ratio')\n",
    "    plt.legend()\n",
    "    plt.title('SNR ratio for peak in infected population for different R0 values')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Initial conditions with a population of 500 people\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "mu = 0.001\n",
    "\n",
    "t_span = 200\n",
    "num_samples = 100\n",
    "\n",
    "mean_time, stdev_time, peak_det, bg, snr = stoc_res(sir, t_span, num_samples, mu)\n",
    "plot_stoc_peak(mean_time, peak_det, bg)\n",
    "plot_stoc_snr(bg, snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d3ab9",
   "metadata": {},
   "source": [
    "### 3.8 Mean for different N populations\n",
    "\n",
    "TODO MARVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e2aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_means_for_different_Ns(N_values, num_runs, t_span, parameters):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    for N in N_values:\n",
    "        sir = (N - 1, 1, 0, N)  # S, I, R, N\n",
    "        _, results_mean, _, _ = gsp_mean(num_runs, t_span, sir, parameters)\n",
    "\n",
    "        # Plot the mean infected population over time\n",
    "        plt.plot(results_mean['I'], label=f'N = {N}')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Mean Infected Population')\n",
    "    plt.title('Mean Infected Population for Different Values of N')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "N_values = [100, 500, 1000, 1500]\n",
    "num_runs = 50\n",
    "t_span = 1000\n",
    "\n",
    "beta = 0.4\n",
    "gamma = 0.2\n",
    "mu = 0.01\n",
    "\n",
    "parameters = (beta, gamma, mu)\n",
    "\n",
    "plot_means_for_different_Ns(N_values, num_runs, t_span, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc28e84",
   "metadata": {},
   "source": [
    "# SIR in Network Models\n",
    "\n",
    "TODO EXPLAIN\n",
    "- 0 = sus, 1 = inf, 2 = removed (recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4c1a9",
   "metadata": {},
   "source": [
    "## 1. Barabasi Albert Network (FINISHED)\n",
    "A Barabasi-Albert (BA) network is a scale-free network.This network aaplies a prefferential attachment method meaning that nodes who are more connected are more likely to aquire new edges. New nodes are therefore more likely to connect to existing nodes with a higher degree of connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da41b8",
   "metadata": {},
   "source": [
    "### 1.1 Barabasi Albert Network\n",
    "With the help of the NetworkX library a random graph using the BA method of attaching nodes is created. By supplying the graph to the Network Diffusion Library (NDlib), a SIR model is created through setting up the appropriate parameters through functions supplied by the Configuration class of NDLib. The model is iterated t_span amount of times, after which the appropriate data is returned. To create a BA network, we supply a variable m which indicates the number of edges to attach from a new node to an existing node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINISHED\n",
    "def barabasi_albert(N, m, beta, gamma, I0, t_span):\n",
    "    \"\"\"\n",
    "    This function generates a Barabasi-Albert (scale-free) network model. \n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes.\n",
    "        m: Number of edges to attach from new node to existing node. \n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Initial number of infected nodes.\n",
    "        t_span: Number of iterations to execute the model.\n",
    "\n",
    "    Returns:\n",
    "        Lists for the number of iterations generated by the model and \n",
    "        data concerning the S, I and R populations of each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    ba_graph = nx.barabasi_albert_graph(N, m)\n",
    "    model = ep.SIRModel(ba_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)  \n",
    "    config.add_model_parameter('gamma', gamma)  \n",
    "    config.add_model_parameter(\"fraction_infected\", I0)  \n",
    "\n",
    "    model.set_initial_status(config)\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "    \n",
    "    y_data = []  \n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:  \n",
    "                S_count += 1\n",
    "            elif state == 1:  \n",
    "                I_count += 1\n",
    "            elif state == 2:  \n",
    "                R_count += 1\n",
    "        \n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2501d",
   "metadata": {},
   "source": [
    "### 1.2 Barabasi Albert Network Parameter Sweep\n",
    "In order to understand the effect of supplying different values for m, a parameter sweep is performed by generating a list of values for m. Additionally, we also want to compare this with changing values for the basic reproductive number (R0). List for these parameters are supplied to a function that will iterate over the lists in seperate functions and run the Barabasi-Albert (BA) network for each value set a specified of times. Data from the BA network is returned and lists of the maximum mean and standard deviations of the number of infected nodes is generated. These values can then be supplied to another function to plot the result and visualize the effect of changing these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished\n",
    "def ba_m_sweep(N, m_values, beta, gamma, I0, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Generates a Barabasi-Albert (BA) network for different values of m \n",
    "    and finds the mean maximum and standard deviation of the number of \n",
    "    infected nodes per run.\n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes\n",
    "        m_values: List of m values.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Percentage of initially infected nodes.\n",
    "        t_span: Number of iterations inside BA network.\n",
    "        num_runs: Number of iterations of BA network.\n",
    "\n",
    "    Returns:\n",
    "        A list of maximum mean and standard deviations of the number of \n",
    "        infected nodes per run.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_max_values = []\n",
    "    std_max_values = []\n",
    "\n",
    "    # Iterate over all values for m to generate a BA network.\n",
    "    for m in m_values:\n",
    "        max_I_values = []\n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = barabasi_albert(N, m, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            # Get the maximum infected value in the current run\n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values\n",
    "\n",
    "\n",
    "# Finished\n",
    "def plot_ba_m_sweep(N, m_values, beta_values, gamma_values, I0, t_span, \n",
    "                    num_runs):\n",
    "    \"\"\"Visualizes data for the parameter sweeps of the BA network.\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        mean_max_values, std_max_values = ba_m_sweep(N, m_values, beta, gamma, \n",
    "                                                     I0, t_span, num_runs)\n",
    "        R0 = beta/gamma\n",
    "\n",
    "        label = f'R₀ = {R0:.1f} (β = {beta:.1f}, γ = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(m, mean_max_values, yerr=std_max_values, fmt='-o', \n",
    "                     capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Number of edges (m)\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\n",
    "        \"Mean Maximum Infected Nodes vs Number of Edges\" \n",
    "        \"for Different R₀ Values\"\n",
    "        )\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Finished\n",
    "def ba_m_vs_R0(N, m_values, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    \"\"\"This function generates a list for combinations of beta and gamma \n",
    "    values based on a supplied list of gamma and R0 values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    \n",
    "    plot_ba_m_sweep(N, m_values, beta_values, gamma_values, I0, t_span, \n",
    "                    num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "m_values = np.arange(1, 11, 1)\n",
    "R0_values = [0.5, 1.0, 2.5] \n",
    "gamma_values = [0.1, 0.2, 0.2]\n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "ba_m_vs_R0(N, m_values, I0, t_span, num_runs, R0_values, gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f67808",
   "metadata": {},
   "source": [
    "## 2. Watts-Strogatz (MAYBE CHANGE PARAMTER SWEEP)\n",
    "In a Watts-Strogatz network model a random graph of small-world properties is generated. The model interpolates between a randomized structure and ring lattice by generating a ring lattice with N nodes and connecting each node with k number of it's nearest neighbors on either side of the node. Nodes are rewired with a probability p. This typically generates short path lengths and high clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692cfce",
   "metadata": {},
   "source": [
    "### 2.1 Watts-Strogatz Network\n",
    "To create the model a graph of a WS network is created with the NetworkX library by supplying WS specific parameters k and p. The graph is passed to NDLib to create a SIR Model. A configuration class is initialized to which parameters are given to build the SIR model through built-in class functions. The SIR model is generated by iterating over it a set number of times and changing the SIR populations accordingly. The data of each S, I and R population is gathered along the appropriate time steps and returned. Creation of the WS graph is specifically dependent on parameters k (Number of nearest neighbors to connect a node in ring topology) and p (Rewiring probability of each edge) and the number of nodes which are all supplied to the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINISHED\n",
    "def watts_strogatz(N, k, p, beta, gamma, I0, t_span):\n",
    "    \"\"\"\n",
    "    Generates a Watts-Strogatz (WA) network model graph and gathers data on S, \n",
    "    I and R populations.\n",
    "\n",
    "    Arguments:\n",
    "        N: number of nodes.\n",
    "        k: Number of nearest neighbors to connect a node in ring topology.\n",
    "        p: Rewiring probability of each edge.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Initial percentage of infected nodes.\n",
    "        t_span: Number of iterations to execute the model.\n",
    "\n",
    "    Returns: \n",
    "        Lists for the number of iterations generated by the model and \n",
    "        data concerning the S, I and R populations of each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    ws_graph = nx.watts_strogatz_graph(N, k, p)\n",
    "    model = ep.SIRModel(ws_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", I0)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "    \n",
    "    y_data = []\n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:\n",
    "                S_count += 1\n",
    "            elif state == 1:\n",
    "                I_count += 1\n",
    "            elif state == 2:\n",
    "                R_count += 1\n",
    "        \n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "k = 6    # Number of neighbors to rewire\n",
    "p = 0.1    # Rewiring probability\n",
    "t_span = 200\n",
    "\n",
    "results = watts_strogatz(N, k, p, beta, gamma, I0, t_span)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3d26d",
   "metadata": {},
   "source": [
    "### 2.2 Watts-Strogatz Network parameter Sweep \n",
    "As with the BA network, a parameter sweep for network specific parameters was performed. Parameters were changed for k and R0. The sweeps were set up similarly to the BA network sweep with the only changes being instead of m, k is varied. R0 are varied for both. Again, lists of the maximum mean and standard deviations of the number of infected nodes is generated and can subsequently be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finished\n",
    "def ws_k_sweep(N, k_values, p, beta, gamma, I0, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Generates a WS network for different values of k and finds the mean \n",
    "    maximum and standard deviation of the number of infected nodes per \n",
    "    run.\n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes\n",
    "        k_values: List of k values.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Percentage of initially infected nodes.\n",
    "        t_span: Number of iterations inside BA network.\n",
    "        num_runs: Number of iterations of BA network.\n",
    "\n",
    "    Returns:\n",
    "        A list of maximum mean and standard deviations of the number of \n",
    "        infected nodes per run.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_max_values = []\n",
    "    std_max_values = []\n",
    "\n",
    "    for k in k_values:\n",
    "        max_I_values = []\n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = watts_strogatz(N, k, p, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            # Get the maximum infected value in the current run\n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values\n",
    "\n",
    "\n",
    "#Finished\n",
    "def plot_ws_k_sweep(N, k_values, p, beta_values, gamma_values, I0, t_span, num_runs):\n",
    "    \"\"\"\"Visualizes data for the parameter sweeps of the WS network.\"\"\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        \n",
    "        mean_max_values, std_max_values = ws_k_sweep(N, k_values, p, beta, gamma, I0, t_span, num_runs)\n",
    "        \n",
    "        R0 = beta/gamma\n",
    "        label = f'R₀ = {R0:.1f} (β = {beta:.1f}, γ = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(k_values, mean_max_values, yerr=std_max_values, fmt='-o', capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Number of Neighbors (n)\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\"Mean Maximum Infected Nodes vs Number of Neighbors for Different R₀ Values\")\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "# Finished\n",
    "def ws_k_vs_R0(N, k_values, p, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    \"\"\"This function generates a list for combinations of beta and gamma \n",
    "    values based on a supplied list of gamma and R0 values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    plot_ws_k_sweep(N, k_values, p, beta_values, gamma_values, I0, t_span, num_runs)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "N = 200\n",
    "k_values = np.arange(2, 22, 2)\n",
    "p = 0.1 # Rewiring probability is fixed for now\n",
    "R0_values = [0.5, 1.0, 2.5] \n",
    "gamma_values = [0.1, 0.2, 0.2]\n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "ws_k_vs_R0(N, k_values, p, I0, t_span, num_runs, R0_values, gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e2adb",
   "metadata": {},
   "source": [
    "## 3. Erdos-Renyi (Finished)\n",
    "The specified library NetworkX uses an Erdos-Renyi network model G(n,p) that generates a random graph by connecting nodes with edges. According to a parameter p, each specific edge is included into the graph. A higher p means a higher number of edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2602b4a",
   "metadata": {},
   "source": [
    "### 3.1 Erdos-Renyi Network\n",
    "With the help of the NetworkX library a random graph using the ER G(n,p) method of attaching nodes is created. By supplying the graph to the Network Diffusion Library (NDlib), a SIR model is created through setting up the appropriate parameters through functions supplied by the Configuration class of NDLib. The model is iterated t_span amount of times, after which the appropriate data is returned. To create a ER network, we supply the variable p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6b0b3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished\n",
    "def erdos_renyi(N, p, beta, gamma, I0, t_span):\n",
    "    \"\"\" \n",
    "    This function generates a ER network model. \n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes.\n",
    "        p: Probability for edge creation \n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Initial number of infected nodes.\n",
    "        t_span: Number of iterations to execute the model.\n",
    "\n",
    "    Returns:\n",
    "        Lists for the number of iterations generated by the model and \n",
    "        data concerning the S, I and R populations of each iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    er_graph = nx.erdos_renyi_graph(N, p)\n",
    "    model = ep.SIRModel(er_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", I0)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "\n",
    "    y_data = [] \n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:\n",
    "                S_count += 1\n",
    "            elif state == 1:\n",
    "                I_count += 1\n",
    "            elif state == 2: \n",
    "                R_count += 1\n",
    "\n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16538ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 \n",
    "p = 0.01  # Probability for edge creation\n",
    "t_span = 200\n",
    "\n",
    "results = erdos_renyi(N, p, beta, gamma, I0, t_span)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c9084",
   "metadata": {},
   "source": [
    "### 3.2 Erdos-Reyni Network Parameter Sweep\n",
    "As with the BA and WS networks, a parameter sweep for network specific parameters was performed. Parameters were changed for p and R0. The sweeps were set up similarly to the other network sweeps. Again, lists of the maximum mean and standard deviations of the number of infected nodes is generated and can subsequently be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8f0b276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finished\n",
    "def er_p_sweep(N, p_values, beta, gamma, I0, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Generates a ER network for different values of p and finds the mean \n",
    "    maximum and standard deviation of the number of infected nodes per \n",
    "    run.\n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes\n",
    "        p_values: List of p values.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Percentage of initially infected nodes.\n",
    "        t_span: Number of iterations inside BA network.\n",
    "        num_runs: Number of iterations of BA network.\n",
    "\n",
    "    Returns:\n",
    "        A list of maximum mean and standard deviations of the number of \n",
    "        infected nodes per run.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_max_values = []  \n",
    "    std_max_values = []   \n",
    "\n",
    "    for p in p_values:\n",
    "        max_I_values = []  \n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = erdos_renyi(N, p, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "     \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values  \n",
    "\n",
    "\n",
    "#Finished\n",
    "def plot_er_prob_sweep(N, p_values, beta_values, gamma_values, I0, t_span, \n",
    "                       num_runs):\n",
    "    \"\"\"\"Visualizes data for the parameter sweeps of the ER network.\"\"\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        mean_max_values, std_max_values = er_p_sweep(N, p_values, beta, gamma, \n",
    "                                                     I0, t_span, num_runs)\n",
    "        \n",
    "        R0 = beta / gamma\n",
    "        label = f'R₀ = {R0:.1f} (β = {beta:.1f}, γ = {gamma:.1f})'\n",
    "        \n",
    "    plt.errorbar(p_values, mean_max_values, yerr=std_max_values, fmt='-o', \n",
    "                 capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Probability p\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\n",
    "        \"Mean Maximum Infected Nodes vs Probability for Different\" \n",
    "        \"R₀ Values\"\n",
    "        )\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Finished\n",
    "def er_prob_vs_R0(N, p_values, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    \"\"\"This function generates a list for combinations of beta and gamma \n",
    "    values based on a supplied list of gamma and R0 values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    plot_er_prob_sweep(N, p_values, beta_values, gamma_values, I0, t_span, \n",
    "                       num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aaad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "p_values = np.linspace(0.01, 0.1, 10)  \n",
    "R0_values = [0.5, 1.0, 2.5]  \n",
    "gamma_values = [0.1, 0.2, 0.2]  \n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "er_prob_vs_R0(N, p_values, I0, t_span, num_runs, R0_values, gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9b3f5",
   "metadata": {},
   "source": [
    "## 4. Generating Networks and Examining Network Statistics (MARVIN)\n",
    "\n",
    "TODO MARVIN explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d2d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished\n",
    "def gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "    \"\"\"\n",
    "    Generate networks of specified types and calculate degree statistics \n",
    "    and clustering coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        nettype: Network type to generate.\n",
    "        N: Number of nodes in the network.\n",
    "        m_vals: List of m values for BA networks.\n",
    "        p_vals: List of p values for ER networks.\n",
    "        r_vals: List of r values for WS networks, normally defined as p.\n",
    "        num_runs: Number of iterations for network generation.\n",
    "        k: Predifined k for WS networks.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing minimum and maximum mean and standard \n",
    "        deviation values for the degrees and clustering coefficients for \n",
    "        each m/p/r value.\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_min_degrees = []\n",
    "    std_min_degrees = []\n",
    "    \n",
    "    mean_max_degrees = []\n",
    "    std_max_degrees = []\n",
    "    \n",
    "    mean_degrees = []\n",
    "    std_degrees = []\n",
    "    \n",
    "    mean_clustering_coeffs = []  \n",
    "    std_clustering_coeffs = []    \n",
    "\n",
    "    if nettype == 'BA':\n",
    "        for m in m_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                ba_net = nx.barabasi_albert_graph(N, m)\n",
    "                \n",
    "                degrees = [deg for _, deg in ba_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(ba_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "\n",
    "    elif nettype == 'ER':   \n",
    "        mean_min_degrees = []\n",
    "        std_min_degrees = []\n",
    "        \n",
    "        mean_max_degrees = []\n",
    "        std_max_degrees = []\n",
    "        \n",
    "        mean_degrees = []\n",
    "        std_degrees = []\n",
    "        \n",
    "        mean_clustering_coeffs = []  \n",
    "        std_clustering_coeffs = []    \n",
    "\n",
    "        for p in p_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                er_net = nx.erdos_renyi_graph(N, p)\n",
    "                \n",
    "                degrees = [deg for _, deg in er_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(er_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "    \n",
    "    elif nettype == 'WS':\n",
    "        mean_min_degrees = []\n",
    "        std_min_degrees = []\n",
    "        \n",
    "        mean_max_degrees = []\n",
    "        std_max_degrees = []\n",
    "        \n",
    "        mean_degrees = []\n",
    "        std_degrees = []\n",
    "        \n",
    "        mean_clustering_coeffs = []  \n",
    "        std_clustering_coeffs = []    \n",
    "\n",
    "        for r in r_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                ws_net = nx.watts_strogatz_graph(N, k, r)\n",
    "                \n",
    "                degrees = [deg for _, deg in ws_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(ws_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "            \n",
    "    return {\n",
    "        'mean_min_degrees': mean_min_degrees,\n",
    "        'std_min_degrees': std_min_degrees,\n",
    "        'mean_max_degrees': mean_max_degrees,\n",
    "        'std_max_degrees': std_max_degrees,\n",
    "        'mean_degrees': mean_degrees,\n",
    "        'std_degrees': std_degrees,\n",
    "        'mean_clustering_coeffs': mean_clustering_coeffs,  \n",
    "        'std_clustering_coeffs': std_clustering_coeffs      \n",
    "    }\n",
    "\n",
    "\n",
    "#Finished\n",
    "def plot_degree_stats(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "    \"\"\"\n",
    "    Plot degree statistics for generated networks of specified types.\n",
    "\n",
    "    Parameters:\n",
    "        nettype: Network type to generate.\n",
    "        N: Number of nodes in the network.\n",
    "        m_vals: List of m values for BA networks.\n",
    "        p_vals: List of p values for ER networks.\n",
    "        r_vals: List of r values for WS networks, normally defined as p.\n",
    "        num_runs: Number of iterations for network generation.\n",
    "        k: Predifined k for WS networks.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    results = gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5)\n",
    "    \n",
    "    mean_min_degrees = results['mean_min_degrees']\n",
    "    std_min_degrees = results['std_min_degrees']\n",
    "    mean_max_degrees = results['mean_max_degrees']\n",
    "    std_max_degrees = results['std_max_degrees']\n",
    "    mean_degrees = results['mean_degrees']\n",
    "    std_degrees = results['std_degrees']\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    if nettype == 'BA':\n",
    "        plt.errorbar(m_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(m_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(m_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, \n",
    "                     label='Mean Degree', color='red')\n",
    "\n",
    "        plt.xlabel(\"m (Number of edges to attach from a new node)\")\n",
    "        plt.title(\n",
    "            \"Mean Min, Max, and Overall Degree vs m in Barabási–Albert\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "        \n",
    "    elif nettype == 'ER':\n",
    "        plt.errorbar(p_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(p_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(p_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, \n",
    "                     label='Mean Degree', color='red')\n",
    "\n",
    "        plt.xlabel(\"p (Probability of connecting two edges)\")\n",
    "        plt.title(\n",
    "            \"Mean Min, Max, and Overall Degree vs p in Erdös–Renyi\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "\n",
    "    elif nettype == 'WS':\n",
    "        plt.errorbar(r_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(r_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(r_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, \n",
    "                     label='Mean Degree', color='red')\n",
    "\n",
    "        plt.xlabel(\"r (Probability of rewiring an exisint edge)\")\n",
    "        plt.title(\n",
    "            \"Mean Min, Max, and Overall Degree vs r in Watts-Strogatz\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "\n",
    "    plt.ylabel(\"Degree\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Finished\n",
    "def plot_clustering_stats(nettype, N, m_vals, p_vals, r_vals, num_runs, \n",
    "                          k=5):\n",
    "    \"\"\"\n",
    "    Plot clustering coefficient statistics for generated networks of \n",
    "    specified types.\n",
    "\n",
    "    Parameters:\n",
    "        nettype: Network type to generate.\n",
    "        N: Number of nodes in the network.\n",
    "        m_vals: List of m values for BA networks.\n",
    "        p_vals: List of p values for ER networks.\n",
    "        r_vals: List of r values for WS networks, normally defined as p.\n",
    "        num_runs: Number of iterations for network generation.\n",
    "        k: Predifined k for WS networks.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5)\n",
    "    mean_clus_c = results['mean_clustering_coeffs']\n",
    "    std_clus_c = results['std_clustering_coeffs']\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    if nettype == 'BA':\n",
    "        plt.xlabel(\"m (Number of edges to attach from a new node)\")\n",
    "        plt.title(\n",
    "            \"Mean Clustering Coefficient vs m in Barabási–Albert\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(m_vals))  \n",
    "        plt.bar(bar_positions, mean_clus_c, yerr=std_clus_c, width=bar_width, \n",
    "                alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, m_vals)  \n",
    "    \n",
    "    elif nettype == 'ER':\n",
    "        plt.xlabel(\"p (Probability of connecting two edges)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs p in Erdös-Renyi Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(p_vals))  \n",
    "        plt.bar(bar_positions, mean_clus_c, yerr=std_clus_c, width=bar_width, \n",
    "                alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, np.round(p_vals, 2)) \n",
    "\n",
    "    elif nettype == 'WS':\n",
    "        plt.xlabel(\"r (Probability of rewiring an exising edge)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs r in Watts-Strogatz Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(r_vals))  \n",
    "        plt.bar(bar_positions, mean_clus_c, yerr=std_clus_c, width=bar_width, \n",
    "                alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, np.round(r_vals, 1)) \n",
    "\n",
    "    plt.ylabel(\"Clustering Coefficient\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "# NOTe FRED: same for sweeps\n",
    "m_vals = np.arange(2, 23, 2)\n",
    "p_vals = np.linspace(0.01, 0.1, 10)\n",
    "r_vals = np.linspace(0.1, 0.9, 10)\n",
    "num_runs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbc8e5",
   "metadata": {},
   "source": [
    "### 4.1 BA Network Results\n",
    "Below the functions for plotting the degree and clustering statistics of the BA network models are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('BA', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('BA', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb06c7",
   "metadata": {},
   "source": [
    "### 4.2 ER Network Results\n",
    "Below the functions for plotting the degree and clustering statistics of the ER network models are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('ER', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('ER', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec243d",
   "metadata": {},
   "source": [
    "### 4.3 WS Network Results\n",
    "Below the functions for plotting the degree and clustering statistics of the WS network models are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4937de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('WS', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('WS', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaa77d",
   "metadata": {},
   "source": [
    "## 5. Dynamic Vaccination Campaign\n",
    "A network containing predetermined node and edge structure was provided to be modelled in a SIR system and to which a vaccination strategy was to be applied. To ascertain the effectiveness of the strategy, we first designed a random null strategy. The null strategy should then be outperformed by the designed strategy. \n",
    "\n",
    "Within each strategy, it is predetermined that we do not know the status of each node until a node is tested. The status a node can have is either 0 (susceptible), 1 (infected) or 2 (removed). Only susceptible nodes can be vaccinated.\n",
    "\n",
    "Certain limitations are set upon the strategy. There are a limited number of tests (200) and We can only test a specific (although not further specified) number of nodes per iteration of the SIR model. However, tests can have an accuracy rating from 0.25 ton 1.0. An inaccurate test will return a node's status as '1' when it is '0' and vice versa. We assume that recovered nodes always return the correct status. Per iteration, it is also possible to vaccinate a limited amount of susceptible people and their status is changed to removed immediately and indefinitely. \n",
    "\n",
    "\n",
    "To Do:\n",
    "1. load in sociopatterns dataset (NDlib and network X)\n",
    "    If i open the data in excel, the data structure is such that the first row and column signify the nodes. nodes from 1 to 374. All cells in between signify if there is an edge between the nodes. if the number is > 0 it means there is an edge, we can negate how high since that is the weight which we are not looking at right now (identity matrix)\n",
    "\n",
    "    1 means infected, 0 means susceptible, 2 means recovered\n",
    "\n",
    "    In NDlib 'Recovered' is 'Removed'\n",
    "\n",
    "2. can we test and vaccinate at the same iteration or not\n",
    "    we assume we can!\n",
    "\n",
    "3. visualize the data\n",
    "\n",
    "4. Add test accuracy!\n",
    "\n",
    "5. we think people infected, they maynot be, dont put their status to 2, if 1 not into 2\n",
    "\n",
    "\"but you can only discover the disease status of a node after a test\"\n",
    "test can show antibodies\n",
    "\n",
    "'status' is something i added to the nodes of known_graph and are not inherently in graph, to access the node statuses of the graph, access the status through model instead!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd344a4",
   "metadata": {},
   "source": [
    "### 5.1 Loading and Initializing the dataset\n",
    "First, the provided dataset is loaded correctly and initialised using the corresponding NDLib and NetworkX libraries. Edges between nodes from the dataset were generated per node. Two graphs were generated, one containg the 'true' graph data and one graph signifying the data that we know since we can only assume a node status after testing but we need the actual data for running an accurate simulation. To keep the distinction clear, we generated two graphs. To the known graph, the 'status' opf a node was added to each node such that their data is accesible. All the nodes in the 'known graph' are first set to 0 (susceptible), assuming that every node we have not tested and/or vaccinated yet is susceptible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finished\n",
    "def load_sociopatterns():\n",
    "    \"\"\"\n",
    "    Loads and initiates the csv file containing sociopattern information.\n",
    "    Initiates two graphs, one for actual data and one simulating what we\n",
    "    know about the data. \n",
    "    \"\"\"\n",
    "\n",
    "    edge_list = pd.read_csv(\"transmission_network.csv\", delimiter=';', \n",
    "                            index_col=0)\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    graph_known = nx.Graph()\n",
    "\n",
    "    graph.add_nodes_from(edge_list.index.tolist())\n",
    "    graph_known.add_nodes_from(edge_list.index.tolist())\n",
    "\n",
    "    # Adds edges between nodes if their weight is higher than 0\n",
    "    for node_i, row in edge_list.iterrows():\n",
    "        for node_j, value in row.items():\n",
    "            if value > 0:\n",
    "                graph.add_edge(int(node_i), int(node_j))\n",
    "                graph_known.add_edge(int(node_i), int(node_j))\n",
    "\n",
    "    return graph, graph_known\n",
    "    \n",
    "\n",
    "#finished\n",
    "def initiate_model(graph, graph_known, beta, gamma):\n",
    "    \"\"\"\" \n",
    "    Initiates SIR model on the graph (real world) and sets the status of \n",
    "    the known graph to everybody as susceptible.\n",
    "    \"\"\"\n",
    "\n",
    "    model = ep.SIRModel(graph)\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "\n",
    "    # Initiates states for all nodes in the known graph to susceptible\n",
    "    for node in graph_known.nodes:\n",
    "        graph_known.nodes[node]['status'] = 0\n",
    "\n",
    "    # Randomly assigns 5 nodes to get infected\n",
    "    infected = 5\n",
    "    infected_nodes = (np.random.choice(graph.nodes(), size=infected, \n",
    "                                       replace=False)).tolist()\n",
    "    config.add_model_initial_configuration('Infected', infected_nodes)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    return model, graph_known\n",
    "\n",
    "\n",
    "#finished\n",
    "def update_sir_model(model, graph, iterations):\n",
    "    \"\"\"\n",
    "    Runs the SIR model for a number of times as specified by itertations.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.iteration_bunch(iterations) \n",
    "\n",
    "    return model, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a91a9",
   "metadata": {},
   "source": [
    "### 5.2 Random Null Strategy\n",
    "To evaluate our vaccination strategy, we had to implement a null strategy to compare our results with. Rather than designing a completely random stratregy, we introduced some intelligence to the strategy to simulate how a random strategy might work in real life rather than something drastically unrealistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffacba",
   "metadata": {},
   "source": [
    "First nodes are tested by generating a list that contains all known suscpetible nodes. Note from a previous statement that we assume all nodes initially as suscpetible. If there are less susceptible nodes availble then the number of tests to perform, we reset the number of tests.\n",
    "\n",
    "From the list of available nodes we randomly choose a number of nodes equivalent to the number of tests that we perform that iteration. \n",
    "\n",
    "The status of the node is retrieved from the SIRmodel class. A provided list containing the accuracy as [chance correct, chance incorrect] determines the accuracy of the tests. A status tested as '1' may therefore be shown as '0' and vice versa. The status in the known_graph will then be updated to this incorrect result and treat it as correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finished\n",
    "def test_nodes_random(model, graph_known, tests, vac_pool, accuracy):\n",
    "    \"\"\"\n",
    "    Tests the status of randomly selected susceptible nodes, updates \n",
    "    their status accordingly and adds or removes nodes from the \n",
    "    vaccination pool.\n",
    "    \n",
    "    Arguments:\n",
    "        model:\n",
    "        graph_known:\n",
    "        tests:\n",
    "        vac_pool:\n",
    "        accuracy:\n",
    "        \n",
    "    Returns\n",
    "        Updated graph_known, the vaccination pool and number of tests \n",
    "        used in this iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    available_nodes = [] \n",
    "\n",
    "    # Adds people that are susceptible to a list of available nodes.\n",
    "    for node in graph_known.nodes:\n",
    "        if graph_known.nodes[node]['status'] == 0:\n",
    "            available_nodes.append(node)\n",
    "    \n",
    "    # Resets the number of tests if there are not enough available nodes.\n",
    "    if len(available_nodes) < tests:\n",
    "        tests = len(available_nodes)\n",
    "\n",
    "        # Returns the function if there are no more available nodes\n",
    "        if tests == 0:\n",
    "            return graph_known, vac_pool, tests\n",
    "\n",
    "    tested_nodes = (np.random.choice(available_nodes, size=tests, \n",
    "                                     replace=False)).tolist()\n",
    "\n",
    "    # Updates the status of the tested nodes on the known graph\n",
    "    for node in tested_nodes:\n",
    "        status = model.status[node]\n",
    "\n",
    "        if status == 0:\n",
    "            status = np.random.choice([status, 1], p=accuracy)\n",
    "        elif status == 1:\n",
    "            status = np.random.choice([status, 0], p=accuracy)\n",
    "            \n",
    "        graph_known.nodes[node]['status'] = status\n",
    "\n",
    "        # Adds to or removes nodes from the vaccination pool.\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "\n",
    "        elif status != 0 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "\n",
    "    return graph_known, vac_pool, tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf49d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf979ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finished\n",
    "def vac_nodes_random(model, graph_known, vac_budget, vac_pool):\n",
    "    \"\"\"Vaccinates nodes randomly according to a supplied list of a pool \n",
    "    of vaccination candidates. Updates statuses accordingly. If a node \n",
    "    status is not actually susceptible, their status is not changed.\n",
    "    \n",
    "    Arguments:\n",
    "        model:\n",
    "        graph_known:\n",
    "        vac_budget:\n",
    "        vac_pool:\n",
    "        \n",
    "    Returns:\n",
    "        The updated model with correct statuses, graph_known with assumed \n",
    "        statuses and vac_pool from which vacinated nodes are removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # If there are not enough Susceptible people, reset the vaccination budget.\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    # Randomly choose susceptible people to vaccinate\n",
    "    vac_nodes = (np.random.choice(vac_pool, size=vac_budget, \n",
    "                                  replace=False)).tolist()\n",
    "\n",
    "    # Update all statuses of vaccinated nodes to 'Removed' if possible.\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated from the vaccination pool.\n",
    "        vac_pool = [node for node in vac_pool if node not in vac_nodes]\n",
    "\n",
    "    return model, graph_known, vac_pool\n",
    "\n",
    "\n",
    "def random_campaign(test_max, beta, gamma, t_span):\n",
    "    \"\"\"Runs the random network model null simulation for a number of \n",
    "    iterations as specified by t_span and stores data for later \n",
    "    visualization. \n",
    "\n",
    "    Arguments:\n",
    "        model:\n",
    "        graph_known:\n",
    "        vac_budget:\n",
    "        vac_pool:\n",
    "\n",
    "    Returns:\n",
    "        The generated results as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "    vac_budget = 5\n",
    "    accuracy = [0.75, 0.25]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    # Tests, vaccinates and riterates the SIR Model.\n",
    "    while t <= t_span:\n",
    "\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, tests = test_nodes_random(model, graph_known, \n",
    "                                                             test_max, vac_pool, accuracy)\n",
    "            \n",
    "            # Updates the total number of tests left.\n",
    "            total_tests -= tests\n",
    "            \n",
    "        model, graph_known, vac_pool = vac_nodes_random(model, graph_known, \n",
    "                                                        vac_budget, vac_pool)\n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        # Stores the current states of the model.\n",
    "        infected_count = sum(1 for node in model.status if model.status[node] == 1)\n",
    "        susceptible_count = sum(1 for node in model.status if model.status[node] == 0)\n",
    "        removed_count = sum(1 for node in model.status if model.status[node] == 2)\n",
    "\n",
    "        results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "        })\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "#Finished\n",
    "def simulate_random_campaign(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"Simulates the random campaign to generate the maximum values for \n",
    "    the number of infected and calculates the mean and standard \n",
    "    deviations.\n",
    "    \"\"\"\n",
    "\n",
    "    max_I_vals = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        results = random_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_counts = [entry['infected'] for entry in results]\n",
    "        max_I = max(infected_counts)\n",
    "        max_I_vals.append(max_I)\n",
    "    \n",
    "    mean_max_I = np.mean(max_I_vals)\n",
    "    std_max_I = np.std(max_I_vals)\n",
    "\n",
    "    return max_I_vals, mean_max_I, std_max_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 5\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 10\n",
    "num_runs = 5\n",
    "\n",
    "simulate_random_campaign(test_max, beta, gamma, t_span, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f7f44",
   "metadata": {},
   "source": [
    "### 5.2 Vaccinating Largest Hubs First Strategy\n",
    "\n",
    "TODO MARVIN explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f8834eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_nodes():\n",
    "    \"\"\"\n",
    "    Returns a list of nodes sorted from high to low degrees.\n",
    "    \"\"\"\n",
    "   \n",
    "    graph, _ = load_sociopatterns()\n",
    "    nodes = [(node, graph.degree(node)) for node in graph]\n",
    "    sorted_nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_nodes\n",
    "    \n",
    "\n",
    "def test_hubs(model, graph_known, tests, vac_pool):\n",
    "    \"\"\"Tests if a node is infected. Should only test people you know are \n",
    "    not currently removed or infected.\"\"\"\n",
    "\n",
    "    sorted_nodes = sort_nodes()\n",
    "    available_nodes = []\n",
    "    accuracy = [0.75, 0.25] \n",
    "  \n",
    "    # Adds people that are susceptible to available nodes\n",
    "    for node in graph_known.nodes:\n",
    "        if graph_known.nodes[node]['status'] == 0:\n",
    "            available_nodes.append(node)\n",
    "\n",
    "    # Resets number of tests if there are not enough available nodes\n",
    "    if len(available_nodes) == 0:\n",
    "        return\n",
    "    \n",
    "    elif len(available_nodes) < tests:\n",
    "        tests = available_nodes\n",
    "    \n",
    "    top_nodes = [node for node, _ in sorted_nodes if node in \n",
    "                 available_nodes][:tests]\n",
    "    \n",
    "    for node in top_nodes:\n",
    "        status = model.status[node]\n",
    "\n",
    "        if status == 0:\n",
    "            status = np.random.choice([status, 1], p=accuracy)\n",
    "        elif status == 1:\n",
    "            status = np.random.choice([status, 0], p=accuracy)\n",
    "            \n",
    "        graph_known.nodes[node]['status'] = status\n",
    "\n",
    "        # Adds to susceptible vaccination pool if the node is susceptible\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "\n",
    "        elif status != 0 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "\n",
    "    return graph_known, vac_pool, tests\n",
    "\n",
    "\n",
    "def vac_hubs(model, graph_known, vac_budget, vac_pool):\n",
    "    \"\"\"Vaccinate largest (susceptible) hubs.\"\"\"\n",
    "\n",
    "    # If there are not enough Susceptible people, reset the vaccination budget\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    # Choose largest susceptible hubs\n",
    "    vac_nodes = vac_pool[0:vac_budget + 1]\n",
    "\n",
    "    # Update all statuses of vaccinated nodes to 'Removed'\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        # Can only remove people who are not currently infected or removed\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated from vaccination pool\n",
    "        vac_pool = [node for node in vac_pool if node not in vac_nodes]\n",
    "\n",
    "    return model, graph_known, vac_pool\n",
    "\n",
    "\n",
    "def hub_campaign(test_max, beta, gamma, t_span):\n",
    "    \"\"\"\n",
    "    Runs the random network model null simulation. \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "    results = []\n",
    "    vac_budget = 5\n",
    "\n",
    "    # Loads and initializes all data, makes graph of known statuses \n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    # Tests, vaccinates and runs sir for t_span amount of iterations\n",
    "    while t <= t_span:\n",
    "\n",
    "        # Can only perform tests if there are tests left in the test budget\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, tests = test_hubs(model, graph_known, \n",
    "                                                     test_max, vac_pool)\n",
    "            total_tests -= tests\n",
    "            \n",
    "        model, graph_known, vac_pool = vac_hubs(model, graph_known, \n",
    "                                                vac_budget, vac_pool)\n",
    "        \n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        # Store the current state of the model\n",
    "        infected_count = sum(1 for node in model.status if model.status[node] == 1)\n",
    "        susceptible_count = sum(1 for node in model.status if model.status[node] == 0)\n",
    "        removed_count = sum(1 for node in model.status if model.status[node] == 2)\n",
    "\n",
    "        # Append results for the current time step\n",
    "        results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "        })\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def simulate_hub_campaign(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    max_I_vals = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "\n",
    "        results = hub_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_counts = [entry['infected'] for entry in results]\n",
    "        max_I = max(infected_counts)\n",
    "        max_I_vals.append(max_I)\n",
    "    \n",
    "    mean_max_I = np.mean(max_I_vals)\n",
    "    std_max_I = np.std(max_I_vals)\n",
    "\n",
    "    return max_I_vals, mean_max_I, std_max_I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b290b07",
   "metadata": {},
   "source": [
    "### 5.3 Vaccination Campaign Results (Including T-Test)\n",
    "\n",
    "TODO EXPLAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c004a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_campaign_results(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Plots the mean maximum infected counts for both random and hub \n",
    "    campaigns with their standard deviations.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, mean_max_random, std_max_random = simulate_random_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    _, mean_max_hub, std_max_hub = simulate_hub_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "    x_labels = ['Random', 'Hub']  \n",
    "    means = [mean_max_random, mean_max_hub]  \n",
    "    std_devs = [std_max_random, std_max_hub]  \n",
    "    \n",
    "    plt.errorbar(x=np.arange(len(means)), y=means, yerr=std_devs, fmt='o', \n",
    "                 capsize=5, color='blue', alpha=0.7, label='Mean Max Infected Counts')\n",
    "    \n",
    "    plt.xticks(np.arange(len(x_labels)), x_labels)  # Set x-tick labels\n",
    "    plt.title('Mean Maximum Infected Counts with Standard Deviation')\n",
    "    plt.ylabel('Count of Infected Individuals')\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()  # Adjust layout to make room for labels\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def t_test(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    max_vals_random, _, _ = simulate_random_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    max_vals_hub, _, _ = simulate_hub_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(max_vals_random, max_vals_hub)\n",
    "\n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_span = 100\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "test_max = 10\n",
    "vac_budget = 5\n",
    "test_accuracy = 1.0\n",
    "num_runs = 10\n",
    "\n",
    "show_campaign_results(test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "t_stat, p_val = t_test(test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebd926",
   "metadata": {},
   "source": [
    "### 5.4 Highest Score First Strategy\n",
    "\n",
    "TODO fred explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc49bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_closeness(graph):\n",
    "    \"\"\".\"\"\"\n",
    "    # Closeness centrality\n",
    "    # How close node to all other nodes\n",
    "    closeness = nx.closeness_centrality(graph)\n",
    "    sort_clo = sorted(closeness.items(), key=lambda x: x[1], reverse=True)\n",
    "    clo_scores = assign_scores(sort_clo)\n",
    "\n",
    "    return clo_scores\n",
    "\n",
    "\n",
    "def calc_betweenness(graph):\n",
    "    \"\"\".\"\"\"\n",
    "    # betweenness\n",
    "    # Node on path of other nodes\n",
    "    betweenness = nx.betweenness_centrality(graph)\n",
    "    sort_bet = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "    bet_scores = assign_scores(sort_bet)\n",
    "\n",
    "    return bet_scores\n",
    "\n",
    "\n",
    "def calc_adjecency(graph):\n",
    "    \"\"\".\"\"\"\n",
    "    # How many neighbors\n",
    "    adjecency = dict(graph.degree())\n",
    "    sort_adj = sorted(adjecency.items(), key=lambda x: x[1], reverse=True)\n",
    "    adj_scores = assign_scores(sort_adj)\n",
    "    \n",
    "    return adj_scores\n",
    "\n",
    "\n",
    "def assign_scores(sortedlist):\n",
    "    \"\"\".\"\"\"\n",
    "    # assigns scores to nodes on a list based on their maximum value (scaled)\n",
    "    # Top list get top scores\n",
    "\n",
    "    value_max = sortedlist[0][1]\n",
    "    score_dict = {}\n",
    "\n",
    "    for node, score in sortedlist:\n",
    "        score_dict[node] = np.round((score/value_max), 4)\n",
    "    \n",
    "    return score_dict\n",
    "\n",
    "\n",
    "def calc_total_scores(graph):\n",
    "    \"\"\".\"\"\"\n",
    "    # Calculates total scores\n",
    "    score_adj = calc_adjecency(graph)\n",
    "    score_bet = calc_betweenness(graph)\n",
    "    score_clo = calc_closeness(graph)\n",
    "    score_total = {}\n",
    "    \n",
    "    for node in score_adj:\n",
    "        score_total[node] = np.round(score_adj[node] + score_bet.get(node, 0) + score_clo.get(node, 0), 4)\n",
    "\n",
    "    sorted_scores = dict(sorted(score_total.items(), key=lambda x: x[1], reverse=True))\n",
    "     \n",
    "    return sorted_scores\n",
    "\n",
    "\n",
    "def test_nodes_score(tests, scores, graph_known, model, vac_pool, infected, accuracy):\n",
    "    \"\"\"Tests if a node is infected. Should only test people you know are \n",
    "    not currently removed or infected.\"\"\"\n",
    "\n",
    "    test_nodes = []\n",
    "    tested_nodes = []\n",
    "\n",
    "    for node, _ in scores.items():\n",
    "        # find neighbors of known infected add to list\n",
    "        if graph_known.nodes[node]['status'] == 1:\n",
    "            neighbors_list = [n for n in graph_known.neighbors(node) \n",
    "                              if graph_known.nodes[n]['status'] == 0]\n",
    "            \n",
    "            for n in neighbors_list:\n",
    "                if n not in test_nodes:\n",
    "                    test_nodes.append(n)\n",
    "                \n",
    "                # Scores get updated based on infected neighbor (only once per infection)\n",
    "                if node in infected:\n",
    "                    scores[n] += scores[node]\n",
    "\n",
    "            # Remove an infected node from this list after all neighbors' scores have been updated\n",
    "            if node in infected: \n",
    "                infected.remove(node)\n",
    "\n",
    "        # Add susceptible known to list\n",
    "        elif graph_known.nodes[node]['status'] == 0:\n",
    "            test_nodes.append(node)\n",
    "\n",
    "    # Sorts the nodes to test based on their score\n",
    "    test_nodes = sorted(test_nodes, key=lambda x: scores.get(x, 0), reverse=True)\n",
    "\n",
    "    for node in test_nodes[:tests]:\n",
    "        status = model.status[node]\n",
    "\n",
    "        # Status may change according to the test accuracy \n",
    "        if status == 0:\n",
    "            status = np.random.choice([status, 1], p=accuracy)\n",
    "        elif status == 1:\n",
    "            status = np.random.choice([status, 0], p=accuracy)\n",
    "            \n",
    "        graph_known.nodes[node]['status'] = status\n",
    "        tested_nodes.append(node)\n",
    "\n",
    "        # Add or remove nodes to their corresponding list\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "        elif status == 1 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "            infected.append(node)\n",
    "        elif status == 2 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "    \n",
    "    #sort the vac_pool based on their score \n",
    "    vac_pool = sorted(vac_pool, key=lambda x: scores.get(x, 0), reverse=True)\n",
    "\n",
    "    return graph_known, vac_pool, tested_nodes, infected\n",
    "\n",
    "\n",
    "#Remove function later\n",
    "def show_status(model, graph_known, vaccinated_nodes, tested_nodes):\n",
    "    # 1. Known counts for infected, removed, and susceptible\n",
    "    known_infected = sum(1 for node in graph_known.nodes if graph_known.nodes[node]['status'] == 1)\n",
    "    known_removed = sum(1 for node in graph_known.nodes if graph_known.nodes[node]['status'] == 2)\n",
    "    known_susceptible = sum(1 for node in graph_known.nodes if graph_known.nodes[node]['status'] == 0)\n",
    "    \n",
    "    print(f\"Known - Infected: {known_infected}, Removed: {known_removed}, Susceptible: {known_susceptible}\")\n",
    "    \n",
    "    # 2. Actual counts from the model for infected, removed, and susceptible\n",
    "    actual_infected = sum(1 for node in model.status if model.status[node] == 1)\n",
    "    actual_removed = sum(1 for node in model.status if model.status[node] == 2)\n",
    "    actual_susceptible = sum(1 for node in model.status if model.status[node] == 0)\n",
    "    \n",
    "    print(f\"Actual - Infected: {actual_infected}, Removed: {actual_removed}, Susceptible: {actual_susceptible}\")\n",
    "    \n",
    "    # 3. Vaccinated count this round\n",
    "    print(f\"Vaccinated this round: {len(vaccinated_nodes)}\")\n",
    "    \n",
    "    # 4. Tested count this round\n",
    "    print(f\"Tested this round: {len(tested_nodes)}\")  \n",
    "    return\n",
    "\n",
    "\n",
    "def vac_nodes_score(model, graph_known, vac_budget, vac_pool, scores):\n",
    "    \"\"\". Only vacc sus people that you know of.\"\"\"\n",
    "    vaccinated = []\n",
    "\n",
    "    # If there are not enough Susceptible people, reset the vaccination budget\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        add_to_pool = vac_budget - len(vac_pool)\n",
    "\n",
    "        candidates = [node for node in graph_known.nodes \n",
    "                      if graph_known.nodes[node]['status'] == 0 \n",
    "                      and node not in vac_pool]\n",
    "        sorted_c = sorted(candidates, key=lambda x: scores.get(x, 0), reverse=True)\n",
    "\n",
    "        for c in sorted_c[:add_to_pool]:\n",
    "            vac_pool.append(c)\n",
    "\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    # Choose largest susceptible hubs\n",
    "    #To Marvin: you had a +1 but you vaccinated an extra person like that?\n",
    "    vac_nodes = vac_pool[0:vac_budget]\n",
    "\n",
    "    # Update all statuses of vaccinated nodes to 'Removed'\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        # Can only remove people who are not currently infected or removed\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated from vaccination pool\n",
    "        vac_pool.remove(node)\n",
    "        vaccinated.append(node)\n",
    "\n",
    "    return model, graph_known, vac_pool, vaccinated\n",
    "\n",
    "\n",
    "def score_campaign(test_max, beta, gamma, t_span):\n",
    "    \"\"\"\n",
    "    Runs the random network model null simulation. \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "    vac_budget = 5\n",
    "    accuracy = [0.75, 0.25]\n",
    "    infected = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Loads and initializes all data, makes a graph of the known statuses.\n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    # Assign scores to nodes based on adjecency, betweenness and closeness.\n",
    "    scores_dict = calc_total_scores(graph)\n",
    "\n",
    "    while t <= t_span:\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, tested_nodes, infected = test_nodes_score(test_max, scores_dict, graph_known, model, vac_pool, infected, accuracy)\n",
    "            \n",
    "        model, graph_known, vac_pool, vaccinated = vac_nodes_score(model, graph_known, vac_budget, vac_pool, scores_dict)\n",
    "        #show_status(model, graph_known, vaccinated, tested_nodes)\n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        total_tests -= test_max\n",
    "\n",
    "        # Reset tests per iteration if the budget is too small.\n",
    "        if total_tests < test_max:\n",
    "            test_max = total_tests\n",
    "\n",
    "        # Store the current state of the model\n",
    "        infected_count = sum(1 for node in model.status if model.status[node] == 1)\n",
    "        susceptible_count = sum(1 for node in model.status if model.status[node] == 0)\n",
    "        removed_count = sum(1 for node in model.status if model.status[node] == 2)\n",
    "\n",
    "        # Append results for the current time step\n",
    "        results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "        })\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def simulate_score_campaign(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    max_I_vals = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "\n",
    "        results = score_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_counts = [entry['infected'] for entry in results]\n",
    "        max_I = max(infected_counts)\n",
    "        max_I_vals.append(max_I)\n",
    "    \n",
    "    mean_max_I = np.mean(max_I_vals)\n",
    "    std_max_I = np.std(max_I_vals)\n",
    "\n",
    "    return max_I_vals, mean_max_I, std_max_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 10\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 50\n",
    "num_runs = 5\n",
    "\n",
    "simulate_score_campaign(test_max, beta, gamma, t_span, num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_campaign_results(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Plots the mean maximum infected counts for both random and hub \n",
    "    campaigns with their standard deviations.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, mean_max_random, std_max_random = simulate_random_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    _, mean_max_hub, std_max_hub = simulate_hub_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    _, mean_max_score, std_max_score = simulate_score_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "    x_labels = ['Random', 'Hub', 'Score']  \n",
    "    means = [mean_max_random, mean_max_hub, mean_max_score]  \n",
    "    std_devs = [std_max_random, std_max_hub, std_max_score]  \n",
    "\n",
    "    \n",
    "    plt.errorbar(x=np.arange(len(means)), y=means, yerr=std_devs, fmt='o', \n",
    "                 capsize=5, color='blue', alpha=0.7, label='Mean Max Infected Counts')\n",
    "\n",
    "    \n",
    "    plt.xticks(np.arange(len(x_labels)), x_labels)  # Set x-tick labels\n",
    "    plt.title('Mean Maximum Infected Counts with Standard Deviation')\n",
    "    plt.ylabel('Count of Infected Individuals')\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()  # Adjust layout to make room for labels\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def t_test(test_max, beta, gamma, t_span, num_runs):\n",
    "\n",
    "    max_vals_random, _, _ = simulate_random_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    max_vals_hub, _, _ = simulate_hub_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    max_vals_score, _, _ = simulate_score_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(max_vals_random, max_vals_hub, max_vals_score)\n",
    "\n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae687d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 10\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 50\n",
    "num_runs = 30\n",
    "\n",
    "show_campaign_results(test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "t_stat, p_val = t_test(test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
