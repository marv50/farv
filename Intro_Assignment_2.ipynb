{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1744b5a6",
   "metadata": {},
   "source": [
    "## Style guides (remove before submitting)\n",
    "1. PEP8 for python: https://peps.python.org/pep-0008\n",
    "2. for jupyter notebook: https://github.com/spacetelescope/style-guides/blob/master/guides/jupyter-notebooks.md\n",
    "\n",
    "## General TODO (remove before submitting)\n",
    "1. Maybe add Raise errors?\n",
    "\n",
    "## DOCSTRING convention example (according to Pep8) (remove before submitting)\n",
    "**Short docstrings:**\\\n",
    "\"\"\"This is an example of a short docstring.\"\"\"\\\n",
    "\\\n",
    "**Long docstrings:**\\\n",
    "\"\"\"\\\n",
    "Short description of the function (may be next to quotations above).\\\n",
    "\\\n",
    "Arguments:\\\n",
    "    parametername: What the parameter is\\\n",
    "    parametername2: what the parameter is\\\n",
    "\\\n",
    "Returns:\\\n",
    "    This is a description of what the function returns.\\\n",
    "\"\"\"\n",
    "\n",
    "# Gillespie's Algorithm and Stochasticity in a SIR model\n",
    "\n",
    "This code implements a Gillespie's algorithm (GA) to a SIR model where stochasticity is introduced.  \n",
    "\n",
    "#### SIR Model\n",
    "A SIR model is a description of the behavioral patterns of infectious disseases with the help of a set of Ordinary Differential Equations (ODEs). Depending on the dissease that's being modeled, there are different types of SIR models that can be implemented. The model that we use is divided into three categories:\n",
    "\n",
    "1.  Susceptible; A group within the population that is susceptible to infection with the dissease.\n",
    "2.  Infected; A group within the population that is currently infected with the dissease\n",
    "3.  Recovered; A group that has recovered from an infection, we assume they cannot be infected again\n",
    "\n",
    "The rate with which people transfer between these categories is described by parameters. The parameters we use are called the infection rate (beta) and recovery rate (gamma) that describe the flow of susceptible to infected (beta) and of infected to recovered (gamma). Additionally, birth and death rates are introduced to describe the effect of 'fresh' additions to the population to the susceptible pool and a chance of mortality at each category.\n",
    "\n",
    "The set of ODEs describe how the populations within these categories change over time due to the applied parameters. \n",
    "\n",
    "### Gillespie's Algorithm\n",
    "A Gillespie's Algorithm (GA) stochastically simulates discrete events from the equation it is applied to. In our application we used the so-called First Reaction Method where the rate at which an event occurs is passed to calculate how long it takes for the event to occur. To this determination, a random variable is attached to add stochasticity. The event that takes the least amount of time to occur is then executed, all other events are negated. The time that passed is updated to include the time it took for the event to occur and a new event is generated. This is repeated until the predetermined end-point is reached (such as an established end-time).\n",
    "\n",
    "- TO DO: \n",
    "    - add ODE functions\n",
    "    - add GA function \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8d472",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The following libraries where imported for further use in the code\n",
    "\n",
    "* tabulate for ...\n",
    "* numpy for use in numerical computing\n",
    "* matplotlib for visualisation of data in plots\n",
    "* pandas for ...\n",
    "* fractions for ...\n",
    "* solve_ivp for numerical integration of the SIR ODE functions\n",
    "* bisect for ...\n",
    "\n",
    "- TO DO:\n",
    "    - Add explanations\n",
    "    - Remove unused imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7642ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tabulate import tabulate\n",
    "#from fractions import Fraction\n",
    "\n",
    "import bisect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.DiffusionModel as dm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fad77b",
   "metadata": {},
   "source": [
    "## Define All Possible Events (test merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea9b02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_update(S, I, R, N, key):\n",
    "    \"\"\"Updates and returns SIRN populations according to given key.\"\"\"\n",
    "\n",
    "    if key == 'infection':\n",
    "        S -= 1\n",
    "        I += 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'recovery': \n",
    "        R += 1\n",
    "        I -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'birth':\n",
    "        S += 1\n",
    "        N += 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death S':\n",
    "        S -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death I':\n",
    "        I -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death R':\n",
    "        R -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41243746",
   "metadata": {},
   "source": [
    "## Implement GSP \n",
    "\n",
    "- Add a way to control noise level (gsp function)\n",
    "    - Larger N reduces noise\n",
    "    - average results on multiple simulations\n",
    "    - reduce noise after simultaion: remove high frequency fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "845d40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsp(sir, beta, gamma, mu, end):\n",
    "    \"\"\"\n",
    "    Simulates disease spread using GA First Reaction Method.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        mu: Natural birth and death rate.\n",
    "        end: Signifies end point of simulation in time.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing a list of time events and population data \n",
    "        over time.\n",
    "    \"\"\"\n",
    "\n",
    "    S, I, R, N = sir\n",
    "    t = 0\n",
    "    \n",
    "    t_events = []\n",
    "    y_data = []\n",
    "    \n",
    "    while t <= end:\n",
    "        \n",
    "        # This queue collects the delta_t of each event at time t + delta_t\n",
    "        event_queue = {}\n",
    "\n",
    "        if S > 0 and I > 0 and N > 0:\n",
    "            dt_infection = np.random.exponential(1/(beta*S*I/N))\n",
    "            event_queue['infection'] = dt_infection\n",
    "\n",
    "        if I > 0:\n",
    "            dt_recovery = np.random.exponential(1/(gamma*I))\n",
    "            event_queue['recovery'] = dt_recovery\n",
    "\n",
    "        if N > 0:\n",
    "            dt_birth = np.random.exponential(1/(mu*N))\n",
    "            event_queue['birth'] = dt_birth\n",
    "\n",
    "        if S > 0:\n",
    "            dt_death_S = np.random.exponential(1/(mu*S))\n",
    "            event_queue['death S'] = dt_death_S\n",
    "\n",
    "        if I > 0:\n",
    "            dt_death_I = np.random.exponential(1/(mu*I))\n",
    "            event_queue['death I'] = dt_death_I\n",
    "\n",
    "        if R > 0:\n",
    "            dt_death_R = np.random.exponential(1/(mu*R))\n",
    "            event_queue['death R'] = dt_death_R\n",
    "\n",
    "        # Select the event with the smallest delta_t, this event will be carried out, the rest is omitted\n",
    "        sorted_queue = dict(sorted(event_queue.items(), \n",
    "                                   key=lambda item: item[1]))\n",
    "        first_event_key, first_event_time = list(sorted_queue.items())[0]\n",
    "        \n",
    "        # Updates the current time with delta_t\n",
    "        t += first_event_time\n",
    "        t_events.append(t)\n",
    "\n",
    "        # Handle each type of event\n",
    "        S, I, R, N = sir_update(S, I, R, N, first_event_key)\n",
    "\n",
    "        y_data.append([S, I, R])\n",
    "    \n",
    "    return (t_events, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c3a0a",
   "metadata": {},
   "source": [
    "## Run Stochastic Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c594d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(sir, beta, gamma, mu, t_span):\n",
    "    \"\"\"\n",
    "    Runs the GA stochastic disease simulation and plots the results.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        mu: Natural birth and death rate.\n",
    "        t_span: Maximum duration of the GA simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    t_events, y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    S = y_data[:, 0]\n",
    "    I = y_data[:, 1]\n",
    "    R = y_data[:, 2]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t_events, S, label='Susceptible (S)', color='blue')\n",
    "    plt.plot(t_events, I, label='Infected (I)', color='orange')\n",
    "    plt.plot(t_events, R, label='Recovered (R)', color='green')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Population')\n",
    "    plt.title('Disease Simulation Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parameters\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.01\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 1000\n",
    "\n",
    "run_simulation(sir, beta, gamma, mu, t_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a75d15",
   "metadata": {},
   "source": [
    "## Run Deterministic Model\n",
    "\n",
    "To do:\n",
    "\n",
    "- Add similarity score between stochastic and derministic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ode(t, sir, parameters, N):\n",
    "    \"\"\"Calculates and returns the change in sir populations over time.\"\"\"\n",
    "    \n",
    "    beta, gamma, mu = parameters\n",
    "    S, I, R = sir\n",
    "\n",
    "    dSdt = (mu*N) - ((beta*S*I)/N) - (mu*S)\n",
    "    dIdt = ((beta*S*I)/N) - (gamma*I) - (mu*I)\n",
    "    dRdt = (gamma*I) - (mu*R)\n",
    "\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "\n",
    "def plot_sir_det(time, S, I, R):\n",
    "    \"\"\"Plots the deterministic sir model.\"\"\"\n",
    "\n",
    "    plt.plot(time, S, label='Sus', color='b')\n",
    "    plt.plot(time, I, label='Infected', color='g')\n",
    "    plt.plot(time, R, label='Rec', color='r')\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Number of Infected Individuals of Total Population')\n",
    "    plt.legend()\n",
    "    plt.title('Diagram of Infected Population against Discretized Time')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_sir_det(sir, parameters, N, t_span):\n",
    "    \"\"\"Runs the deterministic sir model with passed initial values.\n",
    "    \n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        parameters: list containg recovery, infection and \n",
    "                    birth/death rate\n",
    "        N: Total initial population\n",
    "        t_span: Timespan in which the model is ran\n",
    "\n",
    "    Returns: \n",
    "        Timespan used to model sir and population sizes of S, I and R.\n",
    "    \"\"\"\n",
    "\n",
    "    # Time measurement with 1000 samples, equally spaced between 0 and t_span\n",
    "    time = np.linspace(0, t_span, 1000)\n",
    "\n",
    "    sir_integration = solve_ivp(calc_ode, [time[0], time[-1]], sir, \n",
    "                                args=(parameters, N), t_eval=time)\n",
    "    S, I, R = sir_integration.y\n",
    "\n",
    "    #plot_sir_det(time, S, I, R)\n",
    "\n",
    "    return time, S, I, R\n",
    "\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.01\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "# Intitial population densities\n",
    "N = 500\n",
    "S0 = N - 1\n",
    "I0 = N - S0\n",
    "R0 = 0\n",
    "sir_det = [S0, I0, R0]\n",
    "\n",
    "t_span = 200\n",
    "\n",
    "# The semi-colon prevents the array from being printed in cell\n",
    "time, S, I, R = run_sir_det(sir_det, parameters, N, t_span);\n",
    "plot_sir_det(time, S, I, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20ecb7",
   "metadata": {},
   "source": [
    "## Look at variance\n",
    "\n",
    "- Plot results\n",
    "\n",
    "- Delete print statements (not yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96993",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(35)\n",
    "\n",
    "\n",
    "def generate_parameters(num_samples, lower_ratio=0.45, upper_ratio=0.55, \n",
    "                        beta_range=(0.1, 0.9), gamma_range=(0.1, 0.9)):\n",
    "    \"\"\"\n",
    "    Generates beta and gamma pairs randomly to calculate their R0 values. \n",
    "    Ensures ratio of R0 values  falls within specified bounds.\n",
    "    \n",
    "    Arguments:\n",
    "        num_samples: Total number of beta/gamma pairs to generate.\n",
    "        lower_ratio: Lower bound for the ratio of R0 values.\n",
    "        upper_ratio: Upper bound for the ratio of R0 values.\n",
    "        beta_range: Range for generated beta values.\n",
    "        gamma_range: Range for generated gamma values.\n",
    "    \n",
    "    Returns:\n",
    "        A list of the beta gamma pairs and a list of the generated \n",
    "        R0 values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize ratio of R0 values smaller and larger than 1.\n",
    "    ratio = 0\n",
    "\n",
    "    while ratio < lower_ratio or ratio > upper_ratio:\n",
    "\n",
    "        # only same random generator\n",
    "        betas = np.random.uniform(beta_range[0], beta_range[1], num_samples)\n",
    "        gammas = np.random.uniform(gamma_range[0], gamma_range[1], num_samples)\n",
    "\n",
    "        beta_gamma_pairs = list(zip(betas, gammas))\n",
    "        R0_vals = [beta / gamma for beta, gamma in beta_gamma_pairs]\n",
    "\n",
    "        # Calculate the ratio of R0 values < 1 and > 1\n",
    "        num_below_one = np.sum(np.array(R0_vals) < 1)\n",
    "        num_above_one = np.sum(np.array(R0_vals) > 1)\n",
    "        ratio = num_below_one/(num_above_one + 1e-10)  # Avoid division by zero (this is hardcoding, another way?)\n",
    "\n",
    "    R0_vals\n",
    "    print(\"Beta/gamma pairs: \" + str(beta_gamma_pairs))\n",
    "    print(\"R0 values: \" + str(R0_vals))\n",
    "    print(\"Ratio: \" + str(ratio))\n",
    "    \n",
    "    return beta_gamma_pairs, R0_vals\n",
    "\n",
    "\n",
    "def parameter_sweep(sir, pairs, mu, num_runs):\n",
    "    \"\"\"\n",
    "    Performs a parameter sweep over the SIR model simulation to analyze \n",
    "    the impact of varying beta and gamma values on the maximum number of \n",
    "    infected individuals.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        pairs: List of beta-gamma tuples to test in SIR model.\n",
    "        mu: Natural birth and death rate.\n",
    "        num_runs: Number of simulation runs per beta-gamma pair tuples.\n",
    "    \n",
    "    Returns:\n",
    "        A list of variances and covariances of the maximum infected \n",
    "        values for each beta-gamma pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    variances = []\n",
    "    covariances = []\n",
    "\n",
    "    for beta, gamma in pairs:\n",
    "        \n",
    "        # For variance\n",
    "        max_I_vals = []\n",
    "\n",
    "        # For covariance\n",
    "        S_vals= []\n",
    "        I_vals = []\n",
    "        \n",
    "        # Run simulation n times for each (beta, gamma) pair.\n",
    "        for _ in range(num_runs):\n",
    "\n",
    "            result = gsp(sir, beta, gamma, mu, t_span)\n",
    "            y_data = np.array(result[1])\n",
    "\n",
    "            S = y_data[:, 0]\n",
    "            I = y_data[:, 1]\n",
    "            R = y_data[:, 2]\n",
    "\n",
    "            S_vals.extend(S)\n",
    "            I_vals.extend(I)\n",
    "\n",
    "            # Extract max I value from each run.\n",
    "            max_I_vals.append(np.max(I))\n",
    "\n",
    "        # Variance for each (beta, gamma) pair after n runs is recorded.\n",
    "        variances.append(np.var(max_I_vals))\n",
    "        covariance_matrix = np.cov(S_vals, I_vals)\n",
    "        covariances.append(covariance_matrix[0, 1])\n",
    "\n",
    "    return variances, covariances\n",
    "\n",
    "\n",
    "def plot_R0_vs_variance(R0_vals, variances):\n",
    "    \"\"\"\n",
    "    Plots R0 values against variances of maximum infected individuals.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(R0_vals, variances, color='green', edgecolor='black')\n",
    "\n",
    "    plt.xlabel('R0 Values')\n",
    "    plt.ylabel('Variance of Max Infected')\n",
    "    plt.title('R0 Values vs Variance of Maximum Infected Individuals')\n",
    "    #plt.axhline(0, color='gray', linestyle='--')  # Optional: Add a horizontal line at y=0\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_R0_vs_covariances(R0_vals, covariances):\n",
    "    \"\"\"\n",
    "    Plots R0 values against covariances of S and I across different \n",
    "    parameter pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(R0_vals, covariances, color='green', edgecolor='black')\n",
    "\n",
    "    plt.xlabel('R0 Values')\n",
    "    plt.ylabel('S, I Covariance')\n",
    "    plt.title('R0 Values vs Covariances of S and I')\n",
    "    #plt.axhline(0, color='gray', linestyle='--')  # Optional: Add a horizontal line at y=0\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Define number of beta/gamma pairs.\n",
    "num_pairs = 50\n",
    "\n",
    "# Define number of runs per beta/gamma pair.\n",
    "num_runs = 10\n",
    "\n",
    "# Generate Parameters\n",
    "sample_pairs, sample_R0_vals = generate_parameters(num_pairs)\n",
    "\n",
    "# Calculate variances\n",
    "variances, covariances = parameter_sweep(sir, sample_pairs, mu, num_runs)\n",
    "\n",
    "# Combine and sort by R0 for variance analysis\n",
    "var_combined = list(zip(sample_R0_vals, variances))\n",
    "sorted_var_combined = sorted(var_combined)\n",
    "sorted_R0_vals, sorted_variances = zip(*sorted_var_combined)\n",
    "\n",
    "# Combine and sort by R0 for variance analysis\n",
    "covar_combined = list(zip(sample_R0_vals, covariances))\n",
    "sorted_covar_combined = sorted(covar_combined)\n",
    "sorted_R0_vals, sorted_covariances = zip(*sorted_covar_combined)\n",
    "\n",
    "\n",
    "plot_R0_vs_variance(sorted_R0_vals, sorted_variances)\n",
    "plot_R0_vs_covariances(sorted_R0_vals, sorted_covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f380c9",
   "metadata": {},
   "source": [
    "## Calculate the Mean accross multiple runs \n",
    "TO DO: change deterministic to roll with same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cabf3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsp_mean(runs, t_span, sir, parameters):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    beta, gamma, mu = parameters\n",
    "\n",
    "    # calculates how large the steps should be in between time steps    \n",
    "    t_steps = t_span/ 1000\n",
    " \n",
    "    # end excludes end so include t_steps. steps are spacing between values\n",
    "    fixed_steps = np.round(np.arange(0, t_span + t_steps, t_steps), 2)\n",
    "\n",
    "    # store data from run at those fixed time steps \n",
    "    results = {\n",
    "        'time': fixed_steps.tolist(),\n",
    "        'S': {round(step, 4): [] for step in fixed_steps},\n",
    "        'I': {round(step, 4): [] for step in fixed_steps},\n",
    "        'R': {round(step, 4): [] for step in fixed_steps},\n",
    "        'N': {round(step, 4): [] for step in fixed_steps}\n",
    "        }\n",
    "    \n",
    "    results_mean = {\n",
    "        'S': [],\n",
    "        'I': [],\n",
    "        'R': [],\n",
    "        'N': []\n",
    "        }\n",
    "    \n",
    "    results_stdev = {\n",
    "        'S': [],\n",
    "        'I': [],\n",
    "        'R': [],\n",
    "        'N': []\n",
    "        }\n",
    "\n",
    "    # Stores the peak number of Infected and equivalent timepoint for every run\n",
    "    peak_infected = []\n",
    "\n",
    "    I_max = 0\n",
    "    t_max = 0\n",
    "\n",
    "    for run in range(runs):\n",
    "        # get data from run\n",
    "        t_events , y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "        I_max = 0\n",
    "        t_max = 0\n",
    "\n",
    "        # finds for which values of steps in fixed_steps what the closest (lower) is in t_events.\n",
    "        for steps in fixed_steps:\n",
    "\n",
    "            #round the steps similarly to the dictionary\n",
    "            steps = round(steps, 4)\n",
    "\n",
    "            #returns where a value should be inserted\n",
    "            position_value = bisect.bisect_right(t_events, steps)\n",
    "\n",
    "            #want lowest closest value position, but position can be 0 or higher than max (t_span)\n",
    "            if position_value > 0:\n",
    "                position_value -= 1\n",
    "\n",
    "            S, I, R = y_data[position_value]\n",
    "\n",
    "            if I > I_max:\n",
    "                I_max = I\n",
    "                t_max = t_events[position_value]\n",
    "\n",
    "            # Appends the corresponding values to the correct place on the timeline\n",
    "            results['S'][steps].append(S)\n",
    "            results['I'][steps].append(I)\n",
    "            results['R'][steps].append(R)\n",
    "            results['N'][steps].append(S + I + R)\n",
    "            \n",
    "        peak_infected.append([t_max, I_max])\n",
    "\n",
    "    #access every fixed step\n",
    "    # access all entries for S, I , R and N in the fixed steps and store mean values in a dictionary\n",
    "    for steps in fixed_steps:\n",
    "        \n",
    "        results_mean['S'].append(np.mean(results['S'][steps]))\n",
    "        results_mean['I'].append(np.mean(results['I'][steps]))\n",
    "        results_mean['R'].append(np.mean(results['R'][steps]))\n",
    "        results_mean['N'].append(np.mean(results['N'][steps]))\n",
    "\n",
    "        results_stdev['S'].append(np.std(results['S'][steps]))\n",
    "        results_stdev['I'].append(np.std(results['I'][steps]))\n",
    "        results_stdev['R'].append(np.std(results['R'][steps]))\n",
    "        results_stdev['N'].append(np.std(results['N'][steps]))\n",
    "    \n",
    "    return results, results_mean, results_stdev, peak_infected\n",
    "\n",
    "\n",
    "def plot_mean(results, results_mean, results_stdev, sir):\n",
    "   \n",
    "    S, I, R, N = sir\n",
    "    sir_det = [S, I, R]\n",
    "\n",
    "    S_mean = results_mean['S']\n",
    "    I_mean = results_mean['I']\n",
    "    R_mean = results_mean['R']\n",
    "    time = results['time']\n",
    "\n",
    "    time_2, S, I, R = run_sir_det(sir_det, parameters, N, t_span)\n",
    "    \n",
    "    plt.plot(time, S_mean, label='S mean', color='blue')\n",
    "    plt.plot(time, I_mean, label='I mean', color='red')\n",
    "    plt.plot(time, R_mean, label='R mean', color='green')\n",
    "    plt.plot(time_2, S, label='S deterministic', color='blue', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(time_2, I, label='I deterministic', color='red', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(time_2, R, label='R deterministic', color='green', \n",
    "             linestyle='dashed')\n",
    "\n",
    "    time_steps_S = []\n",
    "    time_steps_I = []\n",
    "    time_steps_R = []\n",
    "    S_values = []\n",
    "    I_values = []\n",
    "    R_values = []\n",
    "\n",
    "    for time_step, values in results['S'].items():\n",
    "        for value in values:\n",
    "            time_steps_S.append(time_step)\n",
    "            S_values.append(value)\n",
    "    \n",
    "    for time_step, values in results['I'].items():\n",
    "        for value in values:\n",
    "            time_steps_I.append(time_step)\n",
    "            I_values.append(value)\n",
    "\n",
    "    for time_step, values in results['R'].items():\n",
    "        for value in values:\n",
    "            time_steps_R.append(time_step)\n",
    "            R_values.append(value)\n",
    "\n",
    "    plt.scatter(time_steps_S, S_values, alpha=0.03, linewidths=0, \n",
    "                color='blue', marker='o', label='S values', s=1)\n",
    "    plt.scatter(time_steps_I, I_values, alpha=0.03, linewidths=0, \n",
    "                color='red', marker='o', label='I values', s=1)\n",
    "    plt.scatter(time_steps_R, R_values, alpha=0.03, linewidths=0, \n",
    "                color='green', marker='o', label='R values', s=1)\n",
    "\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Mean Number of Infected Individuals of Total Population')\n",
    "    plt.legend()\n",
    "    plt.title('Diagram of Population against Discretized Time (mean)')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Initial conditions with a population of 500 people\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 100\n",
    "\n",
    "runs = 100\n",
    "\n",
    "results, results_mean, results_stdev, _ = gsp_mean(runs, t_span, sir, parameters);\n",
    "#plot_mean(results, results_mean, results_stdev, sir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18546bd",
   "metadata": {},
   "source": [
    "## R0 vs Extinction Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab711086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_large_R0(num_samples, R0_range=(1.1, 5), gamma_value=0.1):\n",
    "    \"\"\"\n",
    "    Generates systematic beta and gamma pairs such that the R0 values range from 1.1 to 5.\n",
    "    \n",
    "    Parameters:\n",
    "        num_samples (int): Number of beta/gamma pairs to generate.\n",
    "        R0_range (tuple): Range for R0 values.\n",
    "        gamma_value (float): Fixed value for gamma (to systematically calculate beta).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of (beta, gamma) pairs.\n",
    "        list: List of R0 values.\n",
    "    \"\"\"\n",
    "    # Generate evenly spaced R0 values within the specified range\n",
    "    R0_vals = np.linspace(R0_range[0], R0_range[1], num_samples)\n",
    "    \n",
    "    # Use a fixed gamma value, and calculate corresponding beta = R0 * gamma\n",
    "    gammas = np.full(num_samples, gamma_value)\n",
    "    betas = R0_vals*gammas  # beta = R0 * gamma\n",
    "\n",
    "    beta_gamma_pairs = list(zip(betas, gammas))\n",
    "\n",
    "    # Optional: print for debugging\n",
    "    print(\"Beta/gamma pairs: \" + str(beta_gamma_pairs))\n",
    "    print(\"R0 values: \" + str(R0_vals))\n",
    "    \n",
    "    return beta_gamma_pairs, R0_vals\n",
    "\n",
    "\n",
    "def count_R0_extinctions(pairs, num_runs):\n",
    "\n",
    "    extinction_list = []\n",
    "\n",
    "    for beta, gamma in pairs:\n",
    "    \n",
    "        num_extinctions = 0\n",
    "    \n",
    "        for _ in range(num_runs):\n",
    "\n",
    "\n",
    "                result = gsp(sir, beta, gamma, mu, t_span)\n",
    "                y_data = np.array(result[1])\n",
    "\n",
    "                I = y_data[:, 1]\n",
    "\n",
    "                mean = np.mean(I)\n",
    "\n",
    "                print(mean)\n",
    "\n",
    "\n",
    "                if mean < 1e-2:  # Treat any value below a small threshold as extinction:\n",
    "                    \n",
    "                    num_extinctions += 1\n",
    "\n",
    "                \n",
    "        \n",
    "        extinction_list.append(num_extinctions)\n",
    "\n",
    "    \n",
    "    return extinction_list\n",
    "        \n",
    "\n",
    "def plot_results_R0(num_pairs, num_runs):\n",
    "    \n",
    "    sample_pairs, sample_R0_vals = generate_large_R0(num_pairs)\n",
    "    R0_extinctions = count_R0_extinctions(sample_pairs, num_runs)\n",
    "\n",
    "    # Sort R0 values and corresponding extinctions\n",
    "    R0_extinction_pairs = list(zip(sample_R0_vals, R0_extinctions))\n",
    "    sorted_R0_extinction_pairs = sorted(R0_extinction_pairs)\n",
    "\n",
    "    sorted_R0_vals, sorted_extinctions = zip(*sorted_R0_extinction_pairs)\n",
    "\n",
    "    # Convert to numpy arrays for easy indexing\n",
    "    sorted_R0_vals = np.array(sorted_R0_vals)\n",
    "    sorted_extinctions = np.array(sorted_extinctions)\n",
    "\n",
    "    # Bin the R0 values (for example, in intervals of 0.1)\n",
    "    bins = np.arange(min(sorted_R0_vals), max(sorted_R0_vals), 0.2)\n",
    "    bin_indices = np.digitize(sorted_R0_vals, bins)\n",
    "\n",
    "    # Average extinctions within each bin\n",
    "    binned_extinctions = [np.mean(sorted_extinctions[bin_indices == i]) \n",
    "                          for i in range(1, len(bins))]\n",
    "\n",
    "    # Plotting\n",
    "    plt.bar(bins[:-1], binned_extinctions, width=0.1)\n",
    "    plt.xlabel(\"R0 Value\")\n",
    "    plt.ylabel(\"Average Extinctions\")\n",
    "    plt.title(\"Average Extinctions vs. R0 Value\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num_pairs = 20\n",
    "num_runs = 50\n",
    "mu = 0.0001\n",
    "\n",
    "plot_results_R0(num_pairs, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0e80a",
   "metadata": {},
   "source": [
    "## N vs Extinction Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04092cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_populations(num_pops):\n",
    "    populations = []\n",
    "    \n",
    "    # Evenly distributes populations from 100 to 10,000.\n",
    "    S_0 = np.linspace(100, 10000, num_pops)\n",
    "\n",
    "    for i in range(num_pops):\n",
    "        S = S_0[i]\n",
    "        I = 1\n",
    "        R = 0\n",
    "        N = S + I\n",
    "        sir = (S, I, R, N)\n",
    "        populations.append(sir)\n",
    "    \n",
    "    return populations\n",
    "\n",
    "\n",
    "def count_N_extinctions(num_pops, num_runs):\n",
    "    populations = generate_populations(num_pops)\n",
    "    extinction_list = []\n",
    "\n",
    "    for pop in populations:\n",
    "        num_extinctions = 0\n",
    "        for _ in range(num_runs):\n",
    "            result = gsp(pop, beta, gamma, mu, t_span)\n",
    "            y_data = np.array(result[1])\n",
    "            I = y_data[:, 1]\n",
    "            mean = np.mean(I)\n",
    "\n",
    "            # Treats any value below a small threshold as extinction.\n",
    "            if mean < 1e-3:\n",
    "                num_extinctions += 1\n",
    "        \n",
    "        extinction_list.append(num_extinctions)\n",
    "    \n",
    "    return extinction_list\n",
    "\n",
    "\n",
    "def plot_results_N(num_pops, num_runs):\n",
    "    sample_pops = generate_populations(num_pops)\n",
    "    N_extinctions = count_N_extinctions(num_pops, num_runs)\n",
    "\n",
    "    # Sorts population sizes and corresponding extinctions.\n",
    "    N_extinction_pairs = list(zip(sample_pops, N_extinctions))\n",
    "    sorted_N_extinction_pairs = sorted(N_extinction_pairs)\n",
    "\n",
    "    sorted_pops, sorted_extinctions = zip(*sorted_N_extinction_pairs)\n",
    "\n",
    "    # Convert to numpy arrays for easy indexing\n",
    "    sorted_pops = np.array(sorted_pops)\n",
    "    sorted_extinctions = np.array(sorted_extinctions)\n",
    "\n",
    "    # Bin the population sizes more sensibly with a larger bin size\n",
    "    bins = np.arange(min(sorted_pops[:, 0]), max(sorted_pops[:, 0]) + 1, 300)  # Increase bin size to 1000\n",
    "    bin_indices = np.digitize(sorted_pops[:, 0], bins)\n",
    "\n",
    "    # Average extinctions within each bin\n",
    "    binned_extinctions = [np.mean(sorted_extinctions[bin_indices == i]) for i in range(1, len(bins))]\n",
    "\n",
    "    # Plotting\n",
    "    plt.bar(bins[:-1], binned_extinctions, width=np.diff(bins), align='edge')\n",
    "    plt.xlabel(\"N\")\n",
    "    plt.ylabel(\"Average Extinctions\")\n",
    "    plt.title(\"Average Extinctions vs. N (with adjusted bin size)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parameters\n",
    "beta = 0.4\n",
    "gamma = 0.1\n",
    "mu = 0.0001\n",
    "\n",
    "num_pops = 20\n",
    "num_runs = 50\n",
    "\n",
    "plot_results_N(num_pops, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e3585",
   "metadata": {},
   "source": [
    "## Extinctions as a Function of R0 and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_R0_N(num_pairs, num_pops, num_runs):\n",
    "    # Generate R0 pairs\n",
    "    sample_pairs, sample_R0_vals = generate_large_R0(num_pairs)\n",
    "\n",
    "    # Generate populations\n",
    "    populations = generate_populations(num_pops)\n",
    "\n",
    "    # Count extinctions for each combination of R0 and N\n",
    "    extinction_data = []\n",
    "\n",
    "    for (beta, gamma), R0 in zip(sample_pairs, sample_R0_vals):\n",
    "        \n",
    "        for pop in populations:\n",
    "            num_extinctions = 0\n",
    "            \n",
    "            for _ in range(num_runs):\n",
    "                result = gsp(pop, beta, gamma, mu, t_span)\n",
    "                y_data = np.array(result[1])\n",
    "                I = y_data[:, 1]\n",
    "                mean = np.mean(I)\n",
    "                \n",
    "                if mean < 1e-2:  # Treat any value below a small threshold as extinction\n",
    "                    num_extinctions += 1\n",
    "\n",
    "            # Store results: (N, R0, num_extinctions)\n",
    "            N = pop[0] + pop[1] + pop[2]  # S + I + R\n",
    "            extinction_data.append((N, R0, num_extinctions))\n",
    "\n",
    "    # Convert to numpy array for easier indexing\n",
    "    extinction_data = np.array(extinction_data)\n",
    "\n",
    "    # Separate the data for plotting\n",
    "    N_values = extinction_data[:, 0]\n",
    "    R0_values = extinction_data[:, 1]\n",
    "    extinction_counts = extinction_data[:, 2]\n",
    "\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    scatter = ax.scatter(N_values, R0_values, extinction_counts, c=extinction_counts, cmap='viridis')\n",
    "    \n",
    "    ax.set_xlabel('Population Size (N)')\n",
    "    ax.set_ylabel('R0 Value')\n",
    "    ax.set_zlabel('Number of Extinctions')\n",
    "    ax.set_title('Interaction between R0 and N in Extinctions')\n",
    "    \n",
    "    # Add color bar\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Number of Extinctions')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parameters\n",
    "num_pairs = 20\n",
    "num_pops = 20\n",
    "num_runs = 20\n",
    "mu = 0.0001\n",
    "\n",
    "# Execute the plotting function\n",
    "plot_results_R0_N(num_pairs, num_pops, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17600feb",
   "metadata": {},
   "source": [
    "## Stochastic Resonance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091299a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoc_res_R0(num_samples, R0_range=(1, 10), gamma_value=0.1):\n",
    "    \n",
    "    # Generates a list of R0 values, evenly spaced, rounded by 2 decimals.\n",
    "    R0_values = np.round(np.linspace(R0_range[0], R0_range[1], num_samples), 2)\n",
    "    beta_values = []\n",
    "    gamma_values = []\n",
    "\n",
    "    for value in R0_values:\n",
    "        beta_values.append(np.round((value * gamma_value), 2))\n",
    "        gamma_values.append(gamma_value)\n",
    "\n",
    "    beta_gamma_pairs = list(zip(beta_values, gamma_values))\n",
    "    #print(beta_gamma_pairs)\n",
    "    #print(R0_values, beta_values)\n",
    "    # R0 values is a list of n_samples R0 and beta of n_sample amount, gamma equal\n",
    "\n",
    "    return beta_gamma_pairs\n",
    "\n",
    "def stoc_res(sir, t_span, num_samples, mu):\n",
    "    \"\"\"\n",
    "    Peak infected and peak_det are lists containing all sets of peak \n",
    "    infected values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_gamma_pairs = stoc_res_R0(num_samples)\n",
    "\n",
    "    peak_det = []\n",
    "    bg = []\n",
    "    snr = []\n",
    "\n",
    "    # mean time results for gsp list of mean for each b-g pair\n",
    "    mean_time = []\n",
    "    stdev_time = []\n",
    "\n",
    "    for beta, gamma in beta_gamma_pairs:\n",
    "        parameters = [beta, gamma, mu]\n",
    "        runs_stoc = 10\n",
    "        _, _, _, peak_infected = gsp_mean(runs_stoc, t_span, sir, parameters)\n",
    "\n",
    "        # Calculates the mean and stdev for peak infected time in gsp\n",
    "        time = [t[0] for t in peak_infected]\n",
    "        mean_time.append(np.mean([time]))\n",
    "        mean_time_gsp = np.mean([time])\n",
    "        stdev_time.append(np.std([time]))\n",
    "        \n",
    "        # Unpacks and reassign sir for deterministic model.\n",
    "        S, I, R, N = sir\n",
    "        sir_det = S, I , R\n",
    "        time_det, _, I_det, _ = run_sir_det(sir_det, parameters, N, \n",
    "                                                    t_span)\n",
    "\n",
    "        # Finds maximum values for deterministic model and stores them.\n",
    "        I_max = max(I_det)\n",
    "        t_max_index = np.where(I_det == I_max)\n",
    "        t_max = time_det[t_max_index][0]\n",
    "        peak_det.append([t_max])\n",
    "\n",
    "        bg.append(beta/gamma)\n",
    "\n",
    "        snr.append(t_max/ mean_time_gsp)\n",
    "\n",
    "\n",
    "    # have peaks for det\n",
    "    # have peaks for gsp mean\n",
    "    # have peaks for gsp stdev\n",
    "    return mean_time, stdev_time, peak_det, bg, snr\n",
    "\n",
    "def plot_stoc_peak(mean_time, peak_det, bg):\n",
    "    \"\"\"\n",
    "    TO DO: possibly add stdev error bars, substract mean det from mean \n",
    "    gsp, but will go into 0.\"\"\"\n",
    "\n",
    "    plt.plot(bg, peak_det, label='peak I time det', color='green')\n",
    "    plt.plot(bg, mean_time, label='peak I time stoc', color='blue')\n",
    "    plt.xlabel('R0')\n",
    "    plt.ylabel('Time of peak I')\n",
    "    plt.legend()\n",
    "    plt.title('Time to reach peak in Infected population for different R0 values')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "def plot_stoc_snr(bg, snr):\n",
    "    \"\"\"\n",
    "    TO DO: possibly add stdev error bars, substract mean det from mean \n",
    "    gsp, but will go into 0.\"\"\"\n",
    "\n",
    "    plt.plot(bg, snr, label='SNR', color='red')\n",
    "    plt.xlabel('R0')\n",
    "    plt.ylabel('Signal to Noise ratio')\n",
    "    plt.legend()\n",
    "    plt.title('SNR ratio for peak in infected population for different R0 values')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "num_samples = 100\n",
    "#stoc_res_R0(num_samples, R0_range=(0, 5), gamma_value=0.1)\n",
    "\n",
    "# Initial conditions with a population of 500 people\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "mu = 0.001\n",
    "\n",
    "t_span = 200\n",
    "\n",
    "mean_time, stdev_time, peak_det, bg, snr = stoc_res(sir, t_span, num_samples, mu)\n",
    "plot_stoc_peak(mean_time, peak_det, bg)\n",
    "plot_stoc_snr(bg, snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d3ab9",
   "metadata": {},
   "source": [
    "## Mean for different N populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e2aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_means_for_different_Ns(N_values, num_runs, t_span, parameters):\n",
    "    for N in N_values:\n",
    "        # Generate initial conditions based on N\n",
    "        sir = (N - 1, 1, 0, N)  # S, I, R, N\n",
    "\n",
    "        # Get results for the current N\n",
    "        _, results_mean, _, _ = gsp_mean(num_runs, t_span, sir, parameters)\n",
    "\n",
    "        # Plot the mean infected population over time\n",
    "        plt.plot(results_mean['I'], label=f'N = {N}')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Mean Infected Population')\n",
    "    plt.title('Mean Infected Population for Different Values of N')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "N_values = [100, 500, 1000, 1500]  # Example N values\n",
    "num_runs = 50\n",
    "t_span = 1000\n",
    "beta = 0.4\n",
    "gamma = 0.2\n",
    "mu = 0.01\n",
    "\n",
    "parameters = (beta, gamma, mu)\n",
    "\n",
    "plot_means_for_different_Ns(N_values, num_runs, t_span, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4c1a9",
   "metadata": {},
   "source": [
    "## Barabasi Albert Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barabasi_albert(N, m, beta, gamma, I0, t_span):\n",
    "    \"\"\"\n",
    "    A barabasi-Albert network generates a scale-free network where some \n",
    "    nodes have more connections than others.\n",
    "\n",
    "    New nodes are more likely to connect to nodes with more existing\n",
    "    connections.\n",
    "    \"\"\"\n",
    "\n",
    "    ba_graph = nx.barabasi_albert_graph(N, m)\n",
    "\n",
    "    model = ep.SIRModel(ba_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)  \n",
    "    config.add_model_parameter('gamma', gamma)  \n",
    "    config.add_model_parameter(\"fraction_infected\", I0)  \n",
    "\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "\n",
    "    \n",
    "    y_data = []  \n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:  \n",
    "                S_count += 1\n",
    "            elif state == 1:  \n",
    "                I_count += 1\n",
    "            elif state == 2:  \n",
    "                R_count += 1\n",
    "        \n",
    "       \n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data  \n",
    "\n",
    "\n",
    "def ba_parameter_sweep(N, m, beta, gamma, I0,  num_runs, num_pairs):\n",
    "\n",
    "    pairs = generate_parameters(num_pairs)\n",
    "\n",
    "    for pair in pairs:\n",
    "        beta, gamma = pair\n",
    "\n",
    "        iterations, y_data = barabasi_albert(N, m, beta, gamma, I0,  num_runs)\n",
    "\n",
    "    y_data = []  \n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:  \n",
    "                S_count += 1\n",
    "            elif state == 1:  \n",
    "                I_count += 1\n",
    "            elif state == 2:  \n",
    "                R_count += 1\n",
    "        \n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data  \n",
    "\n",
    "\n",
    "\n",
    "N = 1000  \n",
    "# Number of edges for a new node\n",
    "m = 5\n",
    "\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "I0 = 0.05\n",
    "\n",
    "t_span = 200\n",
    "\n",
    "results = barabasi_albert(N, m, beta, gamma, I0, t_span)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e31984",
   "metadata": {},
   "source": [
    "## SIR Sweep on Barabasi Albert network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ba_m_sweep(N, edges, beta, gamma, I0, t_span, num_runs):\n",
    "    mean_max_values = []\n",
    "    std_max_values = []\n",
    "\n",
    "    for m in edges:\n",
    "        max_I_values = []\n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = barabasi_albert(N, m, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            # Get the maximum infected value in the current run\n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values\n",
    "\n",
    "\n",
    "def plot_ba_m_sweep(N, edges, beta_values, gamma_values, I0, t_span, num_runs):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        \n",
    "        mean_max_values, std_max_values = ba_m_sweep(N, edges, beta, gamma, I0, t_span, num_runs)\n",
    "        \n",
    "        R0 = beta/gamma\n",
    "        label = f'R₀ = {R0:.1f} (β = {beta:.1f}, γ = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(edges, mean_max_values, yerr=std_max_values, fmt='-o', capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Number of edges (m)\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\"Mean Maximum Infected Nodes vs Number of Edges for Different R₀ Values\")\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ba_m_vs_R0(N, edges, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    \n",
    "    plot_ba_m_sweep(N, edges, beta_values, gamma_values, I0, t_span, num_runs)\n",
    "\n",
    "\n",
    "N = 200\n",
    "edges = np.arange(1, 11, 1)\n",
    "R0_values = [0.5, 1.0, 2.5] \n",
    "gamma_values = [0.1, 0.2, 0.2]\n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "ba_m_vs_R0(N, edges, I0, t_span, num_runs, R0_values, gamma_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f67808",
   "metadata": {},
   "source": [
    "## Watts-Strogatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watts_strogatz(N, k, p, beta, gamma, I0, t_span):\n",
    "    \"\"\"\n",
    "    A Watts-Strogatz network model generates small-world networks with \n",
    "    short average path lengths between nodes and high cluster densities.\n",
    "    \"\"\"\n",
    "\n",
    "    ws_graph = nx.watts_strogatz_graph(N, k, p)\n",
    "\n",
    "    # Configure the diffusion model (e.g., SIR)\n",
    "    model = ep.SIRModel(ws_graph)\n",
    "\n",
    "    # Model configuration\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)  # Infection rate\n",
    "    config.add_model_parameter('gamma', gamma)  # Recovery rate\n",
    "    config.add_model_parameter(\"fraction_infected\", I0)  # Initial fraction infected\n",
    "\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    # Simulate the model\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "    \n",
    "    # Extract number of S, I, R nodes for each iteration\n",
    "    y_data = []  # List to hold S, I, R counts for each iteration\n",
    "\n",
    "    for iteration in iterations:\n",
    "        # Get the status of nodes\n",
    "        status = iteration['status']\n",
    "        \n",
    "        # Initialize counts\n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        # Count S, I, R based on status\n",
    "        for _, state in status.items():\n",
    "            if state == 0:  # Susceptible\n",
    "                S_count += 1\n",
    "            elif state == 1:  # Infected\n",
    "                I_count += 1\n",
    "            elif state == 2:  # Recovered\n",
    "                R_count += 1\n",
    "        \n",
    "        # Append counts to the list\n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data  # Return both iterations and status counts\n",
    "\n",
    "\n",
    "N = 1000  # Number of nodes\n",
    "k = 6     # Each node is joined with its k nearest neighbors in a ring topology\n",
    "p = 0.1   # Rewiring probability\n",
    "\n",
    "t_span = 200\n",
    "\n",
    "results = watts_strogatz(N, k, p, beta, gamma, I0, t_span)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3d26d",
   "metadata": {},
   "source": [
    "## Sweep for Watts Strogatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_n_sweep(N, neighbors, p, beta, gamma, I0, t_span, num_runs):\n",
    "    mean_max_values = []\n",
    "    std_max_values = []\n",
    "\n",
    "    for n in neighbors:\n",
    "        max_I_values = []\n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = watts_strogatz(N, n, p, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            # Get the maximum infected value in the current run\n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values\n",
    "\n",
    "\n",
    "def plot_ws_n_sweep(N, neighbors, p, beta_values, gamma_values, I0, t_span, num_runs):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        \n",
    "        mean_max_values, std_max_values = ws_n_sweep(N, neighbors, p, beta, gamma, I0, t_span, num_runs)\n",
    "        \n",
    "        R0 = beta/gamma\n",
    "        label = f'R₀ = {R0:.1f} (β = {beta:.1f}, γ = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(neighbors, mean_max_values, yerr=std_max_values, fmt='-o', capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Number of Neighbors (n)\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\"Mean Maximum Infected Nodes vs Number of Neighbors for Different R₀ Values\")\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ws_n_vs_R0(N, neighbors, p, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    \n",
    "    plot_ws_n_sweep(N, neighbors, p, beta_values, gamma_values, I0, t_span, num_runs)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "N = 200\n",
    "neighbors = np.arange(2, 22, 2)\n",
    "p = 0.1 # Rewiring probability is fixed for now\n",
    "R0_values = [0.5, 1.0, 2.5] \n",
    "gamma_values = [0.1, 0.2, 0.2]\n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "ws_n_vs_R0(N, neighbors, p, I0, t_span, num_runs, R0_values, gamma_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e2adb",
   "metadata": {},
   "source": [
    "## Erdos-Reyni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos_reyni(N, p, beta, gamma, I0, t_span):\n",
    "    \"\"\" \n",
    "    A random network model that generates edges (paths) between nodes \n",
    "    randomly. We run sir once on this network.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct E-R Network\n",
    "    er_graph = nx.erdos_renyi_graph(N, p)\n",
    "\n",
    "    model = ep.SIRModel(er_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", I0)\n",
    "\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    # Simulate the model\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "\n",
    "    # Extract number of S, I, R nodes for each iteration\n",
    "    y_data = []  # List to hold S, I, R counts for each iteration\n",
    "\n",
    "    for iteration in iterations:\n",
    "        # Get the status of nodes\n",
    "        status = iteration['status']\n",
    "        \n",
    "        # Initialize counts\n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        # Count S, I, R based on status\n",
    "        for _, state in status.items():\n",
    "            if state == 0:  # Susceptible\n",
    "                S_count += 1\n",
    "            elif state == 1:  # Infected\n",
    "                I_count += 1\n",
    "            elif state == 2:  # Recovered\n",
    "                R_count += 1\n",
    "        \n",
    "        # Append counts to the list\n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data  # Return both iterations and status counts\n",
    "\n",
    "\n",
    "N = 1000  # Number of nodes\n",
    "p = 0.01  # Probability for edge creation\n",
    "t_span = 200\n",
    "\n",
    "results = erdos_reyni(N, p, beta, gamma, I0, t_span)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c9084",
   "metadata": {},
   "source": [
    "## Run SIR Sweep on Random (Erdos-Reyni) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_probability_sweep(N, probabilities, beta, gamma, I0, t_span, num_runs):\n",
    "    mean_max_values = []  \n",
    "    std_max_values = []   \n",
    "\n",
    "    for p in probabilities:\n",
    "        max_I_values = []  \n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = erdos_reyni(N, p, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "     \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values  \n",
    "\n",
    "\n",
    "def plot_er_prob_sweep(N, probabilities, beta_values, gamma_values, I0, t_span, \n",
    "                       num_runs):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        \n",
    "        mean_max_values, std_max_values = er_probability_sweep(N, probabilities, beta, gamma, I0, t_span, num_runs)\n",
    "        \n",
    "        R0 = beta / gamma\n",
    "        label = f'R₀ = {R0:.1f} (β = {beta:.1f}, γ = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(probabilities, mean_max_values, yerr=std_max_values, \n",
    "                     fmt='-o', capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Probability p\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\"Mean Maximum Infected Nodes vs Probability for Different R₀ Values\")\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def er_prob_vs_R0(N, probabilities, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    \n",
    "    plot_er_prob_sweep(N, probabilities, beta_values, gamma_values, I0, t_span, num_runs)\n",
    "\n",
    "\n",
    "\n",
    "N = 200\n",
    "probabilities = np.linspace(0.01, 0.1, 10)  \n",
    "R0_values = [0.5, 1.0, 2.5]  \n",
    "gamma_values = [0.1, 0.2, 0.2]  \n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "er_prob_vs_R0(N, probabilities, I0, t_span, num_runs, R0_values, gamma_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9b3f5",
   "metadata": {},
   "source": [
    "## Generating Networks and Examining Network Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2d2d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate networks of specified types and calculate degree statistics and clustering coefficients.\n",
    "\n",
    "    Parameters:\n",
    "    nettype (str): Type of the network to generate ('BA' for Barabási–Albert, \n",
    "                   'ER' for Erdös-Renyi, 'WS' for Watts-Strogatz).\n",
    "    N (int): Number of nodes in the network.\n",
    "    m_vals (list): List of m values for Barabási–Albert networks (number of edges to attach from a new node).\n",
    "    p_vals (list): List of p values for Erdös-Renyi networks (probability of connecting two edges).\n",
    "    r_vals (list): List of r values for Watts-Strogatz networks (probability of rewiring an existing edge).\n",
    "    num_runs (int): Number of times to run the network generation to gather statistics.\n",
    "    k (int, optional): Number of nearest neighbors each node is connected to in Watts-Strogatz networks. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the following keys and their respective values:\n",
    "        - 'mean_min_degrees': List of mean minimum degrees for each m/p/r value.\n",
    "        - 'std_min_degrees': List of standard deviations of minimum degrees for each m/p/r value.\n",
    "        - 'mean_max_degrees': List of mean maximum degrees for each m/p/r value.\n",
    "        - 'std_max_degrees': List of standard deviations of maximum degrees for each m/p/r value.\n",
    "        - 'mean_degrees': List of mean degrees for each m/p/r value.\n",
    "        - 'std_degrees': List of standard deviations of degrees for each m/p/r value.\n",
    "        - 'mean_clustering_coeffs': List of mean clustering coefficients for each m/p/r value.\n",
    "        - 'std_clustering_coeffs': List of standard deviations of clustering coefficients for each m/p/r value.\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_min_degrees = []\n",
    "    std_min_degrees = []\n",
    "    \n",
    "    mean_max_degrees = []\n",
    "    std_max_degrees = []\n",
    "    \n",
    "    mean_degrees = []\n",
    "    std_degrees = []\n",
    "    \n",
    "    mean_clustering_coeffs = []  \n",
    "    std_clustering_coeffs = []    \n",
    "\n",
    "    if nettype == 'BA':\n",
    "\n",
    "        for m in m_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                ba_net = nx.barabasi_albert_graph(N, m)\n",
    "                \n",
    "                degrees = [deg for _, deg in ba_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(ba_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "\n",
    "    elif nettype == 'ER':\n",
    "        \n",
    "        mean_min_degrees = []\n",
    "        std_min_degrees = []\n",
    "        \n",
    "        mean_max_degrees = []\n",
    "        std_max_degrees = []\n",
    "        \n",
    "        mean_degrees = []\n",
    "        std_degrees = []\n",
    "        \n",
    "        mean_clustering_coeffs = []  \n",
    "        std_clustering_coeffs = []    \n",
    "\n",
    "        for p in p_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                er_net = nx.erdos_renyi_graph(N, p)\n",
    "                \n",
    "                degrees = [deg for _, deg in er_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(er_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "    \n",
    "    elif nettype == 'WS':\n",
    "\n",
    "\n",
    "        mean_min_degrees = []\n",
    "        std_min_degrees = []\n",
    "        \n",
    "        mean_max_degrees = []\n",
    "        std_max_degrees = []\n",
    "        \n",
    "        mean_degrees = []\n",
    "        std_degrees = []\n",
    "        \n",
    "        mean_clustering_coeffs = []  \n",
    "        std_clustering_coeffs = []    \n",
    "\n",
    "        for r in r_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                \n",
    "                ws_net = nx.watts_strogatz_graph(N, k, r)\n",
    "                \n",
    "                degrees = [deg for _, deg in ws_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(ws_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "            \n",
    "    return {\n",
    "        'mean_min_degrees': mean_min_degrees,\n",
    "        'std_min_degrees': std_min_degrees,\n",
    "        'mean_max_degrees': mean_max_degrees,\n",
    "        'std_max_degrees': std_max_degrees,\n",
    "        'mean_degrees': mean_degrees,\n",
    "        'std_degrees': std_degrees,\n",
    "        'mean_clustering_coeffs': mean_clustering_coeffs,  \n",
    "        'std_clustering_coeffs': std_clustering_coeffs      \n",
    "    }\n",
    "\n",
    "\n",
    "def plot_degree_stats(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot degree statistics for generated networks of specified types.\n",
    "\n",
    "    Parameters:\n",
    "    nettype (str): Type of the network to plot ('BA' for Barabási–Albert, \n",
    "                   'ER' for Erdös-Renyi, 'WS' for Watts-Strogatz).\n",
    "    N (int): Number of nodes in the network.\n",
    "    m_vals (list): List of m values for Barabási–Albert networks (number of edges to attach from a new node).\n",
    "    p_vals (list): List of p values for Erdös-Renyi networks (probability of connecting two edges).\n",
    "    r_vals (list): List of r values for Watts-Strogatz networks (probability of rewiring an existing edge).\n",
    "    num_runs (int): Number of times to run the network generation to gather statistics.\n",
    "    k (int, optional): Number of nearest neighbors each node is connected to in Watts-Strogatz networks. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    results = gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5)\n",
    "    \n",
    "    mean_min_degrees = results['mean_min_degrees']\n",
    "    std_min_degrees = results['std_min_degrees']\n",
    "    mean_max_degrees = results['mean_max_degrees']\n",
    "    std_max_degrees = results['std_max_degrees']\n",
    "    mean_degrees = results['mean_degrees']\n",
    "    std_degrees = results['std_degrees']\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    \n",
    "\n",
    "    if nettype == 'BA':\n",
    "        \n",
    "        plt.errorbar(m_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(m_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(m_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, label='Mean Degree', color='red')\n",
    "\n",
    "\n",
    "\n",
    "        plt.xlabel(\"m (Number of edges to attach from a new node)\")\n",
    "        plt.title(\"Mean Min, Max, and Overall Degree vs m in Barabási–Albert Networks\")\n",
    "        \n",
    "\n",
    "    elif nettype == 'ER':\n",
    "        plt.errorbar(p_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(p_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(p_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, label='Mean Degree', color='red')\n",
    "\n",
    "\n",
    "        plt.xlabel(\"p (Probability of connecting two edges)\")\n",
    "        plt.title(\"Mean Min, Max, and Overall Degree vs p in Erdös–Renyi Networks\")\n",
    "\n",
    "    elif nettype == 'WS':\n",
    "        plt.errorbar(r_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(r_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(r_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, label='Mean Degree', color='red')\n",
    "\n",
    "\n",
    "        plt.xlabel(\"r (Probability of rewiring an exisint edge)\")\n",
    "        plt.title(\"Mean Min, Max, and Overall Degree vs r in Watts-Strogatz Networks\")\n",
    "\n",
    "\n",
    "    plt.ylabel(\"Degree\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_clustering_stats(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot clustering coefficient statistics for generated networks of specified types.\n",
    "\n",
    "    Parameters:\n",
    "    nettype (str): Type of the network to plot ('BA' for Barabási–Albert, \n",
    "                   'ER' for Erdös-Renyi, 'WS' for Watts-Strogatz).\n",
    "    N (int): Number of nodes in the network.\n",
    "    m_vals (list): List of m values for Barabási–Albert networks (number of edges to attach from a new node).\n",
    "    p_vals (list): List of p values for Erdös-Renyi networks (probability of connecting two edges).\n",
    "    r_vals (list): List of r values for Watts-Strogatz networks (probability of rewiring an existing edge).\n",
    "    num_runs (int): Number of times to run the network generation to gather statistics.\n",
    "    k (int, optional): Number of nearest neighbors each node is connected to in Watts-Strogatz networks. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    None: This function generates and displays a plot of the clustering coefficients.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5)\n",
    "    mean_clustering_coeffs = results['mean_clustering_coeffs']\n",
    "    std_clustering_coeffs = results['std_clustering_coeffs']\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    \n",
    "    \n",
    "    if nettype == 'BA':\n",
    "        plt.xlabel(\"m (Number of edges to attach from a new node)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs m in Barabási–Albert Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(m_vals))  \n",
    "        plt.bar(bar_positions, mean_clustering_coeffs, yerr=std_clustering_coeffs, width=bar_width, alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, m_vals)  \n",
    "    \n",
    "    elif nettype == 'ER':\n",
    "        plt.xlabel(\"p (Probability of connecting two edges)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs p in Erdös-Renyi Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(p_vals))  \n",
    "        plt.bar(bar_positions, mean_clustering_coeffs, yerr=std_clustering_coeffs, width=bar_width, alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, p_vals) \n",
    "\n",
    "    elif nettype == 'WS':\n",
    "        plt.xlabel(\"r (Probability of rewiring an exisint edge)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs r in Watts-Strogatz Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(r_vals))  \n",
    "        plt.bar(bar_positions, mean_clustering_coeffs, yerr=std_clustering_coeffs, width=bar_width, alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, r_vals) \n",
    "\n",
    "\n",
    "\n",
    "    plt.ylabel(\"Clustering Coefficient\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "N = 300\n",
    "# NOTe FRED: same for sweeps\n",
    "m_vals = np.arange(2, 23, 2)\n",
    "p_vals = np.linspace(0.01, 0.1, 10)\n",
    "r_vals = np.linspace(0.1, 0.9, 10)\n",
    "num_runs = 50\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbc8e5",
   "metadata": {},
   "source": [
    "### BA-Network Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('BA', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('BA', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb06c7",
   "metadata": {},
   "source": [
    "## ER Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('ER', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('ER', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec243d",
   "metadata": {},
   "source": [
    "## WS Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4937de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('WS', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('WS', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaa77d",
   "metadata": {},
   "source": [
    "## Dynamic Vaccination Campaign\n",
    "\n",
    "To Do:\n",
    "1. load in sociopatterns dataset (NDlib and network X)\n",
    "    If i open the data in excel, the data structure is such that the first row and column signify the nodes. nodes from 1 to 374. All cells in between signify if there is an edge between the nodes. if the number is > 0 it means there is an edge, we can negate how high since that is the weight which we are not looking at right now (identity matrix)\n",
    "\n",
    "    1 means infected, 0 means susceptible, 2 means recovered\n",
    "\n",
    "    In NDlib 'Recovered' is 'Removed'\n",
    "\n",
    "2. can we test and vaccinate at the same iteration or not\n",
    "    we assume we can!\n",
    "\n",
    "3. visualize the data\n",
    "\n",
    "4. Add test accuracy!\n",
    "\n",
    "5. we think people infected, they maynot be, dont put their status to 2, if 1 not into 2\n",
    "\n",
    "\"but you can only discover the disease status of a node after a test\"\n",
    "test can show antibodies\n",
    "\n",
    "'status' is something i added to the nodes of known_graph and are not inherently in graph, to access the node statuses of the graph, access the status through model instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83e02e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n",
      "Graph node:  {}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 175\u001b[0m\n\u001b[1;32m    172\u001b[0m vac_budget \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    173\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m--> 175\u001b[0m run_model(test_max, beta, gamma, t_span)\n",
      "Cell \u001b[0;32mIn[8], line 150\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(test_max, beta, gamma, t_span)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Loads and initializes all data, makes graph of known statuses \u001b[39;00m\n\u001b[1;32m    149\u001b[0m graph, graph_known \u001b[38;5;241m=\u001b[39m load_sociopatterns()\n\u001b[0;32m--> 150\u001b[0m model, graph_known \u001b[38;5;241m=\u001b[39m initiate_model(graph, graph_known, beta, gamma)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Tests, vaccinates and runs sir for t_span amount of iterations\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m t \u001b[38;5;241m<\u001b[39m t_span:\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Can only perform tests if there are tests left in the test budget\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36minitiate_model\u001b[0;34m(graph, graph_known, beta, gamma)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph_known\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m     53\u001b[0m     graph_known\u001b[38;5;241m.\u001b[39mnodes[node][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode info of graph: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph\u001b[38;5;241m.\u001b[39mnode)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, graph_known\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "#np.random.seed()\n",
    "\n",
    "\n",
    "def load_sociopatterns():\n",
    "    \"\"\"\n",
    "    Loads and initiates the csv file containing sociopattern information.\n",
    "    Initiates two graphs, one for actual data and one simulating what we\n",
    "    know about the data. \"\"\"\n",
    "\n",
    "    edge_list = pd.read_csv(\"transmission_network.csv\", delimiter=';', \n",
    "                            index_col=0)\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    graph_known = nx.Graph()\n",
    "    #print(\"Graph: \", graph)\n",
    "\n",
    "    # Adds all nodes to the graph\n",
    "    graph.add_nodes_from(edge_list.index.tolist())\n",
    "    graph_known.add_nodes_from(edge_list.index.tolist())\n",
    "\n",
    "    # Adds edges between nodes if their weight is higher than 0\n",
    "    for node_i, row in edge_list.iterrows():\n",
    "        for node_j, value in row.items():\n",
    "            if value > 0:\n",
    "                graph.add_edge(int(node_i), int(node_j))\n",
    "                graph_known.add_edge(int(node_i), int(node_j))\n",
    "\n",
    "    return graph, graph_known\n",
    "    \n",
    "\n",
    "def initiate_model(graph, graph_known, beta, gamma):\n",
    "    \"\"\"\" \n",
    "    Initiates SIR model on the graph (real world) and sets the status of \n",
    "    known graph to everybody as susceptible.\n",
    "    \"\"\"\n",
    "\n",
    "    model = ep.SIRModel(graph)\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "\n",
    "    # Initiates statuses for all nodes in the known graphs to susceptible\n",
    "    for node in graph_known.nodes:\n",
    "        graph_known.nodes[node]['status'] = 0\n",
    "\n",
    "    # Randomly assigns 5 nodes to get infected\n",
    "    infected = 5\n",
    "    infected_nodes = (np.random.choice(graph.nodes(), size=infected, replace=False)).tolist()\n",
    "    config.add_model_initial_configuration('Infected', infected_nodes)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    return model, graph_known\n",
    "\n",
    "\n",
    "def update_sir_model(model, graph, iterations):\n",
    "    \"\"\"\n",
    "    Runs the SIR model for iterations number of times.\n",
    "    \"\"\"\n",
    "    model.iteration_bunch(iterations) \n",
    "\n",
    "    return model, graph\n",
    "\n",
    "\n",
    "def test_nodes_random(model, graph_known, tests, vac_pool):\n",
    "    \"\"\"Tests if a node is infected. Should only test people you know are \n",
    "    not currently removed or infected.\"\"\"\n",
    "\n",
    "    skip = []\n",
    "\n",
    "    # Skips people you know are infected or removed \n",
    "    for node in graph_known.nodes:\n",
    "        if graph_known.nodes[node]['status'] != 0:\n",
    "            skip.append(node)\n",
    "    \n",
    "    # Makes a list of people that are available for test\n",
    "    available_nodes = [node for node in graph_known.nodes() if node not in skip]\n",
    "\n",
    "    # Resets number of tests if there are not enough available nodes\n",
    "    if len(available_nodes) == 0:\n",
    "        return\n",
    "    \n",
    "    elif len(available_nodes) < tests:\n",
    "        tests = available_nodes\n",
    "    \n",
    "    # Selects 'tests' number of nodes randomly\n",
    "    # If replace is false, no one will be tested twice in this iteration\n",
    "    tested_nodes = (np.random.choice(available_nodes, size=tests, \n",
    "                                     replace=False)).tolist()\n",
    "\n",
    "    # Updates the status of the tested nodes on the known graph\n",
    "    for node in tested_nodes:\n",
    "        status = model.status[node]\n",
    "\n",
    "        # write code for test accuracy here\n",
    "\n",
    "        graph_known.nodes[node]['status'] = status\n",
    "\n",
    "        # Adds to susceptible vaccination pool if not already there\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "\n",
    "    return graph_known, vac_pool, tests\n",
    "\n",
    "\n",
    "def vac_nodes_random(model, graph_known, vac_budget, vac_pool):\n",
    "    \"\"\". Only vacc sus people that you know of.\"\"\"\n",
    "\n",
    "    # If there are not enough Susceptible people, reset the vaccination budget\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    # Randomly choose susceptible people to vaccinate\n",
    "    vac_nodes = (np.random.choice(vac_pool, size=vac_budget, \n",
    "                                  replace=False)).tolist()\n",
    "\n",
    "    # Update all statuses of vaccinated nodes to 'Removed'\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        # Can only remove people who are not currently infected or removed\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated from vaccination pool\n",
    "        vac_pool = [node for node in vac_pool if node not in vac_nodes]\n",
    "\n",
    "    return model, graph_known, vac_pool\n",
    "\n",
    "\n",
    "def run_model(test_max, beta, gamma, t_span):\n",
    "    \"\"\"\n",
    "    Runs the random network model null simulation. \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "\n",
    "    # Loads and initializes all data, makes graph of known statuses \n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    # Tests, vaccinates and runs sir for t_span amount of iterations\n",
    "    while t < t_span:\n",
    "\n",
    "        # Can only perform tests if there are tests left in the test budget\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, tests = test_nodes_random(model, graph_known, test_max, vac_pool)\n",
    "            total_tests -= tests\n",
    "            \n",
    "        model, graph_known, vac_pool = vac_nodes_random(model, graph_known, vac_budget, vac_pool)\n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "t_span = 5\n",
    "beta = 0.01\n",
    "gamma = 0.005\n",
    "test_max = 5\n",
    "vac_budget = 5\n",
    "test_accuracy = 1.0\n",
    "\n",
    "run_model(test_max, beta, gamma, t_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8834eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
