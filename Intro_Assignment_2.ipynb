{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1744b5a6",
   "metadata": {},
   "source": [
    "## Style guides (remove before submitting)\n",
    "1. PEP8 for python: https://peps.python.org/pep-0008\n",
    "2. for jupyter notebook: https://github.com/spacetelescope/style-guides/blob/master/guides/jupyter-notebooks.md\n",
    "\n",
    "## General TODO (remove before submitting)\n",
    "1. Maybe add Raise errors?\n",
    "\n",
    "## DOCSTRING convention example (according to Pep8) (remove before submitting)\n",
    "**Short docstrings:**\\\n",
    "\"\"\"This is an example of a short docstring.\"\"\"\\\n",
    "\\\n",
    "**Long docstrings:**\\\n",
    "\"\"\"\\\n",
    "Short description of the function (may be next to quotations above).\\\n",
    "\\\n",
    "Arguments:\\\n",
    "    parametername: What the parameter is\\\n",
    "    parametername2: what the parameter is\\\n",
    "\\\n",
    "Returns:\\\n",
    "    This is a description of what the function returns.\\\n",
    "\"\"\"\n",
    "\n",
    "# Gillespie's Algorithm and Stochasticity in a SIR model\n",
    "\n",
    "This code implements a Gillespie's algorithm (GA) to a SIR model where stochasticity is introduced.  \n",
    "\n",
    "#### SIR Model\n",
    "A SIR model is a description of the behavioral patterns of infectious disseases with the help of a set of Ordinary Differential Equations (ODEs). Depending on the dissease that's being modeled, there are different types of SIR models that can be implemented. The model that we use is divided into three categories:\n",
    "\n",
    "1.  Susceptible; A group within the population that is susceptible to infection with the dissease.\n",
    "2.  Infected; A group within the population that is currently infected with the dissease\n",
    "3.  Recovered; A group that has recovered from an infection, we assume they cannot be infected again\n",
    "\n",
    "The rate with which people transfer between these categories is described by parameters. The parameters we use are called the infection rate (beta) and recovery rate (gamma) that describe the flow of susceptible to infected (beta) and of infected to recovered (gamma). Additionally, birth and death rates are introduced to describe the effect of 'fresh' additions to the population to the susceptible pool and a chance of mortality at each category.\n",
    "\n",
    "The set of ODEs describe how the populations within these categories change over time due to the applied parameters. \n",
    "\n",
    "### Gillespie's Algorithm\n",
    "A Gillespie's Algorithm (GA) stochastically simulates discrete events from the equation it is applied to. In our application we used the so-called First Reaction Method where the rate at which an event occurs is passed to calculate how long it takes for the event to occur. To this determination, a random variable is attached to add stochasticity. The event that takes the least amount of time to occur is then executed, all other events are negated. The time that passed is updated to include the time it took for the event to occur and a new event is generated. This is repeated until the predetermined end-point is reached (such as an established end-time).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8d472",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The following libraries where imported for further use in the code\n",
    "\n",
    "\n",
    "* numpy for use in numerical computing\n",
    "* matplotlib for visualisation of data in plots\n",
    "* solve_ivp for numerical integration of the SIR ODE functions\n",
    "* pandas to work with dataframes\n",
    "* networkx to generate ER, BA and WS graphs\n",
    "* ndlib to simulate SIR on networks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7642ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy import stats\n",
    "\n",
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.DiffusionModel as dm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecd47f",
   "metadata": {},
   "source": [
    "# Stochasticity in a SIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4c8b7",
   "metadata": {},
   "source": [
    "## 1. Making a Stochastig SIR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fad77b",
   "metadata": {},
   "source": [
    "### 1.1 Define All Possible Events \n",
    "\n",
    "In order to update the stochastic GSP SIR model, the sir_update() function is given a key which it uses to identify and update the according S, I, R and or N populations. \n",
    "In this model, we approach the population as individuals, not scaled to percentages. Therefore, updates regard a single individual and only adjust the affected populations.\n",
    "\n",
    "By using if and elif statements, we prevent the function from accessing all if statements as there will always only be one key. If an if statement is accessed, it will return the updated S, I, R and N values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9b02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_update(S, I, R, N, key):\n",
    "    \"\"\"Updates and returns SIRN populations according to given key.\"\"\"\n",
    "\n",
    "    if key == 'infection':\n",
    "        S -= 1\n",
    "        I += 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'recovery': \n",
    "        R += 1\n",
    "        I -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'birth':\n",
    "        S += 1\n",
    "        N += 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death S':\n",
    "        S -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death I':\n",
    "        I -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N\n",
    "    \n",
    "    elif key == 'death R':\n",
    "        R -= 1\n",
    "        N -= 1\n",
    "        return S, I, R, N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41243746",
   "metadata": {},
   "source": [
    "### 1.2 Implement GSP \n",
    "\n",
    "A random exponantial is assigned to each available event, allowing events occur only if the neccesary populations (S, I, R) have individuals. An event queue dictionary is initiated to store all possible events and their time of occurence, sorted in descending order. \n",
    "\n",
    "The simulation iterates by executing the first event in the queue, updating the SIR model parameters and adding the event's occurence time to the total elapsed time. After executing an event, the queue is cleared and reinitialized for the next cycle.\n",
    "\n",
    "This process continues until the elapsed time meets or exceeds a specified duration. The function returns the sizes of S, I, R, N as y_data along with the total simulation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845d40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)\n",
    "\n",
    "def gsp(sir, beta, gamma, mu, t_span):\n",
    "    \"\"\"\n",
    "    Simulates disease spread using GA First Reaction Method.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        mu: Natural birth and death rate.\n",
    "        end: Signifies end point of simulation in time.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing a list of time events and population data \n",
    "        over time.\n",
    "    \"\"\"\n",
    "\n",
    "    S, I, R, N = sir\n",
    "    t = 0\n",
    "    \n",
    "    t_events = []\n",
    "    y_data = []\n",
    "    \n",
    "    while t <= t_span:\n",
    "        \n",
    "        # This queue collects the delta_t of each event at time t + delta_t\n",
    "        event_queue = {}\n",
    "\n",
    "        if S > 0 and I > 0 and N > 0:\n",
    "            dt_infection = np.random.exponential(1/(beta*S*I/N))\n",
    "            event_queue['infection'] = dt_infection\n",
    "\n",
    "        if I > 0:\n",
    "            dt_recovery = np.random.exponential(1/(gamma*I))\n",
    "            event_queue['recovery'] = dt_recovery\n",
    "\n",
    "        if N > 0:\n",
    "            dt_birth = np.random.exponential(1/(mu*N))\n",
    "            event_queue['birth'] = dt_birth\n",
    "\n",
    "        if S > 0:\n",
    "            dt_death_S = np.random.exponential(1/(mu*S))\n",
    "            event_queue['death S'] = dt_death_S\n",
    "\n",
    "        if I > 0:\n",
    "            dt_death_I = np.random.exponential(1/(mu*I))\n",
    "            event_queue['death I'] = dt_death_I\n",
    "\n",
    "        if R > 0:\n",
    "            dt_death_R = np.random.exponential(1/(mu*R))\n",
    "            event_queue['death R'] = dt_death_R\n",
    "\n",
    "        # Select the event with the smallest delta_t, this event will be carried out, the rest is omitted\n",
    "        sorted_queue = dict(sorted(event_queue.items(), \n",
    "                                   key=lambda item: item[1]))\n",
    "        first_event_key, first_event_time = list(sorted_queue.items())[0]\n",
    "        \n",
    "        # Updates the current time with delta_t\n",
    "        t += first_event_time\n",
    "        t_events.append(t)\n",
    "\n",
    "        # Handle each type of event\n",
    "        S, I, R, N = sir_update(S, I, R, N, first_event_key)\n",
    "\n",
    "        y_data.append([S, I, R])\n",
    "    \n",
    "    return (t_events, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c3a0a",
   "metadata": {},
   "source": [
    "### 1.3 Run Stochastic Simulation\n",
    "\n",
    "The function run_gsp_simulation() visualizes the data from the stochastic SIR model simulation above. By running the gsp() function, the neccesary data is unpacked into S, I and R and plotted. The figure indicates the change in population sizes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c594d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gsp_simulation(sir, beta, gamma, mu, t_span):\n",
    "    \"\"\"\n",
    "    Runs the GA stochastic disease simulation and plots the results.\n",
    "\n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        mu: Natural birth and death rate.\n",
    "        t_span: Maximum duration of the GA simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    t_events, y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    S = y_data[:, 0]\n",
    "    I = y_data[:, 1]\n",
    "    R = y_data[:, 2]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t_events, S, label='Susceptible (S)', color='blue')\n",
    "    plt.plot(t_events, I, label='Infected (I)', color='orange')\n",
    "    plt.plot(t_events, R, label='Recovered (R)', color='green')\n",
    "    plt.xlabel('Time (Days)')\n",
    "    plt.ylabel('Population (N)')\n",
    "    plt.title('Stochastic Disease Simulation Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d47952",
   "metadata": {},
   "source": [
    "### 1.4 Parameters \n",
    "\n",
    "Parameters to the gsp model are initialized and passed to run the gsp simulation function. The parameters are kept seperately such that they may be changed with ease.\n",
    "The total population is chosen after which the other populations, Susceptible (S), Infected (I), and Recovered (R), are adjusted accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(49)\n",
    "\n",
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.01\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "timespan = 200\n",
    "\n",
    "run_gsp_simulation(sir, beta, gamma, mu, timespan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a75d15",
   "metadata": {},
   "source": [
    "## 2. Making a Deterministic SIR Model\n",
    "\n",
    "A SIR model as created in the previous assignment is imported to analyze the difference between a deterministic and stochastic model. For clarity, all parameters are initiated again.\n",
    "\n",
    "TO DO: How much do we need to explain this?\n",
    "\n",
    "\n",
    "- Add similarity score between stochastic and derministic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5c1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ode(t, sir, parameters, N):\n",
    "    \"\"\"Calculates and returns the change in sir populations over time.\"\"\"\n",
    "    \n",
    "    beta, gamma, mu = parameters\n",
    "    S, I, R = sir\n",
    "\n",
    "    dSdt = (mu*N) - ((beta*S*I)/N) - (mu*S)\n",
    "    dIdt = ((beta*S*I)/N) - (gamma*I) - (mu*I)\n",
    "    dRdt = (gamma*I) - (mu*R)\n",
    "\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "\n",
    "def run_sir_det(sir, parameters, N, t_span):\n",
    "    \"\"\"Runs the deterministic sir model with passed initial values.\n",
    "    \n",
    "    Arguments:\n",
    "        sir: List of S, I, R and N populations.\n",
    "        parameters: list containg recovery, infection and \n",
    "                    birth/death rate\n",
    "        N: Total initial population\n",
    "        t_span: Timespan in which the model is ran\n",
    "\n",
    "    Returns: \n",
    "        Timespan used to model sir and population sizes of S, I and R.\n",
    "    \"\"\"\n",
    "\n",
    "    time = np.linspace(0, t_span, 1000)\n",
    "    sir_integration = solve_ivp(calc_ode, [time[0], time[-1]], sir, \n",
    "                                args=(parameters, N), t_eval=time)\n",
    "    S, I, R = sir_integration.y\n",
    "\n",
    "    return time, S, I, R\n",
    "\n",
    "\n",
    "def plot_sir_det(time, S, I, R):\n",
    "    \"\"\"Plots the deterministic sir model.\"\"\"\n",
    "\n",
    "    plt.plot(time, S, label='Sus', color='b')\n",
    "    plt.plot(time, I, label='Infected', color='orange')\n",
    "    plt.plot(time, R, label='Rec', color='g')\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Population (N)')\n",
    "    plt.legend()\n",
    "    plt.title('Deterministic Disease Simulation over Time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitial population densities\n",
    "N = 500\n",
    "S0 = N - 1\n",
    "I0 = N - S0\n",
    "R0 = 0\n",
    "sir_det = [S0, I0, R0]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.01\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 200\n",
    "\n",
    "# The semi-colon prevents the array from being printed in cell\n",
    "time, S, I, R = run_sir_det(sir_det, parameters, N, t_span);\n",
    "plot_sir_det(time, S, I, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7200f4",
   "metadata": {},
   "source": [
    "## 3. Analyzing stochasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19917057",
   "metadata": {},
   "source": [
    "### 3.1 Comparing GSP with Deterministic\n",
    "Both graphs of the deterministic and GSP model are overlapped with the same parameters to compare the difference between the results on a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "\n",
    "\n",
    "def plot_sir_detvsgsp(sir, parameters, t_span):\n",
    "    \"\"\"Plots the deterministic vs stochastic sir models.\"\"\"\n",
    "\n",
    "    S, I, R, N = sir\n",
    "    sir_det = [S, I, R]\n",
    "    beta, gamma, mu = parameters\n",
    "\n",
    "    time, S_det, I_det, R_det = run_sir_det(sir_det, parameters, N, t_span)\n",
    "    t_events, y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    S_gsp = y_data[:, 0]\n",
    "    I_gsp = y_data[:, 1]\n",
    "    R_gsp = y_data[:, 2]\n",
    "\n",
    "    plt.plot(time, S_det, label='S (Deterministic)', color='b', linestyle='dashed')\n",
    "    plt.plot(time, I_det, label='I (Deterministic)', color='orange', linestyle='dashed')\n",
    "    plt.plot(time, R_det, label='R (Deterministic)', color='g', linestyle='dashed')\n",
    "\n",
    "    plt.plot(t_events, S_gsp, label='S (GSP)', color='blue')\n",
    "    plt.plot(t_events, I_gsp, label='I (GSP)', color='orange')\n",
    "    plt.plot(t_events, R_gsp, label='R (GSP)', color='green')\n",
    "    \n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Population (N)')\n",
    "    plt.legend()\n",
    "    plt.title('Comparison of Infection spread in Stochastic and Deterministic' \n",
    "              'SIR Model'\n",
    "              )\n",
    "    plt.show()\n",
    "\n",
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6678\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 100\n",
    "\n",
    "plot_sir_detvsgsp(sir, parameters, t_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20ecb7",
   "metadata": {},
   "source": [
    "### 3.2 Look at variance\n",
    "\n",
    "The following cell runs gsp for different values of R0 as well as different population sizes N. We look at the between-run variance as well as the covariance between S and I while varying and and R0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96993",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(35)\n",
    "\n",
    "\n",
    "def generate_parameters(num_samples, R0_range=(0.1, 4.0), \n",
    "                        gamma_range=(0.1, 0.9)):\n",
    "    \"\"\"\n",
    "    Generates beta-gamma pairs within specified ranges of R0 and gamma \n",
    "    values. Beta values are calculated based on the desired R0 values and \n",
    "    corresponding gamma values.\n",
    "\n",
    "    Parameters:\n",
    "        num_samples: Number of (beta, gamma) pairs to generate.\n",
    "        R0_range: The range of R0 values (min, max).\n",
    "        gamma_range: The range of gamma values to produce (min, max).\n",
    "\n",
    "    Returns:\n",
    "        List of beta-gamma pairs and an array of R0 values corresponding \n",
    "        to the pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    R0_vals = np.linspace(R0_range[0], R0_range[1], num_samples)\n",
    "    gammas = np.linspace(gamma_range[0], gamma_range[1], num_samples)\n",
    "    betas = R0_vals * gammas\n",
    "    beta_gamma_pairs = list(zip(betas, gammas))\n",
    "\n",
    "    return beta_gamma_pairs, R0_vals\n",
    "\n",
    "\n",
    "def parameter_sweep(sir, pairs, mu, num_runs):\n",
    "    \"\"\"\n",
    "    Runs multiple simulations on an SIR model by varying beta-gamma \n",
    "    parameters and calculates the variance of maximum infected \n",
    "    individuals and the covariance between S and I.\n",
    "\n",
    "    Parameters:\n",
    "        sir: The SIR model containing S, I and R populations.\n",
    "        pairs: A list of beta-gamma pairs for the simulations.\n",
    "        mu : Natural death rate.\n",
    "        num_runs: Number of simulation iterations per beta-gamma pair.\n",
    "\n",
    "    Returns:\n",
    "        Variance of maximum infected valuesfor each beta-gamma pair and \n",
    "        covariance values between S and I for each beta-gamma pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    variances = []\n",
    "    covariances = []\n",
    "\n",
    "    for beta, gamma in pairs:\n",
    "        \n",
    "        # For variance\n",
    "        max_I_vals = []\n",
    "\n",
    "        # For covariance\n",
    "        S_vals= []\n",
    "        I_vals = []\n",
    "        \n",
    "        # Run simulation n times for each (beta, gamma) pair.\n",
    "        for _ in range(num_runs):\n",
    "            result = gsp(sir, beta, gamma, mu, t_span)\n",
    "            y_data = np.array(result[1])\n",
    "\n",
    "            S = y_data[:, 0]\n",
    "            I = y_data[:, 1]\n",
    "            R = y_data[:, 2]\n",
    "\n",
    "            S_vals.extend(S)\n",
    "            I_vals.extend(I)\n",
    "\n",
    "            max_I_vals.append(np.max(I))\n",
    "\n",
    "        # Variance for each (beta, gamma) pair after n runs is recorded.\n",
    "        variances.append(np.var(max_I_vals))\n",
    "        covariance_matrix = np.cov(S_vals, I_vals)\n",
    "        covariances.append(covariance_matrix[0, 1])\n",
    "\n",
    "    return variances, covariances\n",
    "\n",
    "\n",
    "def plot_R0_vs_variance(R0_vals, variances):\n",
    "    \"\"\"\n",
    "    Plots the relationship between R0 values and variance in the maximum \n",
    "    number of infected individuals for different parameter pairs.\n",
    "\n",
    "    Parameters:\n",
    "        R0_vals: List of R0 values corresponding to the parameter pairs.\n",
    "        variances: Variances of the maximum infected individuals for each \n",
    "            R0 value.\n",
    "\n",
    "    Returns:\n",
    "        None. Displays a scatter plot.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(R0_vals, variances, color='green', edgecolor='black')\n",
    "\n",
    "    plt.xlabel(r'$R_0$-Values')\n",
    "    plt.ylabel('Variance of Max Infected')\n",
    "    plt.title(r'$R_0$-Values vs Variance of Maximum Infected Individuals')\n",
    "    #plt.axhline(0, color='gray', linestyle='--')  # Optional: Add a horizontal line at y=0\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_R0_vs_covariances(R0_vals, covariances):\n",
    "    \"\"\"\n",
    "    Plots the relationship between R0 values and the covariance between \n",
    "    susceptible and infected individuals for different parameter pairs.\n",
    "\n",
    "    Parameters:\n",
    "        R0_vals: List of R0 values corresponding to the parameter pairs.\n",
    "        covariances: Covariance values between S and I for each R0 value.\n",
    "\n",
    "    Returns:\n",
    "        None. Displays a scatter plot.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(R0_vals, covariances, color='green', edgecolor='black')\n",
    "    \n",
    "    plt.xlabel(r'$R_0$-Values')\n",
    "    plt.ylabel('S, I Covariance')\n",
    "    plt.title(r'$R_0$-Values vs Covariances of S and I')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num_pairs = 50\n",
    "num_runs = 20\n",
    "\n",
    "sample_pairs, sample_R0_vals = generate_parameters(num_pairs)\n",
    "variances, covariances = parameter_sweep(sir, sample_pairs, mu, num_runs)\n",
    "\n",
    "# Combine and sort by R0 for variance analysis.\n",
    "var_combined = list(zip(sample_R0_vals, variances))\n",
    "sorted_var_combined = sorted(var_combined)\n",
    "sorted_R0_vals, sorted_variances = zip(*sorted_var_combined)\n",
    "\n",
    "# Combine and sort by R0 for covariance analysis.\n",
    "covar_combined = list(zip(sample_R0_vals, covariances))\n",
    "sorted_covar_combined = sorted(covar_combined)\n",
    "sorted_R0_vals, sorted_covariances = zip(*sorted_covar_combined)\n",
    "\n",
    "plot_R0_vs_variance(sorted_R0_vals, sorted_variances)\n",
    "plot_R0_vs_covariances(sorted_R0_vals, sorted_covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f380c9",
   "metadata": {},
   "source": [
    "### 3.3 Calculate the Mean\n",
    "\n",
    "Since a stochastic simulation may render more extremes, we wanted to calculate and visualizes a mean for the stochastic SIR model to compare with the deterministic model. \n",
    "\n",
    "However, every gsp run may result in different time steps. Therefore we had to initialize dictionaries to store variables for each run at fixed steps. These steps were chosen by starting at t = 0 and ending at t = timespan. Here the timespan equals the timespan used for the gsp function. Steps were taken with equal spacing.\n",
    "\n",
    "For every gsp mean, the values of S, I and R (and N) at these specific time steps was saved. This was done by iterating over the list of fixed_steps and finding the S, I, R and N values at that point in time. The corresponding values are then stored in a dictionary with fixed_steps. This will eventually result in a dictionary with fixed time steps and values for S, I, R and N at each of those fixed steps. The amount of values at each step depends on how often the stochastic sir simulation was performed.\n",
    "\n",
    "The mean and std of each time step is then calculated and stored in seperate dictionaries.\n",
    "\n",
    "\n",
    "Since the steps at which S, I and R are recorded in the mean may differ from the fixed_steps that we determined, the lowest closest value was chosen and the S, I and R values were placed to the right of that value on the timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(29)\n",
    "\n",
    "\n",
    "def gsp_mean(runs, t_span, sir, parameters):\n",
    "    \"\"\"\n",
    "    This function runs the gsp SIR model a set number of times to \n",
    "    calculate the mean and standard deviation the runs.\n",
    "\n",
    "    Arguments:\n",
    "        runs: Number of times to run the gsp function\n",
    "        t_span: Lower bound for the ratio of R0 values.\n",
    "        sir: List of S, I, R and N populations.\n",
    "        parameters: list containg recovery, infection and \n",
    "                    birth/death rate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionaries with information stored of the results, mean and \n",
    "        standard deviation of each time step. Also returns a list of \n",
    "        maximum I values for each run.\n",
    "    \"\"\"\n",
    "\n",
    "    beta, gamma, mu = parameters \n",
    "    t_steps = t_span/ 1000\n",
    "\n",
    "    fixed_steps = np.round(np.arange(0, t_span, t_steps), 2)\n",
    "\n",
    "    # Store data from a run at fixed time steps.\n",
    "    results = {\n",
    "        'time': fixed_steps.tolist(),\n",
    "        'S': {round(step, 4): [] for step in fixed_steps},\n",
    "        'I': {round(step, 4): [] for step in fixed_steps},\n",
    "        'R': {round(step, 4): [] for step in fixed_steps},\n",
    "        'N': {round(step, 4): [] for step in fixed_steps}\n",
    "        }\n",
    "    \n",
    "    results_mean = {\n",
    "        'S': [],\n",
    "        'I': [],\n",
    "        'R': [],\n",
    "        'N': []\n",
    "        }\n",
    "    \n",
    "    results_stdev = {\n",
    "        'S': [],\n",
    "        'I': [],\n",
    "        'R': [],\n",
    "        'N': []\n",
    "        }\n",
    "\n",
    "    peak_infected = []\n",
    "\n",
    "    I_max = 0\n",
    "    t_max = 0\n",
    "\n",
    "    for _ in range(runs):\n",
    "        t_events , y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "\n",
    "        I_max = 0\n",
    "        t_max = 0\n",
    "\n",
    "        # Finds closest lower value of foxed_steps in t_events.\n",
    "        for steps in fixed_steps:\n",
    "            steps = round(steps, 4)\n",
    "\n",
    "            position_value = bisect.bisect_right(t_events, steps)\n",
    "\n",
    "            if position_value > 0:\n",
    "                position_value -= 1\n",
    "\n",
    "            S, I, R = y_data[position_value]\n",
    "\n",
    "            if I > I_max:\n",
    "                I_max = I\n",
    "                t_max = t_events[position_value]\n",
    "\n",
    "            results['S'][steps].append(S)\n",
    "            results['I'][steps].append(I)\n",
    "            results['R'][steps].append(R)\n",
    "            results['N'][steps].append(S + I + R)\n",
    "            \n",
    "        peak_infected.append([t_max, I_max])\n",
    "\n",
    "    for steps in fixed_steps:\n",
    "        results_mean['S'].append(np.mean(results['S'][steps]))\n",
    "        results_mean['I'].append(np.mean(results['I'][steps]))\n",
    "        results_mean['R'].append(np.mean(results['R'][steps]))\n",
    "        results_mean['N'].append(np.mean(results['N'][steps]))\n",
    "\n",
    "        results_stdev['S'].append(np.std(results['S'][steps]))\n",
    "        results_stdev['I'].append(np.std(results['I'][steps]))\n",
    "        results_stdev['R'].append(np.std(results['R'][steps]))\n",
    "        results_stdev['N'].append(np.std(results['N'][steps]))\n",
    "    \n",
    "    return results, results_mean, results_stdev, peak_infected\n",
    "\n",
    "\n",
    "def plot_mean(results, results_mean, sir):\n",
    "    \"\"\"\n",
    "    Visualizes the results from the gsp_mean function as changes in \n",
    "    population sizes over time.\n",
    "    \"\"\"\n",
    "   \n",
    "    S, I, R, N = sir\n",
    "    sir_det = [S, I, R]\n",
    "\n",
    "    S_mean = results_mean['S']\n",
    "    I_mean = results_mean['I']\n",
    "    R_mean = results_mean['R']\n",
    "    time = results['time']\n",
    "\n",
    "    time_2, S, I, R = run_sir_det(sir_det, parameters, N, t_span)\n",
    "    \n",
    "    plt.plot(time, S_mean, label='S mean', color='blue')\n",
    "    plt.plot(time, I_mean, label='I mean', color='red')\n",
    "    plt.plot(time, R_mean, label='R mean', color='green')\n",
    "    plt.plot(time_2, S, label='S deterministic', color='blue', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(time_2, I, label='I deterministic', color='red', \n",
    "             linestyle='dashed')\n",
    "    plt.plot(time_2, R, label='R deterministic', color='green', \n",
    "             linestyle='dashed')\n",
    "\n",
    "    time_steps_S = []\n",
    "    time_steps_I = []\n",
    "    time_steps_R = []\n",
    "    S_values = []\n",
    "    I_values = []\n",
    "    R_values = []\n",
    "\n",
    "    for time_step, values in results['S'].items():\n",
    "        for value in values:\n",
    "            time_steps_S.append(time_step)\n",
    "            S_values.append(value)\n",
    "    \n",
    "    for time_step, values in results['I'].items():\n",
    "        for value in values:\n",
    "            time_steps_I.append(time_step)\n",
    "            I_values.append(value)\n",
    "\n",
    "    for time_step, values in results['R'].items():\n",
    "        for value in values:\n",
    "            time_steps_R.append(time_step)\n",
    "            R_values.append(value)\n",
    "\n",
    "    plt.scatter(time_steps_S, S_values, alpha=0.03, linewidths=0, \n",
    "                color='blue', marker='o', label='S values', s=1)\n",
    "    plt.scatter(time_steps_I, I_values, alpha=0.03, linewidths=0, \n",
    "                color='red', marker='o', label='I values', s=1)\n",
    "    plt.scatter(time_steps_R, R_values, alpha=0.03, linewidths=0, \n",
    "                color='green', marker='o', label='R values', s=1)\n",
    "\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Mean Population (N)')\n",
    "    plt.legend()\n",
    "    plt.title('Epidemic Development of Deterministic and Stochastic SIR')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 1\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "# Parameters for infection, recovery and death rate\n",
    "beta = 0.6\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "parameters = [beta, gamma, mu]\n",
    "\n",
    "t_span = 100\n",
    "runs = 100\n",
    "\n",
    "results, results_mean, results_stdev, _ = gsp_mean(runs, t_span, sir, parameters);\n",
    "plot_mean(results, results_mean, sir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8590f50",
   "metadata": {},
   "source": [
    "Stoc res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18546bd",
   "metadata": {},
   "source": [
    "### 3.4 R0 vs Extinction Events\n",
    "\n",
    "The following cell computes the number of extinctions for varying R0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab711086",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "\n",
    "\n",
    "def generate_large_R0(num_samples, R0_range=(1.1, 5), gamma_value=0.1):\n",
    "    \"\"\"\n",
    "    Generates beta and gamma pairs such that the R0 values range \n",
    "    from 1.1 to 5.\n",
    "    \n",
    "    Arguments:\n",
    "        num_samples: Number of beta/gamma pairs to generate.\n",
    "        R0_range: Range for R0 values.\n",
    "        gamma_value: Fixed value for gamma.\n",
    "    \n",
    "    Returns:\n",
    "        Lists of beta gamma pairs and R0 values.\n",
    "    \"\"\"\n",
    "    \n",
    "    R0_vals = np.linspace(R0_range[0], R0_range[1], num_samples)\n",
    "    \n",
    "    # Use a fixed gamma value, and calculate corresponding beta = R0 * gamma\n",
    "    gammas = np.full(num_samples, gamma_value)\n",
    "    betas = R0_vals*gammas \n",
    "    beta_gamma_pairs = list(zip(betas, gammas))\n",
    "    \n",
    "    return beta_gamma_pairs, R0_vals\n",
    "\n",
    "\n",
    "def count_R0_extinctions(pairs, num_runs):\n",
    "    \"\"\"\n",
    "    Counts the number of epidemic extinctions for each R0 pair for \n",
    "    multiple simulation runs. Extinctions are valid when below a \n",
    "    specified threshold.\n",
    "\n",
    "    Arguments:\n",
    "        pairs: List containing beta and gamma values for each R0.\n",
    "        num_runs: Number of simulation runs for each (beta, gamma) pair.\n",
    "\n",
    "    Returns:\n",
    "        A list containing the number of observed extinctions for each \n",
    "        (beta, gamma) pair.\n",
    "    \"\"\"\n",
    "\n",
    "    extinction_list = []\n",
    "\n",
    "    for beta, gamma in pairs:\n",
    "        num_extinctions = 0\n",
    "    \n",
    "        for _ in range(num_runs):\n",
    "                result = gsp(sir, beta, gamma, mu, t_span)\n",
    "                y_data = np.array(result[1])\n",
    "\n",
    "                I = y_data[:, 1]\n",
    "\n",
    "                mean = np.mean(I)\n",
    "                print(mean)\n",
    "\n",
    "                if mean < 1e-2:\n",
    "                    num_extinctions += 1\n",
    "\n",
    "        extinction_list.append(num_extinctions)\n",
    "\n",
    "    return extinction_list\n",
    "        \n",
    "\n",
    "def plot_results_R0(num_pairs, num_runs):\n",
    "    \"\"\"\n",
    "    Generates a plot for the average number of extinctions across a \n",
    "    range of R0 values.\n",
    "\n",
    "    Arguments:\n",
    "        num_pairs: Number of (beta, gamma) pairs to generate.\n",
    "        num_runs: Number of simulation runs to make for each pair.\n",
    "\n",
    "    Returns:\n",
    "        None. Displays a bar plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate parameters and count extinctions\n",
    "    sample_pairs, sample_R0_vals = generate_large_R0(num_pairs)\n",
    "    R0_extinctions = count_R0_extinctions(sample_pairs, num_runs)\n",
    "\n",
    "    # Sort R0 values and corresponding extinctions\n",
    "    R0_extinction_pairs = list(zip(sample_R0_vals, R0_extinctions))\n",
    "    sorted_R0_extinction_pairs = sorted(R0_extinction_pairs)\n",
    "\n",
    "    sorted_R0_vals, sorted_extinctions = zip(*sorted_R0_extinction_pairs)\n",
    "\n",
    "    # Scatter Plotting\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(sorted_R0_vals, sorted_extinctions, color='blue', edgecolor='black')\n",
    "    plt.xlabel(r\"$R_0$ Value\")\n",
    "    plt.ylabel(\"Total Extinctions\")\n",
    "    plt.title(r\"$R_0$ vs Total Extinctions\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('R0vsext.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num_pairs = 20\n",
    "num_runs = 50\n",
    "mu = 0.0001\n",
    "\n",
    "plot_results_R0(num_pairs, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0e80a",
   "metadata": {},
   "source": [
    "### 3.5 N vs Extinction Events\n",
    "\n",
    "Similar to the cell above. We again count the number of extinctions. This time, however, we vary N.\n",
    "Please note: Runtime is about 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04092cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "\n",
    "\n",
    "def generate_populations(num_pops):\n",
    "    \"\"\"Generate evenly space populations.\"\"\"\n",
    "\n",
    "    populations = []\n",
    "    \n",
    "    # Evenly distributes populations from 100 to 10,000.\n",
    "    S_0 = np.linspace(100, 10000, num_pops)\n",
    "\n",
    "    for i in range(num_pops):\n",
    "        S = S_0[i]\n",
    "        I = 1\n",
    "        R = 0\n",
    "        N = S + I\n",
    "        sir = (S, I, R, N)\n",
    "        populations.append(sir)\n",
    "    \n",
    "    return populations\n",
    "\n",
    "\n",
    "def count_N_extinctions(num_pops, num_runs):\n",
    "    \"\"\"Count the number of extinctions per population\"\"\"\n",
    "\n",
    "    populations = generate_populations(num_pops)\n",
    "    extinction_list = []\n",
    "\n",
    "    for pop in populations:\n",
    "        num_extinctions = 0\n",
    "        for _ in range(num_runs):\n",
    "            result = gsp(pop, beta, gamma, mu, t_span)\n",
    "            y_data = np.array(result[1])\n",
    "            I = y_data[:, 1]\n",
    "            mean = np.mean(I)\n",
    "\n",
    "            # Treats any value below a small threshold as extinction.\n",
    "            if mean < 1e-3:\n",
    "                num_extinctions += 1\n",
    "        \n",
    "        extinction_list.append(num_extinctions)\n",
    "    \n",
    "    return extinction_list\n",
    "\n",
    "\n",
    "def plot_results_N(num_pops, num_runs):\n",
    "    \"\"\"Plot results as scatter plot of total extinctions per population size.\"\"\"\n",
    "    \n",
    "    sample_pops = generate_populations(num_pops)\n",
    "    N_extinctions = count_N_extinctions(num_pops, num_runs)\n",
    "\n",
    "    # Extract population sizes (N) and extinction counts\n",
    "    population_sizes = [pop[3] for pop in sample_pops]  # Extract N values\n",
    "\n",
    "    # Scatter Plotting\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(population_sizes, N_extinctions, color='blue', edgecolor='black')\n",
    "    plt.xlabel(\"Population Size\")\n",
    "    plt.ylabel(\"Total Extinctions\")\n",
    "    plt.title(\"Population Size vs Total Extinctions\")\n",
    "    plt.savefig(\"Nvsext.png\", dpi=150)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parameters\n",
    "beta = 0.4\n",
    "gamma = 0.1\n",
    "mu = 0.0001\n",
    "\n",
    "num_pops = 20\n",
    "num_runs = 50\n",
    "\n",
    "plot_results_N(num_pops, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e3585",
   "metadata": {},
   "source": [
    "### 3.6 Extinctions as a Function of R0 and N\n",
    "\n",
    "Here, we look at how both N and R0 interact, leading to different rates of extinction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(54)\n",
    "\n",
    "def plot_results_R0_N(num_pairs, num_pops, num_runs):\n",
    "    \"\"\"Plot a 3D bar chart of extinction counts across R0 values and \n",
    "    population sizes.\n",
    "    \"\"\"\n",
    "\n",
    "    sample_pairs, sample_R0_vals = generate_large_R0(num_pairs)\n",
    "    populations = generate_populations(num_pops)\n",
    "    extinction_data = []\n",
    "\n",
    "    for (beta, gamma), R0 in zip(sample_pairs, sample_R0_vals):\n",
    "        for pop in populations:\n",
    "            num_extinctions = 0\n",
    "            for _ in range(num_runs):\n",
    "                result = gsp(pop, beta, gamma, mu, t_span)\n",
    "                y_data = np.array(result[1])\n",
    "                I = y_data[:, 1]\n",
    "                mean = np.mean(I)\n",
    "                if mean < 1e-2: \n",
    "                    num_extinctions += 1\n",
    "\n",
    "            N = pop[0] + pop[1] + pop[2]\n",
    "            extinction_data.append((N, R0, num_extinctions))\n",
    "\n",
    "    # Convert to numpy array for easier indexing\n",
    "    extinction_data = np.array(extinction_data)\n",
    "\n",
    "    # Separate data for plotting\n",
    "    N_values = extinction_data[:, 0]\n",
    "    R0_values = extinction_data[:, 1]\n",
    "    extinction_counts = extinction_data[:, 2]\n",
    "\n",
    "    # Plot 3D bar chart\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    dx = dy = 50\n",
    "    dz = extinction_counts\n",
    "\n",
    "    ax.bar3d(N_values, R0_values, np.zeros(len(dz)), dx, dy, dz, shade=True, color='teal')\n",
    "    \n",
    "    ax.set_xlabel('Population Size (N)')\n",
    "    ax.set_ylabel('R0 Value')\n",
    "    ax.set_zlabel('Number of Extinctions')\n",
    "    ax.set_title('Interaction between R0 and N in Extinctions')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Parameters\n",
    "num_pairs = 20\n",
    "num_pops = 20\n",
    "num_runs = 20\n",
    "mu = 0.0001\n",
    "\n",
    "# Execute the plotting function\n",
    "plot_results_R0_N(num_pairs, num_pops, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17600feb",
   "metadata": {},
   "source": [
    "### 3.7 Stochastic Resonance\n",
    "By visualizing the stochastic SIR model and deterministic models together, we may note how the stochastic model fluctuates around the deterministic model. To take a closer look at this relation between the two, we plot the two against each other for different values of R indicating an epidemic and endemic situation (R = 3, R = 1, R = 0.5)\n",
    "\n",
    "Since the stochastic value may generate different values ech run, we plot multiple stochastic graphs to one deterministic to also understand how they differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091299a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "\n",
    "\n",
    "def plot_sir_stoc(sir, parameters, t_span, R0):\n",
    "    \"\"\"Plots the deterministic vs stochastic sir models to visualize \n",
    "    stocastic resonance.\n",
    "    \"\"\"\n",
    "\n",
    "    S, I, R, N = sir\n",
    "    sir_det = [S, I, R]\n",
    "    beta, gamma, mu = parameters\n",
    "\n",
    "    # Retrieves and plots the deterministic model.\n",
    "    time, _, I_det, _ = run_sir_det(sir_det, parameters, N, t_span)\n",
    "    plt.plot(time, I_det, label='I (Deterministic)', color='blue', linestyle='dashed')\n",
    "\n",
    "    # Retrieves and plots the stochastic model 5 times.\n",
    "    for index in range(5):\n",
    "        t_events, y_data = gsp(sir, beta, gamma, mu, t_span)\n",
    "        y_data = np.array(y_data)\n",
    "\n",
    "        I_gsp = y_data[:, 1]\n",
    "\n",
    "        if index == 0:\n",
    "            plt.plot(t_events, I_gsp, alpha=0.5, label='I (GSP)', color='blue', linewidth=0.5)\n",
    "        else:\n",
    "            plt.plot(t_events, I_gsp, alpha=0.5, color='blue', linewidth=0.5)\n",
    "    \n",
    "    if R0 < 1:\n",
    "        plt.ylim(0, 100)\n",
    "    else:\n",
    "        plt.ylim(0, 300)\n",
    "\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Population (I)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Stochastic resonance for R = {R0}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Intitial population sizes\n",
    "N = 500\n",
    "S = N - 10\n",
    "I = N - S\n",
    "R = 0\n",
    "sir = [S, I, R, N]\n",
    "\n",
    "t_span = 100\n",
    "gamma = 0.1\n",
    "mu = 0.05\n",
    "\n",
    "# Plot stoc resenance for R0 = 3\n",
    "R0 = 3\n",
    "beta = R0 * (gamma + mu)\n",
    "parameters = [beta, gamma, mu]\n",
    "plot_sir_stoc(sir, parameters, t_span, R0)\n",
    "\n",
    "# Plot stoc resenance for R0 = 1\n",
    "R0 = 1\n",
    "beta = R0 * (gamma + mu)\n",
    "parameters = [beta, gamma, mu]\n",
    "plot_sir_stoc(sir, parameters, t_span, R0)\n",
    "\n",
    "# Plot stoc resenance for R0 = 0.5\n",
    "R0 = 0.5\n",
    "beta = R0 * (gamma + mu)\n",
    "parameters = [beta, gamma, mu]\n",
    "plot_sir_stoc(sir, parameters, t_span, R0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc28e84",
   "metadata": {},
   "source": [
    "# SIR in Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4c1a9",
   "metadata": {},
   "source": [
    "## 1. Barabasi Albert Network \n",
    "A Barabasi-Albert (BA) network is a scale-free network.This network aaplies a prefferential attachment method meaning that nodes who are more connected are more likely to aquire new edges. New nodes are therefore more likely to connect to existing nodes with a higher degree of connection.\n",
    "\n",
    "For clarification: The '0' status is equivalent to 'susceptible', '1' is equivalent to 'infected' and '2' means 'removed'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da41b8",
   "metadata": {},
   "source": [
    "### 1.1 Barabasi Albert Network\n",
    "With the help of the NetworkX library a random graph using the BA method of attaching nodes is created. By supplying the graph to the Network Diffusion Library (NDlib), a SIR model is created through setting up the appropriate parameters through functions supplied by the Configuration class of NDLib. The model is iterated t_span amount of times, after which the appropriate data is returned. To create a BA network, we supply a variable m which indicates the number of edges to attach from a new node to an existing node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f28880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barabasi_albert(N, m, beta, gamma, I0, t_span):\n",
    "    \"\"\"\n",
    "    This function generates a Barabasi-Albert (scale-free) network model. \n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes.\n",
    "        m: Number of edges to attach from new node to existing node. \n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Initial number of infected nodes.\n",
    "        t_span: Number of iterations to execute the model.\n",
    "\n",
    "    Returns:\n",
    "        Lists for the number of iterations generated by the model and \n",
    "        data concerning the S, I and R populations of each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    ba_graph = nx.barabasi_albert_graph(N, m)\n",
    "    model = ep.SIRModel(ba_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)  \n",
    "    config.add_model_parameter('gamma', gamma)  \n",
    "    config.add_model_parameter(\"fraction_infected\", I0)  \n",
    "\n",
    "    model.set_initial_status(config)\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "    \n",
    "    y_data = []  \n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:  \n",
    "                S_count += 1\n",
    "            elif state == 1:  \n",
    "                I_count += 1\n",
    "            elif state == 2:  \n",
    "                R_count += 1\n",
    "        \n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2501d",
   "metadata": {},
   "source": [
    "### 1.2 Barabasi Albert Network Parameter Sweep\n",
    "In order to understand the effect of supplying different values for m, a parameter sweep is performed by generating a list of values for m. Additionally, we also want to compare this with changing values for the basic reproductive number (R0). List for these parameters are supplied to a function that will iterate over the lists in seperate functions and run the Barabasi-Albert (BA) network for each value set a specified of times. Data from the BA network is returned and lists of the maximum mean and standard deviations of the number of infected nodes is generated. These values can then be supplied to another function to plot the result and visualize the effect of changing these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fa1ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ba_m_sweep(N, m_values, beta, gamma, I0, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Generates a Barabasi-Albert (BA) network for different values of m \n",
    "    and finds the mean maximum and standard deviation of the number of \n",
    "    infected nodes per run.\n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes\n",
    "        m_values: List of m values.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Percentage of initially infected nodes.\n",
    "        t_span: Number of iterations inside BA network.\n",
    "        num_runs: Number of iterations of BA network.\n",
    "\n",
    "    Returns:\n",
    "        A list of maximum mean and standard deviations of the number of \n",
    "        infected nodes per run.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_max_values = []\n",
    "    std_max_values = []\n",
    "\n",
    "    # Iterate over all values for m to generate a BA network.\n",
    "    for m in m_values:\n",
    "        max_I_values = []\n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = barabasi_albert(N, m, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values\n",
    "\n",
    "\n",
    "def plot_ba_m_sweep(N, m_values, beta_values, gamma_values, I0, t_span, \n",
    "                    num_runs):\n",
    "    \"\"\"Visualizes data for the parameter sweeps of the BA network.\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        mean_max_values, std_max_values = ba_m_sweep(N, m_values, beta, gamma, \n",
    "                                                     I0, t_span, num_runs)\n",
    "        R0 = beta/gamma\n",
    "\n",
    "        label = f'R = {R0:.1f} ( = {beta:.1f},  = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(m, mean_max_values, yerr=std_max_values, fmt='-o', \n",
    "                     capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Number of edges (m)\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\n",
    "        \"Mean Maximum Infected Nodes vs Number of Edges\" \n",
    "        \"for Different R Values\"\n",
    "        )\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, N)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ba_m_vs_R0(N, m_values, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    \"\"\"This function generates a list for combinations of beta and gamma \n",
    "    values based on a supplied list of gamma and R0 values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    \n",
    "    plot_ba_m_sweep(N, m_values, beta_values, gamma_values, I0, t_span, \n",
    "                    num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "m_values = np.arange(1, 11, 1)\n",
    "R0_values = [0.5, 1.0, 2.5] \n",
    "gamma_values = [0.1, 0.2, 0.2]\n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "ba_m_vs_R0(N, m_values, I0, t_span, num_runs, R0_values, gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f67808",
   "metadata": {},
   "source": [
    "## 2. Watts-Strogatz\n",
    "In a Watts-Strogatz network model a random graph of small-world properties is generated. The model interpolates between a randomized structure and ring lattice by generating a ring lattice with N nodes and connecting each node with k number of it's nearest neighbors on either side of the node. Nodes are rewired with a probability p. This typically generates short path lengths and high clustering.\n",
    "\n",
    "stox res increases for larger pop n etc, plotting stochastic vs det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692cfce",
   "metadata": {},
   "source": [
    "### 2.1 Watts-Strogatz Network\n",
    "To create the model a graph of a WS network is created with the NetworkX library by supplying WS specific parameters k and p. The graph is passed to NDLib to create a SIR Model. A configuration class is initialized to which parameters are given to build the SIR model through built-in class functions. The SIR model is generated by iterating over it a set number of times and changing the SIR populations accordingly. The data of each S, I and R population is gathered along the appropriate time steps and returned. Creation of the WS graph is specifically dependent on parameters k (Number of nearest neighbors to connect a node in ring topology) and p (Rewiring probability of each edge) and the number of nodes which are all supplied to the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f12f0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watts_strogatz(N, k, p, beta, gamma, I0, t_span):\n",
    "    \"\"\"\n",
    "    Generates a Watts-Strogatz (WA) network model graph and gathers data on S, \n",
    "    I and R populations.\n",
    "\n",
    "    Arguments:\n",
    "        N: number of nodes.\n",
    "        k: Number of nearest neighbors to connect a node in ring topology.\n",
    "        p: Rewiring probability of each edge.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Initial percentage of infected nodes.\n",
    "        t_span: Number of iterations to execute the model.\n",
    "\n",
    "    Returns: \n",
    "        Lists for the number of iterations generated by the model and \n",
    "        data concerning the S, I and R populations of each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    ws_graph = nx.watts_strogatz_graph(N, k, p)\n",
    "    model = ep.SIRModel(ws_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", I0)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "    \n",
    "    y_data = []\n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:\n",
    "                S_count += 1\n",
    "            elif state == 1:\n",
    "                I_count += 1\n",
    "            elif state == 2:\n",
    "                R_count += 1\n",
    "        \n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "k = 6    # Number of neighbors to rewire\n",
    "p = 0.1    # Rewiring probability\n",
    "t_span = 200\n",
    "\n",
    "results = watts_strogatz(N, k, p, beta, gamma, I0, t_span)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3d26d",
   "metadata": {},
   "source": [
    "### 2.2 Watts-Strogatz Network parameter Sweep \n",
    "As with the BA network, a parameter sweep for network specific parameters was performed. Parameters were changed for k and R0. The sweeps were set up similarly to the BA network sweep with the only changes being instead of m, k is varied. R0 are varied for both. Again, lists of the maximum mean and standard deviations of the number of infected nodes is generated and can subsequently be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ed7a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_k_sweep(N, r_vals, beta, gamma, I0, t_span, num_runs, k=5):\n",
    "    \"\"\"\n",
    "    Generates a WS network for different values of k and finds the mean \n",
    "    maximum and standard deviation of the number of infected nodes per \n",
    "    run.\n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes\n",
    "        k: Number of neighbors to connect to.\n",
    "        r_values: Range of rewiring probabilities.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Percentage of initially infected nodes.\n",
    "        t_span: Number of iterations inside BA network.\n",
    "        num_runs: Number of iterations of BA network.\n",
    "\n",
    "    Returns:\n",
    "        A list of maximum mean and standard deviations of the number of \n",
    "        infected nodes per run.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_max_values = []\n",
    "    std_max_values = []\n",
    "\n",
    "    for r in r_vals:\n",
    "        max_I_values = []\n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = watts_strogatz(N, k, r, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            # Get the maximum infected value in the current run\n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values\n",
    "\n",
    "\n",
    "def plot_ws_k_sweep(N, r_vals, beta_values, gamma_values, I0, t_span, num_runs):\n",
    "    \"\"\"\"Visualizes data for the parameter sweeps of the WS network.\"\"\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        \n",
    "        mean_max_values, std_max_values = ws_k_sweep(N, r_vals, beta, gamma, I0, t_span, num_runs, k=5)\n",
    "        \n",
    "        R0 = beta/gamma\n",
    "        label = f'R = {R0:.1f} ( = {beta:.1f},  = {gamma:.1f})'\n",
    "        \n",
    "        plt.errorbar(r_vals, mean_max_values, yerr=std_max_values, fmt='-o', capsize=5, label=label)\n",
    "    \n",
    "    plt.xlabel(\"Rewiring Probability\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes\")\n",
    "    plt.title(\"Mean Maximum Infected Nodes vs Number of Neighbors for Different R Values\")\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Finished\n",
    "def ws_r_vs_R0(N, r_vals, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    \"\"\"This function generates a list for combinations of beta and gamma \n",
    "    values based on a supplied list of gamma and R0 values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    plot_ws_k_sweep(N, r_vals, beta_values, gamma_values, I0, t_span, num_runs)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 300\n",
    "R0_values = [0.5, 1.0, 2.5] \n",
    "gamma_values = [0.1, 0.2, 0.2]\n",
    "r_vals = np.linspace(0.1, 0.9, 10)\n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "ws_r_vs_R0(N, r_vals, I0, t_span, num_runs, R0_values, gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e2adb",
   "metadata": {},
   "source": [
    "## 3. Erdos-Renyi\n",
    "The specified library NetworkX uses an Erdos-Renyi network model G(n,p) that generates a random graph by connecting nodes with edges. According to a parameter p, each specific edge is included into the graph. A higher p means a higher number of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2602b4a",
   "metadata": {},
   "source": [
    "### 3.1 Erdos-Renyi Network\n",
    "With the help of the NetworkX library a random graph using the ER G(n,p) method of attaching nodes is created. By supplying the graph to the Network Diffusion Library (NDlib), a SIR model is created through setting up the appropriate parameters through functions supplied by the Configuration class of NDLib. The model is iterated t_span amount of times, after which the appropriate data is returned. To create a ER network, we supply the variable p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b0b3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos_renyi(N, p, beta, gamma, I0, t_span):\n",
    "    \"\"\" \n",
    "    This function generates a ER network model. \n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes.\n",
    "        p: Probability for edge creation \n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Initial number of infected nodes.\n",
    "        t_span: Number of iterations to execute the model.\n",
    "\n",
    "    Returns:\n",
    "        Lists for the number of iterations generated by the model and \n",
    "        data concerning the S, I and R populations of each iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    er_graph = nx.erdos_renyi_graph(N, p)\n",
    "    model = ep.SIRModel(er_graph)\n",
    "\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", I0)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    iterations = model.iteration_bunch(t_span)\n",
    "\n",
    "    y_data = [] \n",
    "\n",
    "    for iteration in iterations:\n",
    "        status = iteration['status']\n",
    "        \n",
    "        S_count = 0\n",
    "        I_count = 0\n",
    "        R_count = 0\n",
    "        \n",
    "        for _, state in status.items():\n",
    "            if state == 0:\n",
    "                S_count += 1\n",
    "            elif state == 1:\n",
    "                I_count += 1\n",
    "            elif state == 2: \n",
    "                R_count += 1\n",
    "\n",
    "        y_data.append({'S': S_count, 'I': I_count, 'R': R_count})\n",
    "\n",
    "    return iterations, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16538ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "p = 0.01  # Probability for edge creation\n",
    "t_span = 50\n",
    "\n",
    "results = erdos_renyi(N, p, beta, gamma, I0, t_span)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c9084",
   "metadata": {},
   "source": [
    "### 3.2 Erdos-Reyni Network Parameter Sweep\n",
    "As with the BA and WS networks, a parameter sweep for network specific parameters was performed. Parameters were changed for p and R0. The sweeps were set up similarly to the other network sweeps. Again, lists of the maximum mean and standard deviations of the number of infected nodes is generated and can subsequently be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f0b276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_p_sweep(N, p_values, beta, gamma, I0, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Generates a ER network for different values of p and finds the mean \n",
    "    maximum and standard deviation of the number of infected nodes per \n",
    "    run.\n",
    "\n",
    "    Arguments:\n",
    "        N: Total number of nodes\n",
    "        p_values: List of p values.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        I0: Percentage of initially infected nodes.\n",
    "        t_span: Number of iterations inside BA network.\n",
    "        num_runs: Number of iterations of BA network.\n",
    "\n",
    "    Returns:\n",
    "        A list of maximum mean and standard deviations of the number of \n",
    "        infected nodes per run.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_max_values = []  \n",
    "    std_max_values = []   \n",
    "\n",
    "    for p in p_values:\n",
    "        max_I_values = []  \n",
    "        \n",
    "        for _ in range(num_runs):  \n",
    "            _, y_data = erdos_renyi(N, p, beta, gamma, I0, t_span)\n",
    "            \n",
    "            I_values = [data['I'] for data in y_data]\n",
    "            \n",
    "            max_I = max(I_values) if I_values else 0\n",
    "            max_I_values.append(max_I)\n",
    "        \n",
    "        mean_max_I = np.mean(max_I_values) if max_I_values else 0\n",
    "        std_max_I = np.std(max_I_values) if max_I_values else 0\n",
    "        \n",
    "     \n",
    "        mean_max_values.append(mean_max_I)\n",
    "        std_max_values.append(std_max_I)\n",
    "    \n",
    "    return mean_max_values, std_max_values  \n",
    "\n",
    "\n",
    "def plot_er_prob_sweep(N, p_values, beta_values, gamma_values, I0, t_span, num_runs):\n",
    "    \"\"\"\"Visualizes data for the parameter sweeps of the ER network.\"\"\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    \n",
    "    for beta, gamma in zip(beta_values, gamma_values):\n",
    "        # Calculate mean and standard deviation for each beta and gamma pair\n",
    "        mean_max_values, std_max_values = er_p_sweep(N, p_values, beta, gamma, I0, t_span, num_runs)\n",
    "        \n",
    "        # Calculate R0 and create label\n",
    "        R0 = beta / gamma\n",
    "        label = f'R = {R0:.1f} ( = {beta:.1f},  = {gamma:.1f})'\n",
    "        \n",
    "        # Plot error bars for each beta and gamma pair\n",
    "        plt.errorbar(p_values, mean_max_values, yerr=std_max_values, fmt='-o', capsize=5, label=label)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.xlabel(\"Probability p\") \n",
    "    plt.ylabel(\"Mean Maximum Infected Nodes (I)\")\n",
    "    plt.title(\"Mean Maximum Infected Nodes vs Probability for Different R Values\")\n",
    "    plt.legend()  \n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"er-sweep.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def er_prob_vs_R0(N, p_values, I0, t_span, num_runs, R0_values, gamma_values):\n",
    "    \"\"\"This function generates a list for combinations of beta and gamma \n",
    "    values based on a supplied list of gamma and R0 values.\n",
    "    \"\"\"\n",
    "\n",
    "    beta_values = [R0 * gamma for R0, gamma in zip(R0_values, gamma_values)]\n",
    "    plot_er_prob_sweep(N, p_values, beta_values, gamma_values, I0, t_span, \n",
    "                       num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aaad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "p_values = np.linspace(0.01, 0.1, 10)  \n",
    "R0_values = [0.5, 1.0, 2.5]  \n",
    "gamma_values = [0.1, 0.2, 0.2]  \n",
    "I0 = 0.01\n",
    "t_span = 50\n",
    "num_runs = 50\n",
    "\n",
    "er_prob_vs_R0(N, p_values, I0, t_span, num_runs, R0_values, gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9b3f5",
   "metadata": {},
   "source": [
    "## 4. Generating Networks and Examining Network Statistics \n",
    "\n",
    "The following code generates multiple networks of each type (ER, BA, WS). For each type, we look at the average maximum degree, average minumum degree and average clustering coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2d2d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "    \"\"\"\n",
    "    Generate networks of specified types and calculate degree statistics \n",
    "    and clustering coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        nettype: Network type to generate.\n",
    "        N: Number of nodes in the network.\n",
    "        m_vals: List of m values for BA networks.\n",
    "        p_vals: List of p values for ER networks.\n",
    "        r_vals: List of r values for WS networks, normally defined as p.\n",
    "        num_runs: Number of iterations for network generation.\n",
    "        k: Predifined k for WS networks.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing minimum and maximum mean and standard \n",
    "        deviation values for the degrees and clustering coefficients for \n",
    "        each m/p/r value.\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_min_degrees = []\n",
    "    std_min_degrees = []\n",
    "    \n",
    "    mean_max_degrees = []\n",
    "    std_max_degrees = []\n",
    "    \n",
    "    mean_degrees = []\n",
    "    std_degrees = []\n",
    "    \n",
    "    mean_clustering_coeffs = []  \n",
    "    std_clustering_coeffs = []    \n",
    "\n",
    "    if nettype == 'BA':\n",
    "        for m in m_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                ba_net = nx.barabasi_albert_graph(N, m)\n",
    "                \n",
    "                degrees = [deg for _, deg in ba_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(ba_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "\n",
    "    elif nettype == 'ER':   \n",
    "        mean_min_degrees = []\n",
    "        std_min_degrees = []\n",
    "        \n",
    "        mean_max_degrees = []\n",
    "        std_max_degrees = []\n",
    "        \n",
    "        mean_degrees = []\n",
    "        std_degrees = []\n",
    "        \n",
    "        mean_clustering_coeffs = []  \n",
    "        std_clustering_coeffs = []    \n",
    "\n",
    "        for p in p_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                er_net = nx.erdos_renyi_graph(N, p)\n",
    "                \n",
    "                degrees = [deg for _, deg in er_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(er_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "    \n",
    "    elif nettype == 'WS':\n",
    "        mean_min_degrees = []\n",
    "        std_min_degrees = []\n",
    "        \n",
    "        mean_max_degrees = []\n",
    "        std_max_degrees = []\n",
    "        \n",
    "        mean_degrees = []\n",
    "        std_degrees = []\n",
    "        \n",
    "        mean_clustering_coeffs = []  \n",
    "        std_clustering_coeffs = []    \n",
    "\n",
    "        for r in r_vals:\n",
    "            min_degrees = []\n",
    "            max_degrees = []\n",
    "            degree_sums = []\n",
    "            clustering_coeffs = []  \n",
    "\n",
    "            for _ in range(num_runs):\n",
    "                ws_net = nx.watts_strogatz_graph(N, k, r)\n",
    "                \n",
    "                degrees = [deg for _, deg in ws_net.degree()]\n",
    "\n",
    "                min_degrees.append(min(degrees))\n",
    "                max_degrees.append(max(degrees))\n",
    "                degree_sums.append(np.mean(degrees))  \n",
    "                clustering_coeffs.append(nx.average_clustering(ws_net))  \n",
    "                \n",
    "            mean_min_degrees.append(np.mean(min_degrees))\n",
    "            std_min_degrees.append(np.std(min_degrees))\n",
    "            \n",
    "            mean_max_degrees.append(np.mean(max_degrees))\n",
    "            std_max_degrees.append(np.std(max_degrees))\n",
    "\n",
    "            mean_degrees.append(np.mean(degree_sums))\n",
    "            std_degrees.append(np.std(degree_sums))\n",
    "\n",
    "            mean_clustering_coeffs.append(np.mean(clustering_coeffs))  \n",
    "            std_clustering_coeffs.append(np.std(clustering_coeffs))  \n",
    "            \n",
    "    return {\n",
    "        'mean_min_degrees': mean_min_degrees,\n",
    "        'std_min_degrees': std_min_degrees,\n",
    "        'mean_max_degrees': mean_max_degrees,\n",
    "        'std_max_degrees': std_max_degrees,\n",
    "        'mean_degrees': mean_degrees,\n",
    "        'std_degrees': std_degrees,\n",
    "        'mean_clustering_coeffs': mean_clustering_coeffs,  \n",
    "        'std_clustering_coeffs': std_clustering_coeffs      \n",
    "    }\n",
    "\n",
    "\n",
    "def plot_degree_stats(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5):\n",
    "    \"\"\"\n",
    "    Plot degree statistics for generated networks of specified types.\n",
    "\n",
    "    Parameters:\n",
    "        nettype: Network type to generate.\n",
    "        N: Number of nodes in the network.\n",
    "        m_vals: List of m values for BA networks.\n",
    "        p_vals: List of p values for ER networks.\n",
    "        r_vals: List of r values for WS networks, normally defined as p.\n",
    "        num_runs: Number of iterations for network generation.\n",
    "        k: Predifined k for WS networks.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    results = gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5)\n",
    "    \n",
    "    mean_min_degrees = results['mean_min_degrees']\n",
    "    std_min_degrees = results['std_min_degrees']\n",
    "    mean_max_degrees = results['mean_max_degrees']\n",
    "    std_max_degrees = results['std_max_degrees']\n",
    "    mean_degrees = results['mean_degrees']\n",
    "    std_degrees = results['std_degrees']\n",
    "    \n",
    "    plt.figure(figsize=(7, 4))\n",
    "\n",
    "    if nettype == 'BA':\n",
    "        plt.errorbar(m_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(m_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(m_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, \n",
    "                     label='Mean Degree', color='red')\n",
    "\n",
    "        plt.xlabel(\"m (Number of edges to attach from a new node)\")\n",
    "        plt.title(\n",
    "            \"Mean Min, Max, and Overall Degree vs m in BarabsiAlbert\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "        \n",
    "    elif nettype == 'ER':\n",
    "        plt.errorbar(p_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(p_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(p_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, \n",
    "                     label='Mean Degree', color='red')\n",
    "\n",
    "        plt.xlabel(\"p (Probability of connecting two edges)\")\n",
    "        plt.title(\n",
    "            \"Mean Min, Max, and Overall Degree vs p in ErdsRenyi\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "\n",
    "    elif nettype == 'WS':\n",
    "        plt.errorbar(r_vals, mean_min_degrees, yerr=std_min_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Min Degree', color='blue')\n",
    "\n",
    "        plt.errorbar(r_vals, mean_max_degrees, yerr=std_max_degrees, fmt='o', \n",
    "                     capsize=5, label='Mean Max Degree', color='green')\n",
    "\n",
    "        plt.errorbar(r_vals, mean_degrees, yerr=std_degrees, fmt='o', capsize=5, \n",
    "                     label='Mean Degree', color='red')\n",
    "\n",
    "        plt.xlabel(\"r (Probability of rewiring an exisint edge)\")\n",
    "        plt.title(\n",
    "            \"Mean Min, Max, and Overall Degree vs r in Watts-Strogatz\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "\n",
    "    plt.ylabel(\"Degree\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(nettype + \"-degrees.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_clustering_stats(nettype, N, m_vals, p_vals, r_vals, num_runs, \n",
    "                          k=5):\n",
    "    \"\"\"\n",
    "    Plot clustering coefficient statistics for generated networks of \n",
    "    specified types.\n",
    "\n",
    "    Parameters:\n",
    "        nettype: Network type to generate.\n",
    "        N: Number of nodes in the network.\n",
    "        m_vals: List of m values for BA networks.\n",
    "        p_vals: List of p values for ER networks.\n",
    "        r_vals: List of r values for WS networks, normally defined as p.\n",
    "        num_runs: Number of iterations for network generation.\n",
    "        k: Predifined k for WS networks.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = gen_nets(nettype, N, m_vals, p_vals, r_vals, num_runs, k=5)\n",
    "    mean_clus_c = results['mean_clustering_coeffs']\n",
    "    std_clus_c = results['std_clustering_coeffs']\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "\n",
    "    if nettype == 'BA':\n",
    "        plt.xlabel(\"m (Number of edges to attach from a new node)\")\n",
    "        plt.title(\n",
    "            \"Mean Clustering Coefficient vs m in BarabsiAlbert\" \n",
    "            \"Networks\"\n",
    "            )\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(m_vals))  \n",
    "        plt.bar(bar_positions, mean_clus_c, yerr=std_clus_c, width=bar_width, \n",
    "                alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, m_vals)  \n",
    "    \n",
    "    elif nettype == 'ER':\n",
    "        plt.xlabel(\"p (Probability of connecting two edges)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs p in Erds-Renyi Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(p_vals))  \n",
    "        plt.bar(bar_positions, mean_clus_c, yerr=std_clus_c, width=bar_width, \n",
    "                alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, np.round(p_vals, 2)) \n",
    "\n",
    "    elif nettype == 'WS':\n",
    "        plt.xlabel(\"r (Probability of rewiring an exising edge)\")\n",
    "        plt.title(\"Mean Clustering Coefficient vs r in Watts-Strogatz Networks\")\n",
    "        bar_width = 0.4  \n",
    "        bar_positions = np.arange(len(r_vals))  \n",
    "        plt.bar(bar_positions, mean_clus_c, yerr=std_clus_c, width=bar_width, \n",
    "                alpha=0.6, color='orange', label='Mean Clustering Coefficient')\n",
    "        plt.xticks(bar_positions + bar_width / 2, np.round(r_vals, 1)) \n",
    "\n",
    "    plt.ylabel(\"Clustering Coefficient\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(nettype + \"-clustering.png\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51d8dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "m_vals = np.arange(2, 23, 2)\n",
    "p_vals = np.linspace(0.01, 0.1, 10)\n",
    "r_vals = np.linspace(0.1, 0.9, 10)\n",
    "num_runs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbc8e5",
   "metadata": {},
   "source": [
    "### 4.1 BA Network Results\n",
    "Below the functions for plotting the degree and clustering statistics of the BA network models are called. Note: Runtime is around 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('BA', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('BA', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb06c7",
   "metadata": {},
   "source": [
    "### 4.2 ER Network Results\n",
    "Below the functions for plotting the degree and clustering statistics of the ER network models are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('ER', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('ER', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec243d",
   "metadata": {},
   "source": [
    "### 4.3 WS Network Results\n",
    "Below the functions for plotting the degree and clustering statistics of the WS network models are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4937de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_stats('WS', N, m_vals, p_vals, r_vals, num_runs)\n",
    "plot_clustering_stats('WS', N, m_vals, p_vals, r_vals, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaa77d",
   "metadata": {},
   "source": [
    "## 5. Dynamic Vaccination Campaign\n",
    "A network containing predetermined node and edge structure was provided to be modelled in a SIR system and to which a vaccination strategy was to be applied. To ascertain the effectiveness of the strategy, we first designed a random null strategy. The null strategy should then be outperformed by the designed strategy. \n",
    "\n",
    "Within each strategy, it is predetermined that we do not know the status of each node until a node is tested. The status a node can have is either 0 (susceptible), 1 (infected) or 2 (removed). Only susceptible nodes can be vaccinated.\n",
    "\n",
    "Certain limitations are set upon the strategy. There are a limited number of tests (200) and We can only test a specific (although not further specified) number of nodes per iteration of the SIR model. However, tests can have an accuracy rating from 0.25 ton 1.0. An inaccurate test will return a node's status as '1' when it is '0' and vice versa. We assume that recovered nodes always return the correct status. Per iteration, it is also possible to vaccinate a limited amount of susceptible people and their status is changed to removed immediately and indefinitely. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd344a4",
   "metadata": {},
   "source": [
    "### 5.1 Loading and Initializing the dataset\n",
    "First, the provided dataset is loaded correctly and initialised using the corresponding NDLib and NetworkX libraries. Edges between nodes from the dataset were generated per node. Two graphs were generated, one containg the 'true' graph data and one graph signifying the data that we know since we can only assume a node status after testing but we need the actual data for running an accurate simulation. To keep the distinction clear, we generated two graphs. To the known graph, the 'status' opf a node was added to each node such that their data is accesible. All the nodes in the 'known graph' are first set to 0 (susceptible), assuming that every node we have not tested and/or vaccinated yet is susceptible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "963b57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sociopatterns():\n",
    "    \"\"\"\n",
    "    Loads and initiates the csv file containing sociopattern information.\n",
    "    Initiates two graphs, one for actual data and one simulating what we\n",
    "    know about the data. \n",
    "    \"\"\"\n",
    "\n",
    "    edge_list = pd.read_csv(\"transmission_network.csv\", delimiter=';', \n",
    "                            index_col=0)\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    graph_known = nx.Graph()\n",
    "\n",
    "    graph.add_nodes_from(edge_list.index.tolist())\n",
    "    graph_known.add_nodes_from(edge_list.index.tolist())\n",
    "\n",
    "    # Adds edges between nodes if their weight is higher than 0.\n",
    "    for node_i, row in edge_list.iterrows():\n",
    "        for node_j, value in row.items():\n",
    "            if value > 0:\n",
    "                graph.add_edge(int(node_i), int(node_j))\n",
    "                graph_known.add_edge(int(node_i), int(node_j))\n",
    "\n",
    "    return graph, graph_known\n",
    "    \n",
    "\n",
    "def initiate_model(graph, graph_known, beta, gamma):\n",
    "    \"\"\"\" \n",
    "    Initiates SIR model on the graph (real world) and sets the status of \n",
    "    the known graph to everybody as susceptible.\n",
    "    \"\"\"\n",
    "\n",
    "    model = ep.SIRModel(graph)\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "\n",
    "    # Initiates states for all nodes in the known graph to susceptible.\n",
    "    for node in graph_known.nodes:\n",
    "        graph_known.nodes[node]['status'] = 0\n",
    "\n",
    "    # Randomly assigns 5 nodes to get infected.\n",
    "    infected = 5\n",
    "    infected_nodes = (np.random.choice(graph.nodes(), size=infected, \n",
    "                                       replace=False)).tolist()\n",
    "    config.add_model_initial_configuration('Infected', infected_nodes)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    return model, graph_known\n",
    "\n",
    "\n",
    "def update_sir_model(model, graph, iterations):\n",
    "    \"\"\"\n",
    "    Runs the SIR model for a number of times as specified by itertations.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.iteration_bunch(iterations) \n",
    "\n",
    "    return model, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a91a9",
   "metadata": {},
   "source": [
    "### 5.2 Random Null Strategy (finished)\n",
    "To evaluate our vaccination strategy, we had to implement a null strategy to compare our results with. Rather than designing a completely random stratregy, we introduced some intelligence to the strategy to simulate how a random strategy might work in real life rather than something drastically unrealistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffacba",
   "metadata": {},
   "source": [
    "First nodes are tested by generating a list that contains all known suscpetible nodes. Note from a previous statement that we assume all nodes initially as suscpetible. If there are less susceptible nodes availble then the number of tests to perform, we reset the number of tests.\n",
    "\n",
    "From the list of available nodes we randomly choose a number of nodes equivalent to the number of tests that we perform that iteration. \n",
    "\n",
    "The status of the node is retrieved from the SIRmodel class. A provided list containing the accuracy as [chance correct, chance incorrect] determines the accuracy of the tests. A status tested as '1' may therefore be shown as '0' and vice versa. The status in the known_graph will then be updated to this incorrect result and treat it as correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nodes_random(model, graph_known, tests, vac_pool, accuracy):\n",
    "    \"\"\"\n",
    "    Tests the status of randomly selected susceptible nodes, updates \n",
    "    their status accordingly and adds or removes nodes from the \n",
    "    vaccination pool.\n",
    "    \n",
    "    Arguments:\n",
    "        model: A class from NDLib to simulate a SIR model.\n",
    "        graph_known: A graph containing the assumed statuses of nodes.\n",
    "        tests: Number of maximum tests to do per iteration.\n",
    "        vac_pool: A list containing nodes ready for vaccination.\n",
    "        accuracy: A list containing accuracy scores for tests.\n",
    "        \n",
    "    Returns\n",
    "        Updated graph_known, the vaccination pool and number of tests \n",
    "        used in this iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    available_nodes = [] \n",
    "\n",
    "    # Adds people that are susceptible to a list of available nodes.\n",
    "    for node in graph_known.nodes:\n",
    "        if graph_known.nodes[node]['status'] == 0:\n",
    "            available_nodes.append(node)\n",
    "    \n",
    "    # Resets the number of tests if there are not enough available nodes.\n",
    "    if len(available_nodes) < tests:\n",
    "        tests = len(available_nodes)\n",
    "\n",
    "        # Returns the function if there are no more available nodes\n",
    "        if tests == 0:\n",
    "            return graph_known, vac_pool, tests\n",
    "\n",
    "    tested_nodes = (np.random.choice(available_nodes, size=tests, \n",
    "                                     replace=False)).tolist()\n",
    "\n",
    "    # Updates the status of the tested nodes on the known graph\n",
    "    for node in tested_nodes:\n",
    "        status = model.status[node]\n",
    "\n",
    "        if status == 0:\n",
    "            status = np.random.choice([status, 1], p=accuracy)\n",
    "        elif status == 1:\n",
    "            status = np.random.choice([status, 0], p=accuracy)\n",
    "            \n",
    "        graph_known.nodes[node]['status'] = status\n",
    "\n",
    "        # Adds to or removes nodes from the vaccination pool.\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "\n",
    "        elif status != 0 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "\n",
    "    return graph_known, vac_pool, tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf49d2",
   "metadata": {},
   "source": [
    "Nodes are vacinated randomly from the vaccination pool as generated during the testing phase. The status of these nodes is then updated accordingly. If the current status of vacccinated node is not o (susceptible), the status is only updated to removed in the known graph. The vaccinated node is removed from the vaccination pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf979ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vac_nodes_random(model, graph_known, vac_budget, vac_pool):\n",
    "    \"\"\"Vaccinates nodes randomly according to a supplied list of a pool \n",
    "    of vaccination candidates. Updates statuses accordingly. If a node \n",
    "    status is not actually susceptible, their status is not changed.\n",
    "    \n",
    "    Arguments:\n",
    "        model: A class from NDLib to simulate a SIR model.\n",
    "        graph_known: A graph containing the assumed statuses of nodes.\n",
    "        tests: Number of maximum tests to do per iteration.\n",
    "        vac_pool: A list containing nodes ready for vaccination.\n",
    "        \n",
    "    Returns:\n",
    "        The updated model with correct statuses, graph_known with assumed \n",
    "        statuses and vac_pool from which vacinated nodes are removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # If there are not enough Susceptible people, reset the vaccination budget.\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    # Randomly choose susceptible people to vaccinate\n",
    "    vac_nodes = (np.random.choice(vac_pool, size=vac_budget, \n",
    "                                  replace=False)).tolist()\n",
    "\n",
    "    # Update all statuses of vaccinated nodes to 'Removed' if possible.\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated from the vaccination pool.\n",
    "        vac_pool = [node for node in vac_pool if node not in vac_nodes]\n",
    "\n",
    "    return model, graph_known, vac_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e3663",
   "metadata": {},
   "source": [
    "The random null strategy campaign first stores initial statuses of nodes in the results. Then, the strategy tests first before vaccinating tested nodes. Afterwards it will iterate over the SIR model to update node statusses accordingly. Results of the current iteration are recorded and saved. This will repeated for a predetermined time span in a while loop until the timespan has passed. \n",
    "The campaign is simulated for a specified number of runs (num_runs) to gather a number of maximum values of the infected population per run. A mean and standard deviation will be calculated and returned with the list of maximum values for the number of nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2bd7326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_campaign(test_max, beta, gamma, t_span):\n",
    "    \"\"\"Runs the random network model null simulation for a number of \n",
    "    iterations as specified by t_span and stores data for later \n",
    "    visualization. \n",
    "\n",
    "    Arguments:\n",
    "        test_max: MAximum number of tests per iteration.\n",
    "        beta: Parameter for infection rate.\n",
    "        gamma: Parameter for recovery rate.\n",
    "        t_span: Time span to run the simulation.\n",
    "\n",
    "    Returns:\n",
    "        The generated results as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "    vac_budget = 5\n",
    "    accuracy = [0.75, 0.25]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    infected_count = sum(1 for node in model.status if model.status[node] == 1)\n",
    "    susceptible_count = sum(1 for node in model.status if model.status[node] == 0)\n",
    "    removed_count = sum(1 for node in model.status if model.status[node] == 2)\n",
    "\n",
    "    results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "            })\n",
    "\n",
    "    # Tests, vaccinates and riterates the SIR Model.\n",
    "    while t <= t_span:\n",
    "\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, tests = test_nodes_random(model, graph_known, \n",
    "                                                             test_max, vac_pool, accuracy)\n",
    "            \n",
    "            # Updates the total number of tests left.\n",
    "            total_tests -= tests\n",
    "            \n",
    "        model, graph_known, vac_pool = vac_nodes_random(model, graph_known, \n",
    "                                                        vac_budget, vac_pool)\n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        # Stores the current states of the model.\n",
    "        infected_count = sum(1 for node in model.status if model.status[node] == 1)\n",
    "        susceptible_count = sum(1 for node in model.status if model.status[node] == 0)\n",
    "        removed_count = sum(1 for node in model.status if model.status[node] == 2)\n",
    "\n",
    "        t += 1\n",
    "        \n",
    "        results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def simulate_random_campaign(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"Simulates the random campaign to generate the maximum values for \n",
    "    the number of infected and calculates the mean and standard \n",
    "    deviations.\n",
    "    \"\"\"\n",
    "\n",
    "    max_I_vals = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        results = random_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_counts = [entry['infected'] for entry in results]\n",
    "        max_I = max(infected_counts)\n",
    "        max_I_vals.append(max_I)\n",
    "    \n",
    "    mean_max_I = np.mean(max_I_vals)\n",
    "    std_max_I = np.std(max_I_vals)\n",
    "\n",
    "    return max_I_vals, mean_max_I, std_max_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 5\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 10\n",
    "num_runs = 5\n",
    "\n",
    "simulate_random_campaign(test_max, beta, gamma, t_span, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f7f44",
   "metadata": {},
   "source": [
    "### 5.3 Vaccinating Largest Hubs First Strategy\n",
    "\n",
    "TODO MARVIN explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f8834eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_nodes():\n",
    "    \"\"\"\n",
    "    Initiates graph and sorts nodes based on the amount of neighbors \n",
    "    they have.\n",
    "    \"\"\"\n",
    "   \n",
    "    graph, _ = load_sociopatterns()\n",
    "    nodes = [(node, graph.degree(node)) for node in graph]\n",
    "    sorted_nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_nodes\n",
    "    \n",
    "\n",
    "def test_hubs(model, graph_known, tests, vac_pool, accuracy):\n",
    "    \"\"\"\n",
    "    Checks available nodes and sorts nodes to test according to their \n",
    "    degree scores. Tests the status of the selected top nodes, updates \n",
    "    their status accordingly and adds or removes nodes from the \n",
    "    vaccination pool.\n",
    "    \n",
    "    Arguments:\n",
    "        model: A class from NDLib to simulate a SIR model.\n",
    "        graph_known: A graph containing the assumed statuses of nodes.\n",
    "        tests: Number of maximum tests to do per iteration.\n",
    "        vac_pool: A list containing nodes ready for vaccination.\n",
    "        accuracy: A list containing accuracy scores for tests.\n",
    "        \n",
    "    Returns\n",
    "        Updated graph_known, the vaccination pool and number of tests \n",
    "        used in this iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    sorted_nodes = sort_nodes()\n",
    "    available_nodes = []\n",
    "  \n",
    "    # Adds people that are susceptible to available nodes\n",
    "    for node in graph_known.nodes:\n",
    "        if graph_known.nodes[node]['status'] == 0:\n",
    "            available_nodes.append(node)\n",
    "    \n",
    "    # Resets number of tests if there are not enough available nodes\n",
    "    if len(available_nodes) < tests:\n",
    "        tests = len(available_nodes)\n",
    "\n",
    "        if tests == 0:\n",
    "            return graph_known, vac_pool, tests\n",
    "    \n",
    "    # Selects a limited number of nodes to test if they are available.\n",
    "    top_nodes = [node for node, _ in sorted_nodes if node in \n",
    "                 available_nodes][:tests]\n",
    "    \n",
    "    for node in top_nodes:\n",
    "        status = model.status[node]\n",
    "\n",
    "        # Returns the correct node status with specified accuracy.\n",
    "        if status == 0:\n",
    "            status = np.random.choice([status, 1], p=accuracy)\n",
    "        elif status == 1:\n",
    "            status = np.random.choice([status, 0], p=accuracy)\n",
    "            \n",
    "        graph_known.nodes[node]['status'] = status\n",
    "\n",
    "        # Adds to or removes nodes from the vaccination pool.\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "\n",
    "        elif status != 0 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "\n",
    "    return graph_known, vac_pool, tests\n",
    "\n",
    "\n",
    "def vac_hubs(model, graph_known, vac_budget, vac_pool):\n",
    "    \"\"\"Vaccinates nodes according to a supplied list of a pool \n",
    "    of vaccination candidates. Updates statuses accordingly. If a node \n",
    "    status is not actually susceptible, their status is not changed.\n",
    "    \n",
    "    Arguments:\n",
    "        model: A class from NDLib to simulate a SIR model.\n",
    "        graph_known: A graph containing the assumed statuses of nodes.\n",
    "        tests: Number of maximum tests to do per iteration.\n",
    "        vac_pool: A list containing nodes ready for vaccination.\n",
    "        \n",
    "    Returns:\n",
    "        The updated model with correct statuses, graph_known with assumed \n",
    "        statuses and vac_pool from which vacinated nodes are removed.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    # Choose largest susceptible hubs.\n",
    "    vac_nodes = vac_pool[0:vac_budget]\n",
    "\n",
    "    # Update statuses of vaccinated nodes to 'Removed'.\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        # Only remove people who are not currently infected or removed.\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated nodes from the vaccination pool.\n",
    "        vac_pool = [node for node in vac_pool if node not in vac_nodes]\n",
    "\n",
    "    return model, graph_known, vac_pool\n",
    "\n",
    "\n",
    "def hub_campaign(test_max, beta, gamma, t_span):\n",
    "    \"\"\"Runs the hub vaccination campaign simulation for a number of \n",
    "    iterations as specified by t_span and stores data for later \n",
    "    visualization. \n",
    "\n",
    "    Arguments:\n",
    "        test_max: MAximum number of tests per iteration.\n",
    "        beta: Parameter for infection rate.\n",
    "        gamma: Parameter for recovery rate.\n",
    "        t_span: Time span to run the simulation.\n",
    "\n",
    "    Returns:\n",
    "        The generated results as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "    results = []\n",
    "    vac_budget = 5\n",
    "    accuracy = [0.75, 0.25] \n",
    "\n",
    "    # Loads and initializes all data, makes graph of known statuses \n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    # Store the current state of the model.\n",
    "    infected_count = sum(1 for node in model.status \n",
    "                         if model.status[node] == 1)\n",
    "    susceptible_count = sum(1 for node in model.status \n",
    "                            if model.status[node] == 0)\n",
    "    removed_count = sum(1 for node in model.status \n",
    "                        if model.status[node] == 2)\n",
    "\n",
    "    results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "        })\n",
    "\n",
    "    # Tests, vaccinates and simulates SIR for a set number of iterations.\n",
    "    while t <= t_span:\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, tests = test_hubs(model, graph_known, \n",
    "                                                     test_max, vac_pool, \n",
    "                                                     accuracy)\n",
    "            total_tests -= tests\n",
    "            \n",
    "        model, graph_known, vac_pool = vac_hubs(model, graph_known, \n",
    "                                                vac_budget, vac_pool)\n",
    "        \n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        infected_count = sum(1 for node in model.status \n",
    "                             if model.status[node] == 1)\n",
    "        susceptible_count = sum(1 for node in model.status \n",
    "                                if model.status[node] == 0)\n",
    "        removed_count = sum(1 for node in model.status \n",
    "                            if model.status[node] == 2)\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def simulate_hub_campaign(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"Simulates the hub campaign to generate the maximum values for \n",
    "    the number of infected and calculates the mean and standard \n",
    "    deviations.\n",
    "    \"\"\"\n",
    "\n",
    "    max_I_vals = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        results = hub_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_counts = [entry['infected'] for entry in results]\n",
    "        max_I = max(infected_counts)\n",
    "        max_I_vals.append(max_I)\n",
    "    \n",
    "    mean_max_I = np.mean(max_I_vals)\n",
    "    std_max_I = np.std(max_I_vals)\n",
    "\n",
    "    return max_I_vals, mean_max_I, std_max_I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebd926",
   "metadata": {},
   "source": [
    "### 5.4 Highest Score First Strategy\n",
    "As we saw a general improvement where the total number of infected individuals is, on average, lower than the null campaign. We wanted to find the significance of adding more score baseed assesments to a vaccination strategy. We chose to assess the Closeness, betweenness and adjecency. \n",
    "\n",
    "Adjacency measures the number of edges that a node has. Nodes with high adjacency connect to many neighbors.\n",
    "\n",
    "Closeness indicates how quickly a node can reach others in the network. High closeness indicates that nodes have a short average path length to other nodes.\n",
    "\n",
    "Betweenness indicates how often a node lies on the shortest path between other nodes. Nodes with high betweenness serve as bridges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2a8e0",
   "metadata": {},
   "source": [
    "Scores for each are calculated seperately and the scopres are sorted from highest to lowest. Scores are then scaled to the highest value such that theirt values range from 1 to 0. Finally, all scores are added per node and the scores are resorted with the scores lying between 3 and the 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e9a7e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_closeness(graph):\n",
    "    \"\"\"Calculates the closeness of each node and returns a sorted \n",
    "    list with scaled scores.\n",
    "    \"\"\"\n",
    "\n",
    "    closeness = nx.closeness_centrality(graph)\n",
    "    sort_clo = sorted(closeness.items(), key=lambda x: x[1], reverse=True)\n",
    "    clo_scores = assign_scores(sort_clo)\n",
    "\n",
    "    return clo_scores\n",
    "\n",
    "\n",
    "def calc_betweenness(graph):\n",
    "    \"\"\"Calculates the betweenness of each node and returns a sorted \n",
    "    list with scaled scores.\n",
    "    \"\"\"\n",
    "\n",
    "    betweenness = nx.betweenness_centrality(graph)\n",
    "    sort_bet = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "    bet_scores = assign_scores(sort_bet)\n",
    "\n",
    "    return bet_scores\n",
    "\n",
    "\n",
    "def calc_adjecency(graph):\n",
    "    \"\"\"Calculates the adjecency of each node and returns a sorted \n",
    "    list with scaled scores.\n",
    "    \"\"\"\n",
    "\n",
    "    adjecency = dict(graph.degree())\n",
    "    sort_adj = sorted(adjecency.items(), key=lambda x: x[1], reverse=True)\n",
    "    adj_scores = assign_scores(sort_adj)\n",
    "    \n",
    "    return adj_scores\n",
    "\n",
    "\n",
    "def assign_scores(sortedlist):\n",
    "    \"\"\"Scales the scores of a given list such that they rank from \n",
    "    0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    value_max = sortedlist[0][1]\n",
    "    score_dict = {}\n",
    "\n",
    "    for node, score in sortedlist:\n",
    "        score_dict[node] = np.round((score/value_max), 4)\n",
    "    \n",
    "    return score_dict\n",
    "\n",
    "\n",
    "def calc_total_scores(graph):\n",
    "    \"\"\"Calculates the total scores of each node and sorts the scores \n",
    "    from highest to lowest.\n",
    "    \"\"\"\n",
    "\n",
    "    score_adj = calc_adjecency(graph)\n",
    "    score_bet = calc_betweenness(graph)\n",
    "    score_clo = calc_closeness(graph)\n",
    "    score_total = {}\n",
    "    \n",
    "    for node in score_adj:\n",
    "        score_total[node] = np.round(score_adj[node] + score_bet.get(node, 0) \n",
    "                                     + score_clo.get(node, 0), 4)\n",
    "\n",
    "    sorted_scores = dict(sorted(score_total.items(), key=lambda x: x[1], \n",
    "                                reverse=True))\n",
    "     \n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de62a0c",
   "metadata": {},
   "source": [
    "Nodes are not immediately tested based on scores but rather checked if they are neighboring a previouslt determined infected node. Neighbors of a previously infected node will receive a a higher score based on the score of the infected node they neighbor. This may result in nodes being higher in the score list but does not neccesarily prioritize them over all the nodes. \n",
    "\n",
    "A list of nodes neighboring infected noides is made and those nodes are assigned a higher score. This will only occu once per infected neighbor in the total simulation by checking if they did not already receive a score boost. This is checked by storing infected nodes in 'infected' until they have assigned scores to neighbors. Tests are, however, susceptible to accuracy errors and will return either a false susceptible for an infected node or a false infected for a susceptible node.\n",
    "\n",
    "All (known) susceptible nodes are then added to the test candidate list and sorted. The top nodes, dependent on the number of tests, are teste and their status is set to the tested status in the known graph. Remember that the true status of a node is not always up to dat and also susceptible to accuracy errors in the test phase. \n",
    "\n",
    "Susceptible nodes are added to the vaccination pool and all other statusses are removed from the vaccination pool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8bc49bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nodes_score(tests, scores, graph_known, model, vac_pool, infected, \n",
    "                     accuracy):\n",
    "    \"\"\"\n",
    "    Tests nodes to determine their infection status based on scores \n",
    "    and known statuses. Only tests nodes that are not currently removed \n",
    "    or infected.\n",
    "\n",
    "    Parameters:\n",
    "        tests: Maximum number of nodes to test.\n",
    "        scores: Dictionary of nodes with their associated scores.\n",
    "        graph_known: The graph representing known node statuses.\n",
    "        model: The model containing the current status of each node.\n",
    "        vac_pool: List of nodes available for vaccination.\n",
    "        infected: List of currently infected nodes.\n",
    "        accuracy: Probabilities for testing accuracy (true positive, \n",
    "                  false positive).\n",
    "\n",
    "    Returns:\n",
    "        Updated graph_known data, vaccination pool and the infected nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    test_nodes = []\n",
    "    tested_nodes = []\n",
    "\n",
    "    for node, _ in scores.items():\n",
    "        # find neighbors of known infected add to list\n",
    "        if graph_known.nodes[node]['status'] == 1:\n",
    "            neighbors_list = [n for n in graph_known.neighbors(node) \n",
    "                              if graph_known.nodes[n]['status'] == 0]\n",
    "            \n",
    "            for n in neighbors_list:\n",
    "                if n not in test_nodes:\n",
    "                    test_nodes.append(n)\n",
    "                \n",
    "                # Scores get updated based on infected neighbor (only once per infection)\n",
    "                if node in infected:\n",
    "                    scores[n] += scores[node]\n",
    "\n",
    "            # Remove an infected node from this list after all neighbors' scores have been updated\n",
    "            if node in infected: \n",
    "                infected.remove(node)\n",
    "\n",
    "        # Add susceptible known to list\n",
    "        elif graph_known.nodes[node]['status'] == 0:\n",
    "            test_nodes.append(node)\n",
    "\n",
    "    # Sorts the nodes to test based on their score\n",
    "    test_nodes = sorted(test_nodes, key=lambda x: scores.get(x, 0), \n",
    "                        reverse=True)\n",
    "\n",
    "    for node in test_nodes[:tests]:\n",
    "        status = model.status[node]\n",
    "\n",
    "        # Status may change according to the test accuracy \n",
    "        if status == 0:\n",
    "            status = np.random.choice([status, 1], p=accuracy)\n",
    "        elif status == 1:\n",
    "            status = np.random.choice([status, 0], p=accuracy)\n",
    "            \n",
    "        graph_known.nodes[node]['status'] = status\n",
    "        tested_nodes.append(node)\n",
    "\n",
    "        # Add or remove nodes to their corresponding list\n",
    "        if status == 0 and node not in vac_pool:\n",
    "            vac_pool.append(node)\n",
    "        elif status == 1 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "            infected.append(node)\n",
    "        elif status == 2 and node in vac_pool:\n",
    "            vac_pool.remove(node)\n",
    "    \n",
    "    #sort the vac_pool based on their score \n",
    "    vac_pool = sorted(vac_pool, key=lambda x: scores.get(x, 0), reverse=True)\n",
    "\n",
    "    return graph_known, vac_pool, infected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176f6a2",
   "metadata": {},
   "source": [
    "Nodes are vaccinated dependent on the vaccination budget and available nodes in the vaccination pool. The top nodes, dependent on the number of vaccinations, are vaccinated and their status is set to 'removed'' in the known graph. The status is only updated in the model if their true status was susceptible. Remember that the true status of a node is not always up to date and may experience accuracy errors in the test phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ce1e16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vac_nodes_score(model, graph_known, vac_budget, vac_pool, scores):\n",
    "    \"\"\"\n",
    "    Tests nodes for infection based on their score and updates their \n",
    "    status, prioritizing nodes based on score.\n",
    "\n",
    "    Parameters:\n",
    "        tests: Maximum number of nodes to test.\n",
    "        scores: Node scores indicating infection likelihood.\n",
    "        graph_known: Graph with each node's known status.\n",
    "        model: Model with 'status' attribute for current node statuses.\n",
    "        vac_pool: List nodes selected for vaccination.\n",
    "        infected: List of infected nodes.\n",
    "        accuracy: Probability of correct test results for each status.\n",
    "\n",
    "    Returns:\n",
    "        Updated data for graph_known, vac_pool, tested_nodes and \n",
    "        infected.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(vac_pool) < vac_budget:\n",
    "        add_to_pool = vac_budget - len(vac_pool)\n",
    "        candidates = [node for node in graph_known.nodes \n",
    "                      if graph_known.nodes[node]['status'] == 0 \n",
    "                      and node not in vac_pool]\n",
    "        sorted_c = sorted(candidates, key=lambda x: scores.get(x, 0), \n",
    "                          reverse=True)\n",
    "\n",
    "        for c in sorted_c[:add_to_pool]:\n",
    "            vac_pool.append(c)\n",
    "\n",
    "        vac_budget = len(vac_pool)\n",
    "\n",
    "    vac_nodes = vac_pool[0:vac_budget]\n",
    "\n",
    "    # Update all statuses of vaccinated nodes to 'Removed'\n",
    "    for node in vac_nodes:\n",
    "        graph_known.nodes[node]['status'] = 2\n",
    "\n",
    "        # Can only remove people who are not currently infected or removed\n",
    "        if model.status[node] == 0:\n",
    "            model.status[node] = 2\n",
    "\n",
    "        # Remove vaccinated from vaccination pool\n",
    "        vac_pool.remove(node)\n",
    "\n",
    "    return model, graph_known, vac_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf9c60",
   "metadata": {},
   "source": [
    "The final simulation is run for a predetermined time span and a specified number of times and tests are only carried out while there are tests remaining in the total test buidget. The results are stored to be analyzed later. The means and standard deviations of the maximum number of infected in each run is also calculated and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "76796437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_campaign(test_max, beta, gamma, t_span):\n",
    "    \"\"\"\n",
    "    Simulates an SIR model score based vaccination campaign.\n",
    "\n",
    "    Arguments:\n",
    "        test_max: Maximum number of nodes to test per time step.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        t_span: Total time duration for the simulation.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries containing infection counts, \n",
    "        susceptible counts, removed counts, vaccination pool size, and \n",
    "        remaining tests at each time step.\n",
    "    \"\"\"\n",
    "\n",
    "    total_tests = 200\n",
    "    t = 0\n",
    "    vac_pool = []\n",
    "    iterations = 1\n",
    "    vac_budget = 5\n",
    "    accuracy = [0.75, 0.25]\n",
    "    infected = []\n",
    "    results = []\n",
    "\n",
    "    # Loads and initializes all data, makes a graph of the known statuses.\n",
    "    graph, graph_known = load_sociopatterns()\n",
    "    model, graph_known = initiate_model(graph, graph_known, beta, gamma)\n",
    "\n",
    "    # Assign scores to nodes based on adjecency, betweenness and closeness.\n",
    "    scores_dict = calc_total_scores(graph)\n",
    "\n",
    "    infected_count = sum(1 for node in model.status \n",
    "                             if model.status[node] == 1)\n",
    "    susceptible_count = sum(1 for node in model.status \n",
    "                            if model.status[node] == 0)\n",
    "    removed_count = sum(1 for node in model.status \n",
    "                        if model.status[node] == 2)\n",
    "\n",
    "    # Append results for the current time step\n",
    "    results.append({\n",
    "        'time': t,\n",
    "        'infected': infected_count,\n",
    "        'susceptible': susceptible_count,\n",
    "        'removed': removed_count,\n",
    "        'vaccination_pool_size': len(vac_pool),\n",
    "        'total_tests_remaining': total_tests,\n",
    "    })\n",
    "\n",
    "    while t <= t_span:\n",
    "        if total_tests > 0:\n",
    "            graph_known, vac_pool, infected = test_nodes_score(test_max, scores_dict, graph_known, \n",
    "                                        model, vac_pool, infected, accuracy)\n",
    "            \n",
    "        model, graph_known, vac_pool = vac_nodes_score(model, graph_known, vac_budget, vac_pool, \n",
    "                                  scores_dict)\n",
    "        \n",
    "        update_sir_model(model, graph, iterations)\n",
    "\n",
    "        total_tests -= test_max\n",
    "\n",
    "        # Reset tests per iteration if the budget is too small.\n",
    "        if total_tests < test_max:\n",
    "            test_max = total_tests\n",
    "\n",
    "        # Store the current state of the model\n",
    "        infected_count = sum(1 for node in model.status \n",
    "                             if model.status[node] == 1)\n",
    "        susceptible_count = sum(1 for node in model.status \n",
    "                                if model.status[node] == 0)\n",
    "        removed_count = sum(1 for node in model.status \n",
    "                            if model.status[node] == 2)\n",
    "\n",
    "        # Append results for the current time step\n",
    "        results.append({\n",
    "            'time': t,\n",
    "            'infected': infected_count,\n",
    "            'susceptible': susceptible_count,\n",
    "            'removed': removed_count,\n",
    "            'vaccination_pool_size': len(vac_pool),\n",
    "            'total_tests_remaining': total_tests,\n",
    "        })\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def simulate_score_campaign(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Runs multiple simulations of the score-based campaign.\n",
    "\n",
    "    Parameters:\n",
    "        test_max: Maximum number of tests per time step.\n",
    "        beta: Infection rate.\n",
    "        gamma: Recovery rate.\n",
    "        t_span: Total time duration for each simulation run.\n",
    "        num_runs: Number of times to repeat the simulation.\n",
    "\n",
    "    Returns:\n",
    "        A List of peak infection counts across runs, the average of peak \n",
    "        infection counts and the standard deviation of peak infection \n",
    "        counts.\n",
    "    \"\"\"\n",
    "\n",
    "    max_I_vals = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        results = score_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_counts = [entry['infected'] for entry in results]\n",
    "        max_I = max(infected_counts)\n",
    "        max_I_vals.append(max_I)\n",
    "    \n",
    "    mean_max_I = np.mean(max_I_vals)\n",
    "    std_max_I = np.std(max_I_vals)\n",
    "\n",
    "    return max_I_vals, mean_max_I, std_max_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 10\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 50\n",
    "num_runs = 5\n",
    "\n",
    "simulate_score_campaign(test_max, beta, gamma, t_span, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2e419",
   "metadata": {},
   "source": [
    "To compare the strategies, data from all campaigns is gathered to be plotted against each other. \n",
    "\n",
    "The highest Infected values for each campaign are gathered multiple times for which the mean ius calculated, as well as the standard deviation. These are then plotteds with eror bars to compare the vaccination strategies.\n",
    "\n",
    "A plot of the mean development of the S, I and R populations over time for each vaccination strategy is also plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "0fd6b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_campaign_results(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Plots the mean maximum infected counts for random, hub and score\n",
    "    campaigns with their standard deviations.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, mean_max_random, std_max_random = simulate_random_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    _, mean_max_hub, std_max_hub = simulate_hub_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    _, mean_max_score, std_max_score = simulate_score_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "    x_labels = ['Random', 'Hub', 'Score']  \n",
    "    means = [mean_max_random, mean_max_hub, mean_max_score]  \n",
    "    std_devs = [std_max_random, std_max_hub, std_max_score]  \n",
    "\n",
    "    \n",
    "    plt.errorbar(x=np.arange(len(means)), y=means, yerr=std_devs, fmt='o', \n",
    "                 capsize=5, color='blue', alpha=0.7, \n",
    "                 label='Mean Max Infected Counts')\n",
    "\n",
    "    plt.xticks(np.arange(len(x_labels)), x_labels)\n",
    "    plt.title('Mean Maximum Infected Counts with Standard Deviation')\n",
    "    plt.ylabel('Count of Infected Individuals')\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def t_test(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"\n",
    "    Performs a t-test comparing the peak infection counts of random, \n",
    "    hub-based, and score-based testing campaigns to evaluate significant \n",
    "    differences.\n",
    "    \"\"\"\n",
    "\n",
    "    max_vals_random, _, _ = simulate_random_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    max_vals_hub, _, _ = simulate_hub_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    max_vals_score, _, _ = simulate_score_campaign(\n",
    "        test_max, beta, gamma, t_span, num_runs)\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(max_vals_random, max_vals_hub, \n",
    "                                    max_vals_score)\n",
    "\n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae687d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 10\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 50\n",
    "num_runs = 10\n",
    "\n",
    "show_campaign_results(test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "#t_stat, p_val = t_test(test_max, beta, gamma, t_span, num_runs)\n",
    "\n",
    "#print(\"t-statistic:\", t_stat)\n",
    "#print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43a016",
   "metadata": {},
   "source": [
    "To compare the campaigns, we also plotted the data of each population against time to see a trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "bc16ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_strategies(test_max, beta, gamma, t_span, num_runs):\n",
    "    \"\"\"Calculates the mean values for the populations for each \n",
    "    strategy.\n",
    "    \"\"\"\n",
    "        \n",
    "    num_time_steps = t_span \n",
    "    num_runs = num_runs \n",
    "\n",
    "    i_mean_r = [[] for _ in range(num_time_steps)]\n",
    "    s_mean_r = [[] for _ in range(num_time_steps)]\n",
    "    r_mean_r = [[] for _ in range(num_time_steps)]\n",
    "\n",
    "    i_mean_h = [[] for _ in range(num_time_steps)]\n",
    "    s_mean_h = [[] for _ in range(num_time_steps)]\n",
    "    r_mean_h = [[] for _ in range(num_time_steps)]\n",
    "\n",
    "    i_mean_s = [[] for _ in range(num_time_steps)]\n",
    "    s_mean_s = [[] for _ in range(num_time_steps)]\n",
    "    r_mean_s = [[] for _ in range(num_time_steps)]\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        \n",
    "        results_r = random_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_r = [entry['infected'] for entry in results_r]\n",
    "        susceptible_r = [entry['susceptible'] for entry in results_r]\n",
    "        removed_r = [entry['removed'] for entry in results_r]\n",
    "\n",
    "        results_h = hub_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_h = [entry['infected'] for entry in results_h]\n",
    "        susceptible_h = [entry['susceptible'] for entry in results_h]\n",
    "        removed_h = [entry['removed'] for entry in results_h]\n",
    "\n",
    "        results_s = score_campaign(test_max, beta, gamma, t_span)\n",
    "        infected_s = [entry['infected'] for entry in results_s]\n",
    "        susceptible_s = [entry['susceptible'] for entry in results_s]\n",
    "        removed_s = [entry['removed'] for entry in results_s]\n",
    "\n",
    "        for time_step in range(num_time_steps):\n",
    "            i_mean_r[time_step].append(infected_r[time_step])\n",
    "            s_mean_r[time_step].append(susceptible_r[time_step])\n",
    "            r_mean_r[time_step].append(removed_r[time_step])\n",
    "\n",
    "            i_mean_s[time_step].append(infected_s[time_step])\n",
    "            s_mean_s[time_step].append(susceptible_s[time_step])\n",
    "            r_mean_s[time_step].append(removed_s[time_step])\n",
    "\n",
    "            i_mean_h[time_step].append(infected_h[time_step])\n",
    "            s_mean_h[time_step].append(susceptible_h[time_step])\n",
    "            r_mean_h[time_step].append(removed_h[time_step])\n",
    "\n",
    "\n",
    "    mean_i_r = [np.mean(i_mean_r[time_step]) for time_step in range(num_time_steps)]\n",
    "    mean_s_r = [np.mean(s_mean_r[time_step]) for time_step in range(num_time_steps)]\n",
    "    mean_r_r = [np.mean(r_mean_r[time_step]) for time_step in range(num_time_steps)]\n",
    "\n",
    "    mean_i_s = [np.mean(i_mean_s[time_step]) for time_step in range(num_time_steps)]\n",
    "    mean_s_s = [np.mean(s_mean_s[time_step]) for time_step in range(num_time_steps)]\n",
    "    mean_r_s = [np.mean(r_mean_s[time_step]) for time_step in range(num_time_steps)]\n",
    "\n",
    "    mean_i_h = [np.mean(i_mean_h[time_step]) for time_step in range(num_time_steps)]\n",
    "    mean_s_h = [np.mean(s_mean_h[time_step]) for time_step in range(num_time_steps)]\n",
    "    mean_r_h = [np.mean(r_mean_h[time_step]) for time_step in range(num_time_steps)]\n",
    "\n",
    "    mean_r = [mean_s_r, mean_i_r, mean_r_r]\n",
    "    mean_h = [mean_s_h, mean_i_h, mean_r_h]\n",
    "    mean_s = [mean_s_s, mean_i_s, mean_r_s]\n",
    "\n",
    "    return mean_r, mean_h, mean_s\n",
    "    \n",
    "\n",
    "def plot_strategies_sir(mean_r, mean_h, mean_s, t_span):\n",
    "    \"\"\"Plots the results of the SIR vaccination campaign simulations.\n",
    "\n",
    "    Arguments:\n",
    "        mean_r: Calculated mean values for the random campaign.\n",
    "        mean_h: Calculated mean values for the hub campaign.\n",
    "        mean_s: Calculated mean values for the score campaign.\n",
    "        t_span: timespan of each run.\n",
    "\n",
    "    Returns:\n",
    "        None, plots a graph.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_s_r, mean_i_r, mean_r_r = mean_r\n",
    "    mean_s_h, mean_i_h, mean_r_h = mean_h\n",
    "    mean_s_s, mean_i_s, mean_r_s = mean_s\n",
    "\n",
    "    time = np.arange(0, t_span, 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time, mean_s_r, label='Random (S)', color='b', linestyle='-')\n",
    "    plt.plot(time, mean_i_r, label='Random (I)', color='orange', linestyle='-')\n",
    "    plt.plot(time, mean_r_r, label='Random (R)', color='g', linestyle='-')\n",
    "\n",
    "    plt.plot(time, mean_s_h, label='Hub (S)', color='b', linestyle='--')\n",
    "    plt.plot(time, mean_i_h, label='Hub (I)', color='orange', linestyle='--')\n",
    "    plt.plot(time, mean_r_h, label='Hub (R)', color='g', linestyle='--')\n",
    "\n",
    "    plt.plot(time, mean_s_s, label='Score (S)', color='b', linestyle=':')\n",
    "    plt.plot(time, mean_i_s, label='Score (I)', color='orange', linestyle=':')\n",
    "    plt.plot(time, mean_r_s, label='Score (R)', color='g', linestyle=':')\n",
    "    \n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Population (N)')\n",
    "    plt.title('SIR Model Vaccination Campaigns')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 10\n",
    "beta = 0.05\n",
    "gamma = 0.01\n",
    "t_span = 300\n",
    "num_runs = 30\n",
    "\n",
    "mean_r, mean_h, mean_s = calc_mean_strategies(test_max, beta, gamma, t_span, num_runs)\n",
    "plot_strategies_sir(mean_r, mean_h, mean_s, t_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce27954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
